---
title: "arXiv2506 || 层次推理模型：突破传统思维链的深度计算新范式"
source: "https://mp.weixin.qq.com/s/teKAJ-GTirAXGHWxK3eSPQ"
author:
  - "[[Weixin Official Accounts Platform]]"
published:
created: 2025-07-03
description: "用2700万参数和1000个训练样本，HRM在复杂推理任务上取得的卓越表现，不仅证明了生物启发架构的巨大潜力，更重要的是为突破当前大模型固有的计算深度限制开辟了全新技术路径。"
tags:
  - "生物启发架构"
  - "计算深度限制"
  - "小样本学习"
abstract: "HRM模型通过生物启发架构和层次化收敛机制，仅用2700万参数和1000个训练样本就在复杂推理任务上实现了卓越表现。"
---
![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/ExPPKXgNVtcjFy8ibds0G8gjdC7Jkj3D385TtDZooztdC0EibwasfG534lxQBSFwQUibDiauejkzY6ViaGTpiap4K9Ug/0?wx_fmt=jpeg)

[深度图学习与大模型LLM](https://mp.weixin.qq.com/s/) *2025年07月03日 10:09*

## 层次推理模型：突破传统思维链的深度计算新范式

---

当前人工智能发展中，深度学习推理领域正在经历一次重要变革。虽然大模型在众多任务中展现了卓越性能，但在复杂推理任务中仍受限于计算深度。传统Transformer架构，难以胜任大量迭代推理的问题，Chain-of-Thought (CoT)等方法虽能在一定程度上缓解这一问题，但普遍存在脆弱性和数据效率低的缺陷。

**本文将介绍一项2025年6月份的研究成果** ——Hierarchical Reasoning Model (HRM)，这是一个基于大脑层次化处理机制的全新架构。该模型仅使用2700万参数和1000个训练样本，便在复杂Sudoku谜题、迷宫导航和ARC-AGI挑战等任务中实现了近乎完美的性能，大幅超越了o3-mini-high和Claude 3.7等大型CoT模型。

![Image](https://mmbiz.qpic.cn/mmbiz_png/ExPPKXgNVtcjFy8ibds0G8gjdC7Jkj3D3wFghJebHMIY9clJnLVcVQzlzRsDWKztK0Hich2hJ65YbyVUO84uXqIQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

## 1\. 基本信息

**论文标题：** Hierarchical Reasoning Model / 层次推理模型

**作者团队：** 该研究由Sapient Intelligence (新加坡)与清华大学联合完成。核心成员包括来自Sapient Intelligence的Guan Wang、Jin Li、Yuhao Sun、Xing Chen、Changling Liu、Yue Wu、Meng Lu，以及清华大学的Sen Song和Sapient Intelligence的Yasin Abbasi Yadkori。Guan Wang、Meng Lu、Sen Song和Yasin Abbasi Yadkori担任通讯作者。

**发表信息：** 论文于2025年6月26日在arXiv发布，编号为arXiv:2506.21734v1 \[cs.AI\]。

## 2\. 研究背景

深度学习的核心思想在于通过增加网络层数来增强表征能力和提升性能， **但当前大模型的架构却呈现出一种矛盾现象——它们在多项任务中表现优异，核心架构却相对较浅** 。这种固定深度限制使Transformer被局限在特定计算复杂度类别（如AC⁰或TC⁰）中。更关键的是，大模型不具备图灵完备性，无法端到端地执行复杂算法推理，而这类推理对于精密规划或符号操作任务不可或缺。

为弥补这一缺陷，目前主要采用Chain-of-Thought (CoT)提示技术来增强推理能力。 **CoT将复杂任务拆解为简单中间步骤，利用浅层模型按序生成文本，将推理过程外化为Token级语言表达** 。CoT推理本质上只是一种临时解决方案，并非理想答案。它依赖于人为设计的子任务，任何单步错误或步骤混乱都可能导致整个推理过程崩溃。更重要的是，这种将推理限制在Token级模式内，使得CoT推理通常需要海量训练数据，并在复杂推理任务中生成大量Token，最终导致响应速度缓慢。

大脑通过皮层区域间的层次化组织处理信息，这些区域在不同时间尺度上协同工作，实现了深度多阶段推理。递归反馈回路不断精炼内部表征，使得缓慢的高层区域能够指导快速的低层电路执行下级处理，同时维持全局一致性。值得注意的是，大脑实现这种深度处理时并不承担通常困扰递归网络的反向传播时间（BPTT）的高昂信用分配代价。

受这种层次化多时间尺度生物架构启发，作者设计了Hierarchical Reasoning Model (HRM)。 **HRM旨在大幅提升有效计算深度，采用两个相互耦合的递归模块：负责抽象深度推理的高层(H)模块和负责快速精细计算的低层(L)模块** 。这种架构通过"层次化收敛"过程避免了标准递归模型的快速收敛问题。每个周期内，L模块向局部平衡稳定收敛，这种平衡取决于该周期内提供的高层状态 。T步完成后，H模块整合子计算结果（L模块最终状态）并执行自身更新， 的更新为L模块创建新的上下文环境，实质上"重置"其计算路径并启动向不同局部平衡的新收敛过程。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

## 3\. 方法

隐藏状态趋向固定点时，更新幅度逐渐缩小，有效终止后续计算并限制网络的深度。理想情况下应让收敛过程极为缓慢以保持计算能力，但实现这种渐进式方法极为困难，因为过度延缓收敛会使系统趋于不稳定。

**HRM通过层次化收敛机制主动对抗这种过早收敛现象** 。每个周期内，L模块（一个RNN）表现出向局部平衡的稳定收敛特性。这种平衡状态依赖于该周期内提供的高层状态 。T步完成后，H模块整合子计算结果（最终状态 ）并执行自身更新。 的更新为L模块建立新的上下文环境，实质上"重启"其计算路径并启动向不同局部平衡的新收敛阶段。

具体而言，HRM模型包含四个可学习组件：输入网络 、低层递归模块 、高层递归模块 和输出网络 。模型动态过程在N个高层周期中展开，每个周期包含T个低层时间步。一次前向传播的总时间步采用索引 。

模型从输入向量x到输出预测向量 的映射过程如下。首先，输入x通过输入网络投影为工作表征：

每个时间步i中，L模块基于自身前一状态、H模块当前状态（整个周期内保持固定）以及输入表征来更新状态。H模块仅在每个周期更新一次（即每T个时间步），使用该周期末L模块的最终状态：

最终，N个完整周期后，从H模块隐藏状态中提取预测：

这整个NT时间步过程构成HRM的一次前向传播。停止机制（后续详述）决定模型是否终止并使用 作为最终预测，或继续执行额外的前向传播。

### 近似梯度计算

递归模型通常采用BPTT计算梯度， **BPTT需要存储前向传播的隐藏状态，然后在反向传播过程中将其与梯度结合，对T个时间步需要O(T)内存** 。这种庞大的内存负担迫使采用更小批次规模，导致GPU利用率不佳，对大规模网络尤为如此。此外，由于保留完整时间历史轨迹在生物学上不可行，大脑不太可能实现BPTT。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

幸运的是，当递归神经网络收敛到固定点时，作者可通过在该平衡点应用单步反向传播来避免展开状态序列。基于这一发现，作者提出了HRM梯度的单步近似方法—— **使用各模块最终状态的梯度，将其他状态视为常数** 。梯度路径为：

输出头 → H模块最终状态 → L模块最终状态 → 输入嵌入

该方法仅需O(1)内存，无需时间展开，可通过PyTorch等自动微分框架轻松实现。考虑到各模块只需通过最近的局部突触活动反向传播错误，这种方法与皮层信用分配依赖短程时间局部机制而非全局活动模式重放的观点高度吻合。

### 深度监督机制

作者将深度监督机制融入HRM。给定数据样本 ，模型运行多个HRM前向传播，每个称为一个段(segment)。设M表示终止前执行的段总数。对每个段 ，设 表示段m结束时的隐藏状态。

---

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

每个段m均应用深度监督步骤：首先，给定前一段状态 ，通过HRM模型前向传播计算下一状态 及对应输出 ；然后计算当前段损失 ；最后更新参数 。

该过程的关键在于隐藏状态 在用作下一段输入状态前从计算图中"分离"。因此，段 的梯度不会反向传播至段m，有效创建了递归深度监督过程的1步近似。

### 自适应计算时间

受大脑在自动思维（"系统1"）与深度推理（"系统2"）间动态切换机制启发，作者将自适应停止策略整合到HRM中，实现"快慢思维"。该整合利用深度监督并采用Q学习算法自适应确定段数。

Q头使用H模块最终状态预测"停止"和"继续"动作的Q值：

其中 表示逐元素应用的sigmoid函数。停止或继续动作采用随机策略选择。设 表示最大段数（固定超参数）， 表示最小段数（随机变量）。 值随机确定：以概率 从集合 中均匀采样（鼓励长时思考），以概率 设为1。

停止动作在两种情况下被选择：段数超过最大阈值 时，或估计停止值 超过估计继续值 且段数达到最小阈值 时。

Q头通过Q学习算法更新，定义在以下情节马尔可夫决策过程(MDP)上。MDP在段m的状态为 ，动作空间为 。选择"halt"动作终止情节并返回表示预测正确性的二元奖励 。选择"continue"产生0奖励且状态转移至 。

各监督段的总损失结合了Q头损失和序列到序列损失：

最小化上述损失可实现准确预测和近乎最优的停止决策。

## 4\. 实验与发现

作者在三个高难度基准测试上评估了HRM性能，这些基准专门用于测试AI模型的不同推理能力。实验设计体现了小样本学习的严格标准： **所有HRM模型均采用随机权重初始化，在序列到序列设置中使用输入-输出对训练，每个任务仅使用约1000个训练样本，且无预训练或CoT标签** 。

  

**ARC-AGI挑战测试** 充分展现了HRM在归纳推理方面的卓越能力。在ARC-AGI-1基准测试中，使用960个训练样本， **HRM实现了40.3%的准确率** ，大幅超越o3-mini-high的34.5%和Claude 3.7 8K的21.2%。在更具挑战性的ARC-AGI-2测试中，使用1120个训练样本，HRM获得了5.0%的准确率，而其他模型表现均未超过3.0%。这些成果尤为瞩目，因为HRM仅有2700万参数和30×30网格上下文（900个Token），而对比的CoT模型拥有更大参数规模和上下文长度。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**Sudoku-Extreme任务** 突出体现了HRM在符号树搜索难题上的突破性表现。作者专门构建了Sudoku-Extreme数据集，平均难度为每个谜题需要22次回溯搜索，远高于现有数据集。在这一极具挑战性的任务上，\*\*HRM达到了55.0%的准确率，而所有基线方法（包括Direct prediction、o3-mini-high、Claude 3.7 8K和Deepseek R1）准确率均为0.0%\*\*。该结果表明，传统CoT方法在需要大量搜索和回溯的任务上完全失效，而HRM能够有效应对此类复杂推理。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**Maze-Hard导航任务** 进一步验证了HRM在空间推理方面的优势。在30×30迷宫最优路径寻找任务中， **HRM实现了74.5%的准确率，同样远超所有基线方法的0.0%表现** 。该任务要求找出从起点到终点的最短有效路径，难度按最短路径长度定义，与GPU上广度优先搜索算法的线性时间复杂度相对应。

**计算深度的重要性** 通过对比实验得到有力验证。在Sudoku-Extreme Full任务中，增加Transformer宽度几乎不产生任何性能提升，增加深度则至关重要。标准架构会出现饱和现象，无法从增加的深度中受益。 **HRM突破了这一根本限制，有效利用计算深度实现接近完美的准确率** 。随着深度从8层增至512层，HRM性能持续提升，而标准Transformer和递归Transformer在达到特定深度后性能趋于平稳。

**自适应计算时间机制** 的有效性通过详细分析得到确认。实验表明，ACT能够根据任务复杂性有效调节计算资源，在保持最小性能影响的同时实现显著计算节省。与采用固定计算步数的模型相比，采用ACT的HRM在平均计算步数方面保持较低且稳定的水平，即使最大限制参数增加也是如此。更重要的是， **HRM展现了无缝推理时扩展能力，通过简单增加计算限制参数 即可在推理时获得性能提升，无需额外训练或架构修改** 。

## 5\. 结论与展望

Hierarchical Reasoning Model标志着人工智能推理架构的重大突破，成功将大脑层次化处理原理转化为实用的深度学习模型。 **仅用2700万参数和1000个训练样本，HRM在复杂推理任务上取得的卓越表现，不仅证明了生物启发架构的巨大潜力，更重要的是为突破当前大模型固有的计算深度限制开辟了全新技术路径** 。

该研究的理论贡献在于揭示了层次化收敛机制如何有效解决传统递归网络的早期收敛问题，同时通过单步梯度近似规避了BPTT的计算和内存开销。在实际应用层面，HRM展现的推理时扩展能力和自适应计算特性为构建真正的通用推理系统奠定了坚实基础。特别值得关注的是， **模型学习到的维度层次化组织与大脑皮层结构的惊人相似性，不仅为理解人工神经网络内在机制提供了新视角，也为未来架构设计指明了方向** 。

继续滑动看下一个

深度图学习与大模型LLM

向上滑动看下一个