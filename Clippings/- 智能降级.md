---
title: "智能降级"
source: "https://mp.weixin.qq.com/s/QtSboPNmxoBxcfJt-rD29A"
author:
  - "[[老李话一三]]"
published:
created: 2025-08-25
description: "我们做的很多事可能不是在增加AI的能力，而是起到智能降级的效果"
tags:
  - "智能降级"
  - "提示词陷阱"
  - "数据中台"
  - "独占性上下文"
abstract: "文章指出过度依赖提示词和规则会限制AI的通用智能，主张通过提供独占性上下文和高势能工具箱来避免智能降级，并强调数据中台的重要性。"
---
Original 老李话一三 *2025年08月24日 21:00*

近来 看到 个 最好玩 的 消息 ， 大致 下面 这样 ：

  

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/ZPgufkUbasSE1CDYrVCe3kCXibddrH49YTRNVPnzomHibgHksbQLojdQ7uicPRgdCBXe3QTtDjlN666fvmiaFnk3VQ/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

看到 这个内容的 时候 ， 我 是 真 的 笑 喷 了 。

这 其实 意味 着 大家 花了 很多 时间 做 所谓 的 智能体 ，创造 的 全是 负 价值 。

#### 为啥会这样？

原因特简单。

来自 过去产研阵营 的 人类 总 是 觉得， 可以 通过 加入 人类 以为 让 A I 更好 的 知识 （表现为提示词，本质是规则） 来 提升 A I 在 特定 方向 的 表现。

这些所谓的“ 人类 知识” 和 " 小技巧 " ，表现出来就是提示词（Prompt），本质上 则 是一堆 给 A I 的 规则。

这些 东西 有助于 提高 限定 目标 下 的 精度 ， 但 对于一个大模型来说， 实则 是一种戕害 ， 是一种“智能降级”的行为。

  

大模型的 厉害 之处在哪？

  

在于它学了海量的数据，内部形成了一个模拟真实世界的、极其复杂的概率模型。它有种“涌现”出来的、我们都还没完全搞懂的通用智能。

你加进去的那些规则，就像是给一个想象力无限的画家，硬塞了一本儿童涂色书，还规定他必须在框框里涂色，不能出界。

你以为你在“优化”他画苹果的能力，实际上你废掉了他创作《星空》的可能。

当你面对的需求，敞口巨大、千奇百怪、无限贴近真实世界的时候——比如一个律师的日常工作——你那点“局部优化”就变得 得不偿失 。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/ZPgufkUbasSE1CDYrVCe3kCXibddrH49YOKPZPiadHTicYALiaqCqsoE00uXx6E4dKaLdoCyw1MicJg86piajiaJr89aw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

你阉割掉的通用智能部分 所 带来 的 损失 大于 你费劲匹配上的那部分需求 上 的 收益 。

最终就 化成 用户 的 三个字： 不好用 。

这就是 “智能降级” ， 也 就是现在做智能体的典型陷阱。

更要命的是，大模型本身，还有像通用搜索这种脚手架， 它 进步越快，陷阱就挖得越深。

#### 咋办？

要规避“智能降级”这个大 天 坑，核心就一句话：

别再尝试教AI“怎么思考”，而是要给它“思考的材料”。

（背后的原则就是我们23年就开始提到的智能优先）

  

人类 得 承认 AI的“脑子”（底座模型） 在 无属性 的 智能 上 已经比 人 强了， 所以 不 要 尝试 当 一个 蹩脚 的 “老师”，而是当它的“情报官”。

给它提供它原本接触不到的、高质量的、独家的“情报”，也就是数据和上下文。然后相信它的智商，让它自己去推理、去判断。

当然 因为 你 要 更 了解 你 想 干什么 ， 所以 需要 一个 比较 复杂 的 评估 系统 。  

（这部分很复杂，本篇不展开）

沿着这个思路， 让 智能体 有 价值 方向其实很清晰：

  

方向一：深挖“独占性上下文”

通用大模型，懂的是 公域 。

它不知道你公司上周开了什么会，不知道你们最重要的客户是谁，更不知道你们的王牌产品是怎么研发出来的。

这些，就是你的“独占性上下文”。这是你唯一的、也是最坚固的护城河。

我们以前的说法：数据的边界是应用的边界。

智能体的首要价值，就是把这些散落在公司各个角落的、内部的、私有的数据，安全、高效地喂给大模型。

说白了，就是给AI开“内网权限”。让它能看到所有邮件、聊天记录、会议纪要、代码库、产品文档、客户关系管理系统（CRM）里的数据。

当AI能看到这一切的时候，它就不再是一个只会说胡话的“互联网嘴替”，而是一个真正懂你业务的“数字员工”。

人类 要 做 的主要不是用什么技巧提高 智能 ， 而是 要 补 数字化 的 课 。 上面 这事 深挖 的 话 ， 背后 是 数字 成本 和 生产 关系 问题 。

不管 怎么样 ， 人 这部分 才是 最大 的 成本 和 障碍 。

方向二：提供“高势能工具箱”

光能看还不行，还得能干活。

但这个“干活”，不是你规定好一步两步三步的僵化流程。

而是你给它一堆“工具”，就像给一个聪明的工人一个工具箱，里面有锤子、有扳手、有电钻。然后你告诉他，目标是“把墙上那幅画挂起来”。

他自己会判断，是该用钉子和锤子，还是用膨胀螺丝和电钻。

这个“工具箱”，在数字世界里就是各种API。比如“查库存”、“下订单”、“发邮件”、“创建日历”……

一个好的智能体，应该是一个能熟练使用你给的工具箱、去自主完成你交待的目标的“高级打杂工”。它有脑子，也有手脚。

方向 三其实 是 自我 优化 ，这更难搞，这篇 文章 里面不展开 了 。

前面的第一二点并非是Ai领域的问题，和过去的ERP、数字化等等重叠度更高。一定程度是补课和融合。陈果同志经常讲的内容，在这里是很有用的。比如：

  

#### 什么样的产品形态才能赢？还是看Glean吧

说了这么多，那到底什么样的产品才能避开“智能降级”的坑？

我们可以拿市面上两种不同形态的产品做个对比，一下就明白了。

  

失败的形态：那个5万美元的合同AI

这种产品，我称之为“工作流AI”。

它 明显 的 问题 是 灵活度 不够 ， 而 灵活 度 不够 则 是 因为 整合 深度 不够 。

它的逻辑是，在一个封闭的软件内部，预设好一个“分析合同”的流程。然后让AI来填充这个流程里的某些环节。

这时候 当人 可以 和 A I 高频 交互 的 时候 ， 你 的 工作流 带来 的 就 基本 是 坏处 。

它的问题 可能 是：

1\. 上下文缺失 ：它只知道你上传的这一份合同，不知道这份合同的背景、谈判过程（可能在邮件里）、相关的历史合同（可能在另一个文件夹里）。它是个“睁眼瞎”。

2\. 流程僵化 ：它把你和AI都锁死在一个固定的流程里。律师想换个角度问点问题，想让AI结合点别的信息，门儿都没有。这就是“智能降级”的重灾区。

3\. 价值孤 点 ：它的价值，仅限于“分析合同”这一个孤零零的场景。它无法把这个能力，和你公司的其他工作流串联起来。

成功的形态：Glean这样的产品

Glean的本质是一个“上下文平台” 。

它 所有 的 贡献 在 于 确保我们反复说过的：现实 理解 纵深 。

它什么流程都不预设。它的唯一目标，就是打通一家公司内部所有的数据孤岛，把Slack、Google Drive、Jira、Salesforce……所有系统里的数据全都连接起来，形成一个统一的、可供AI检索和理解的“企业知识图谱”或“企业大脑”。

这部分最麻烦的活其实并不是 大模型 出现 后 才 做好 的 。  

国内 当年说的 数据中台 其实 和 这活 非常 类似 。

只不过做数据中台的公司估计挂个七七八八了吧，这从一个侧面也反应了AI深度应用的现实难度。

下面是我随便找的一个中台的图，大家可以和Glean的架构比比：

![image.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

(https://juejin.cn/post/6844904164292575246)

下面是Glean的架构图：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

对比下来会有个可怕的结论：想做智能体先做好数据中台...

做不好数据中台，智能体一样不好用，至少牵涉生产关系的肯定不好用

  

Glean本身，就是那个最牛的“情报官”。它不教AI怎么思考，它只负责把最全、最准的“情报”喂给AI。

  

当一个智能体被架设在Glean这样的平台上，它就活了。你问它：“上个季度我们最重要的客户‘ACME公司’那边有什么进展和风险？”

一个“孤岛AI”会一脸懵逼。

但基于Glean的智能体是这么干的：

1\. 调取ACME公司在CRM里的所有记录。

2\. 调取与ACME相关的所有邮件和Slack聊天记录。

3\. 调取内部关于ACME项目的会议纪要和周报。

4\. 然后，它调用大模型的通用智能，把这些碎片化的信息综合起来，给出一个有理有据、包含洞察的回答：“进展是XX合同已续签，但风险是他们的关键接口人最近在邮件中抱怨我们的交付延迟，相关讨论在XX的Slack频道里有记录。”

  

你看，这整个过程，没有任何人去预设一个“客户风险分析”的死板流程。

Glean这种形态，就不 太 会出现“智能降级”的问题。

因为它做的不是“减法”（用规则限制AI），而是“乘法”（用数据拓宽AI的视野）。它的核心价值，不在于设计了多 厉害 的Prompt，而在于构建了多么 厉害 的“数据通路”。

当底层大模型从GPT-4升级到GPT-5，那个5万美元的“孤岛AI”可能就废了。

但Glean的价值反而会暴增。因为更强的大脑，配上更全的数据，能产生的智能是指数级增长的。

  

再强调下，上面的内容被我简化了，用于说明方向，真做开发的时候，累计偏差等处理有很复杂的过程。需要架构、领域模型等的综合。我1年多以前写过些这类文章。

#### 小结：智能优先与无人公司

说到底，这背后是一种根本的范式转变，一种“智能优先（AI First）”的原则。

过去的思路是“流程优先”，我们设计好流程，让AI来打辅助。这背后本质是人类优先，流程用于固化某种期望。

  

而“智能优先”是倒过来的：我们默认有一个聪明的“大脑”在C位，我们所有的工作，都是为这个大脑搭建一个能让它发挥最大价值的环境。

我们 以前 管 这个 叫 ： i f e l s e 调整 到 a n y t h e n 的 思维 模式 。

这个原则推到终极形态，就是“无人公司”。

未来的组织，不再是靠人类员工执行成千上万个僵化的SOP（标准操作程序）。而是把整个公司的业务逻辑，都 封装到一套智能体体系 里。

怎么封装？ 不是写死板的代码，而是为智能体体系定义好：

1\. 目标（Goals） ：比如，“维持公司产品A的库存量在1000到1200件之间”。

2\. 上下文（Context） ：给它接入实时的销售数据、供应链数据、物流信息（Glean模式）。

3\. 工具（Tools） ：给它调用采购系统API、向供应商发邮件API、向人类主管发预警API的权限。

这些 都 需要 个 底座 ， 这个 底座 就是 我 们 基本 干黄 的 数据 中台 。

然后，这个智能体体系就会像一个生命体一样，7x24小时地自主运行，自己做决策，自己调用工具去执行。

人类的角色，从执行者，变成了目标的设定者和最终结果的监督者。

所以， 规避 给AI“上规矩” 并且 最终产生 “智能降级”产品 ，首先要整明白个基础问题：AI是啥，是干啥的！  

(不过 说 起来很尴尬， 我 写了 快 两年 智能 原生 、 智能 优先 、 无人公司 ，不说别人，我的朋友们好多好像 还是不咋理解或者认同 ）

  

注：加入AI碰撞局或者入群联系:shuixiu2024

继续滑动看下一个

琢磨事

向上滑动看下一个