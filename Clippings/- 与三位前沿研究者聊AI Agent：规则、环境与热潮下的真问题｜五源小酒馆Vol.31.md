---
title: "与三位前沿研究者聊AI Agent：规则、环境与热潮下的真问题｜五源小酒馆Vol.31"
source: "https://mp.weixin.qq.com/s?__biz=MzkwMDI2ODE0OQ==&chksm=c1067722cee2c739897d484e4997114132de914f00fdcdbe77fee2b4ec22c087cb918913c635&idx=1&mid=2247502805&sn=4c9099d9c7f42439fa1c3da7d98f71c3#rd"
author:
  - "[[五源小酒馆]]"
published:
created: 2025-07-30
description: "Agent能提出真问题了吗？"
tags:
  - "AI Agent"
  - "科研突破"
  - "环境构建"
abstract: "三位前沿研究者探讨AI Agent在科研与复杂任务中的进展与挑战。"
---
Original 五源小酒馆 *2025年07月30日 16:08*

![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdckRrrlDjs0euJL0BnQictyncEGJY6icNMSHdUAsPjN3G2EpyksKOp1WMRAiaPAmF6OG5j4IZaqVjIsg/640?wx_fmt=png&from=appmsg&randomid=urv8t8an&tp=webp&wxfrom=5&wx_lazy=1)

  

这一期五源小酒馆，我们对话了三位活跃在 AI Agent 前沿的研究者——黄柯鑫、谢云飞与张佳钇，探讨智能体发展的真实进展与挑战。

  

从科研到应用，他们分享了对当下 Agent 系统能力边界的判断、未来演化路径的推测，以及一个重要而激进的问题：未来的模型，是否可能具备像科学家一样的“问题意识”，主动提出有价值的任务，并凭借自身能动性完成突破？

  

这是一场关于Agent的拆解，也是一场关于智能未来的对话。

  

![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdckRrrlDjs0euJL0BnQictynepEyXPAsNIIS22kMT8G4vkibUAXfOvmscshpB7BXoQEx34WHWrG1oaQ/640?wx_fmt=png&from=appmsg&randomid=rc3w4fgl&tp=webp&wxfrom=5&wx_lazy=1)

  

**【本期嘉宾】**

  

邢曜鹏 五源投资人（主持人）

黄柯鑫 斯坦福大学博士生 Biomni作者

谢云飞 莱斯大学博士生 ViGaL作者

张佳钇 香港科技大学（广州）博士生，MetaGPT 团队

  

***以下为播客内容的精选：***

  

  

**01 当前的Agent可以做什么**

  

**邢曜鹏:** 非常开心邀请三位来我们新一期的小酒馆，可以先请各位简单介绍一下自己的背景和目前在做的研究工作。

  

**张佳钇:** 我现在是在香港科技大学（广州）读博士一年级，同时也在MetaGPT公司参与研究工作，主要负责一个开源项目组织叫 Foundation Agents，围绕这个组织，我们做了一些开源项目和研究，比如 Foundation Agent、Open Manus，以及在推进的一系列Automating Something相关的工作。最近我主要带领团队在做 agent 的环境训练和形式探索，大概有 5、6 篇论文在同步推进。

  

**谢云飞:** 我刚刚本科毕业，下半年将前往 Rice University 攻读PhD。最近这半年在研究基于规则的强化学习，怎么跟多模态大模型结合。我们刚做了个实验，让 agent 通过 RL 学会玩贪吃蛇， 结果它的数学和推理能力明显提升，且训练过程中完全未使用数学样本， 效果是传统 SFT做不到的。我接下来还会继续在 RL 和 agent 应用这块探索。

  

**黄柯鑫:** 我是柯鑫，我现在是在Stanford计算机系读第四年的PhD，我一直都是做AI加生物医药方向。之前做过 biological foundation model，最近两年主要在研究 AI agent 怎么参与科学发现。我们刚发布了一个叫 biomni 的通用生物医药 agent，也在做环境搭建和 RL，目标是让它真正具备 AI 生物学家的能力。

  

**邢曜鹏:** 关于agent行业里面其实也有很多的争议和非共识，首先也想问一下 **站在今天的这个时间，各位是怎么定义agent？能不能讲一下你们对它的定义以及思考？**

**张佳钇:** 我们大概从 2023 年开始正式讨论基于大模型的 agent 架构。我们那时候把 agent 分成三个层次：底层是语言模型等基础单元，中间是连接这些单元的结构，最上层是整个系统的行为逻辑。当时讨论最多的是怎么把这些组件“拓扑式”组合起来。

  

后来我们意识到，光有语言模型还不够，它得有足够的“空间感”和“自我调度”能力，才能变成一个真正意义上的 agent，然后通过自主沟通的机制形成 autonomous mutli agent system 。当然，这类系统目前更多还停留在 simulation层面，真正能解决实际任务的还不多。

  

我们现在在做的 foundation agent，是希望它能拥有和人类类似的“环境等级”——也就是能适应不同的环境规则。如果 agent 能像人一样跨环境行动，我们就可以给它一个通用的协议，让它逐步演化成一个现实世界中的 agent 网络。说到底， agent 这个词本身没有一个静态定义，我更认为它是一个动态演化的过程。

  

**谢云飞:** 我从强化学习这边补充一点，其实 agent 这个概念在大模型之前就已经存在，像 AlphaGo 就是典型的 RL agent：它能感知环境、做搜索、决策，也有记忆。但过去这些 agent 的决策能力都比较专一、局限。大语言模型出来之后，它本身就是一个强大的感知和决策网络。我们可以把 AlphaGo 这种“专家模型”换成更通用的大模型，让 agent 在更复杂的环境里解决更有挑战的问题。所以我对 agent 的理解更偏系统层面——大模型是其中更强大的“大脑”， agent 是围绕这个大脑搭建的一整套执行与反馈系统。

  

**黄柯鑫:** 我从另一个角度补充一下。最近很多人都在讨论“agency”，就是说，有些人为什么有 agency、有些人没有？agent 在某些领域，指的其实就是能主动完成任务的那个体，它具备意志、目标感——是 very intentional 的存在。

  

我们最终想要的 agent，说白了，其实是一个虚拟的人类。那人类的哪些特质能被 AI 复制？目前看来，环境是关键的第一步。只有 agent 能真实地处在环境中、与环境互动，它才算是有“agency”。未来也许还会出现意识、情感等能力，但就目前而言，我觉得 “ 能 用环境、在环境中学习和行动 ” 是对 agent 比较基础也比较标准的定义。

  

**邢曜鹏:** **过去一年有哪些技术或研究突破让你们印象深刻？未来又最期待什么能真正进入现实？**

谢云飞: 对我来说，最震撼的是 DeepSeek 的工作，它把 GRPO（基于规则的强化学习）这套方法跑通了。这在学术界展现出了很强的泛化能力，以前我们训练模型要依赖大量语料和预训练，现在只需要设计好环境和规则，就能让模型自己学。在工业界也是巨大突破，以前训练一个像订机票这样的 agent，要靠大量人工标注的数据，比如鼠标轨迹、按钮坐标，成本高又繁琐。现在只要搭建一个虚拟网页环境，设定清晰规则，agent 就能靠 RL 自主完成任务。这比传统方法高效太多了。

  

去年虽然也有很多大体量的 agent 数据集，但那种记录人类行为的数据收集方式没法 scale。而基于规则的 RL，可以让 agent 在标准化环境里无限跑，自主学习。我觉得它很可能会革新 agent 的训练方式。

  

**邢曜鹏:** 这个就引申出了一个话题，很多任务的reward没法量化，比如商业谈判这类复杂博弈。我们不可能像评分考试一样给 AI 每句话打分。现实中，人类的反馈经常是模糊的，比如“你这策略不行”或者“这提案不够好”，没有绝对的对错。AI 怎么从这些模糊信号中快速学习，是个很值得期待的突破方向。

  

**谢云飞:** 对的，基于规则强化学习是有局限性的，可能在一些场景，比如说我想买一个东西，判断任务是否成功有明确的规则。但面对更复杂的系统时，如何定义这些规则本身就是强化学习需要攻克的难题。

  

**黄柯鑫:** 过去一年最让我震撼的还是 AI 的推理能力，尤其是在科学应用这个方向。早期虽然能看到一些 scientific knowledge 被写进了 ROM（只读内存），但光有知识远远不够，很多任务依然无法完成。我当时参与的 oo series 项目，能明显感受到：同样的任务，随着模型推理能力的提升，AI 解锁了很多原本难以实现的应用场景。这或许不算震撼性的突破，但它确实是一个持续推进的过程。比如一年前 Future House 还只是发表了关于科研流程的论文（literature research workflow），很多人觉得跟 ChatGPT 没什么区别。但这一年能看到，AI 已经开始完成一些真正有经济价值的科学发现任务。

  

这个变化背后，其实是很多因素共同推动的：底层模型的知识库更大了，推理能力变强了，强化学习框架也开始引导模型做更复杂的任务……这些组合起来，让“AI 科学家”这个概念慢慢变得现实。我觉得这是一个“渐进但实质”的进展，挺震撼的。

  

**邢曜鹏:** 这个事情我自己也挺有体会的。我们平时也会接触很多想用 AI 做科研的创业者。以前看他们的材料很吃力，现在用o3来分析、推理他们背后的技术逻辑，其实已经能帮助我们快速理解了，学习门槛降低了不少。

**那你们用过哪些 agent 产品，让你们印象比较深刻？**

**张佳钇：** 我用得最多的是 Cursor和Claude Code这类code工具。对我来说，一个好的 AI 工具要能长期帮我完成实际任务，而不仅仅是一次性的“回答问题”。除了写代码，它也能处理一些日常杂活，比如我会下载很多 PDF，但不想手动整理，它就能自动帮我分类、归档，这点还挺实用的。

  

另外像 OpenAI和Gemini的DeepResearch产品，我更倾向用它来做入门总结，尤其是在我完全不熟悉的领域。它能快速整理出几百个相关链接，覆盖广、效率也高，有时候比我自己查还快。

  

**谢云飞：** 我和佳钇差不多，也主要用一些 code 工具。现在的很多 agent 看起来很炫酷，但离真正能融入我的工作流还差得远。大多数成功率不高，实际效率也不一定好，有时候等它跑半天，最后还失败了，又得重试，体验挺糟糕的。反而是 code agent 这类，真的能提升生产力、带来直接价值。

  

**黄柯鑫：** 我也是 Cursor重度用户，尤其是做代码相关的任务确实帮了不少忙。身边做生物学的朋友最近也开始用它，虽然目前大多用在一些基础任务上，但能看出来已经开始融入他们日常的科研工作了。像云飞说的，更复杂的任务还没法完全靠 agent，但趋势是明显的，大家都在慢慢学着怎么把这些工具用起来，真正落地在科研上。

  

  

**02 通用Agent的瓶颈、边界与探索**

  

**邢曜鹏:** 这是个挺有意思的现象。我们每次和有科研或技术背景的人交流，发现他们其实不太用市面上那些通用型 agent 产品，真正愿意花时间的，还是 coding 工具。我们自己测试过很多通用 agent，有同事会让它们做比如特斯拉的 DCF 估值分析，结果看起来炫酷，内容却经不起推敲。

  

所以在专业场景下，code agent 的能力是被认可的；而通用型 agent 更多是在应对“交差式任务”时表现不错，比如帮你写一份八十分的报告、缓解职场焦虑，确实也有市场。但真要进到某些垂直领域，还是要靠那些环境和工具扎实的产品，才能带来真正的效率提升。

  

这也引出一个问题—— **现在这些通用 agent 的能力瓶颈还很多。你们怎么看？未来它们的能力该怎么演化？有没有可能真正解决 coding 之外的高价值任务？**

**张佳钇:** 我的看法是这样的，现在很多做通用 agent 的公司，都面临一个关键难题：如何构建数据飞轮。虽然他们没明确说自己在做这件事，但通常会强调通过用户点击等行为数据训练 browser agent。但我认为问题的核心不是数据采集方式，而是 agent 的能力阶段。

  

目前 agent 主要有两类功能：信息整理和信息生成。像 Deep Research 能在整理环节带来帮助，但真正决定用户体验的，是生成——不仅要生成对的内容，还要生成用户觉得“顺眼”的形式。这方面目前缺乏有效的反馈机制，也没有统一标准。比如我们做网页产品时，模型可以实现功能，却无法判断什么是“好看”。像美感、简洁度这些人类直观感知的元素，agent 目前无法捕捉。

  

所以我们尝试从用户意图出发，结合行为数据训练自己的模型，在生成阶段优化结构与美感。本质是解决“生成的内容是否像人做的”这个问题。

  

**谢云飞:** 佳钇说得挺好的，我也有类似的感觉。现在的这些agent，它们有能力去完成任务，但离“做好”还有很大差距。比如生成的网页虽然功能完备，却看起来很丑，像玩具一样，用户很快就会放弃。我们现在还需要给 agent 写很详细的需求说明，它才能产出勉强满意的结果。但真正理想的，是用户只说一句话，它就能一次性做出出色成果。

  

这个转变就像 GPT-3 到 GPT-3.5 的过程，前者只是“能用”，后者才开始变成真正的生产力工具。今天的通用 agent 还没迈过这个门槛，必须靠大量数据、系统优化和工程积累，去解决大量 corner case。

  

**黄柯鑫:** 我们做的是科研领域的 vertical agent，也遇到类似挑战。关键问题有三点：第一，知识储备不够。很多生物和医学资料在付费墙后，模型训练时根本接触不到。第二，缺少高质量工具和实时反馈机制，难以支持 agent 完成有经济价值的复杂任务。第三，缺乏领域内的“常识”。比如最近一个任务，agent 的方案基本正确，但专家指出一个小错误，而那个错误恰恰至关重要。这类细节错误目前很难避免。所以，尽管 UI 等体验也重要，但决定 agent 是否真正“有用”的，还是它是否能达到 expert-level 的专业能力。

  

**邢曜鹏:****未来如果想为用户提供专业个性化的体验，哪些部分应在模型层优化，哪些又需要在模型之外的系统层面构建？这两者之间的边界又该如何划分？**

张佳钇: 我自己的理解是，如果让我从头搭一个偏通用、能跨环境的 agent 系统，我会先明确“模型”和“系统”这两个概念——它们之间其实是有清晰界限的。但“模型”和“agent”的界限反而没那么明显。现在很多模型已经能完成一部分自主任务，因此单靠“能完成任务”这一点，已经不足以区分它是不是 agent。

  

在我看来，模型就是模型，核心职责是 提供基础智能（intelligence） ，特别是理解环境中的 动态（dynamics） 。我可能会选择一个基础模型（base model），可以是开源的，也可以调权重，在这个模型基础上，再接入一个 learning system——它能根据数据或环境反馈，不断调整模型或系统本身。

  

所以整个系统可以拆成两部分：一是可微调或固定的基础模型，二是负责执行的外部系统。learning system 则起到桥梁作用，通过环境或用户数据不断学习、调整执行策略。换句话说，模型层提供智能和对环境的理解，而系统层负责 contextual awareness——知道在什么环境下做什么样的适配与处理。很多学习任务可能发生在系统层，但其对象依然是模型本身。

  

**谢云飞:** 刚刚提到“边界”和“个性化体验”这两个关键词，让我立刻想到推荐系统。相比之下，现在的 agent 系统在用户反馈机制上其实很薄弱。比如 GPT 虽然允许你对回答点赞或点踩，甚至有时提供两种回复让你选择哪种更好，但大多数时候用户根本懒得点——我就是这样。如果回答不满意，我可能直接关掉，或者换个 agent，而不是留下反馈。

  

推荐系统就不一样，它天然可以通过 A/B 测试对比不同算法的效果，用数据指导优化。但 agent 目前几乎没有类似机制。虽然我们能做 pre-training、也能在上线前 fine-tune，但一旦上线之后，如何根据真实用户的使用行为进行后续优化，这一点做得很有限。

  

更进一步说，不同用户与 agent 的交互风格差别其实非常大。有的人喜欢写清楚每一个细节、一步到位，有的人偏好多轮对话、反复精修（refinement）。prompt 长短、复杂度、节奏也都不一样。但 agent 现在还不够敏感，无法真正适配这些差异。

  

所以我觉得， 如何动态适应不同用户的互动偏好， 也是 agent 当前的一大挑战。这不仅是产品问题，更是系统边界与能力边界的问题。

  

**黄柯鑫:** 刚才其实提到了一个很关键的问题——agent 本质上依赖于 environment 和 base model。这也是我一直在思考的事。比如像 Claude 或 ChatGPT 这样的通用平台，如果未来要支持开发某些垂直领域的 agent，那它们要怎么做？

  

因为很多 vertical agent 都严重依赖特定环境，而这些环境往往是高度专门化的。如果你想让一个 agent 在这样的 specialized environment 中运行得好，就需要先构建出这个环境本身。也就是说，在每个垂直领域，Claude 或 OpenAI 都要提供一个与之匹配的 environment，然后系统才能基于这个环境去采集数据、训练模型。

  

这让我觉得特别有意思的一点是， environment 和 base model 是一个共演（co-evolve）的过程。 而且大家也知道，environment 本身不是静态的，尤其是在科学发现这种变化极快的领域：今天最好用的工具，可能明天就过时了。那如果你只在某个时间点训练了一个 base model，它怎么才能跟上知识演进？如何实现 continuous learning，或 continuous agent adaptation？这其实引出了很多值得探讨的问题。

  

比如最近他们推出的 artifacts，就是专为网页开发设计的一个轻量级环境。但如果像 Dario 设想的那样，未来要做一个 “virtual biologist”，那就需要一个为生物学量身定制的环境。而这个环境可能非常复杂，还需要一个庞大的团队长期维护。所以我认为，agent 要真正进化，关键在于 environment 和 base model 如何协同演化，这决定了 agent 的适应力与长期价值。

  

**邢曜鹏:** 刚才大家其实也提到，这背后既是技术问题，也是商业问题。随着智能持续进化，agent 很可能会深入各个行业，届时模型和环境之间或将形成一种更明确的分工协作关系。比如，有些 environment 是为 base model 自我迭代设计的，而从商业效率出发，有些则更适合服务特定的垂直领域。还有一些被大厂忽视的细分环境，反而可能被创业公司用来获取精准反馈、打磨体验。

  

以我们在多模态领域的观察为例：这几年，不少导演和创作者从技术角度认可 GPT 4o或 Flux 的出图能力，甚至觉得它们已经非常逼真。但现实是，三年过去，很多艺术创作者依然首选 MidJourney——因为它在审美风格上的细腻与个性化，是其他工具尚未具备的。这就像小公司在某些专注方向上做深做透，反而能在巨头没重视的场景中站住脚，背后也是一场值得关注的商业博弈。

  

如果智能体继续演进，正如不少研究者提出的，未来也许不能再用固定 benchmark 去评价模型和 agent，而需要构建一种新的“环境+反馈”体系，让 agent 在任务中不断获得激励和优化机会。

  

  

**03 从执行任务到发现问题，Agent 还有多远？**

  

**邢曜鹏：** **你们觉得，未来模型能不能像科学家那样，主动提出有价值的问题，并凭主观能动性设计出更优质的任务？**

**谢云飞：** 我觉得可以分两类。一类是增量式的问题，基于现有知识稍作组合或推理，比如文献综述后发现的新角度，这类现在的 agent 基本能胜任。因为定义清晰、搜索空间明确，通过组合和概括就能找到。

  

但另一类问题就更难了，更像文学创作，靠灵感、直觉，是那种“从没被问过”的问题。这种问题的提出背后是科学品味和价值判断，这部分我觉得 agent 还不具备。

  

所以现在 agent 能在已有知识边界上提出一些问题没问题，但想提出颠覆性、突破性的创见——还挺难的。

  

**张佳钇：** 我挺认同云飞的说法。我们现在做的一些事，其实就是在已有思想和结构上做延展推理，这不完全依赖模型本身的知识深度，更重要的是引导它沿着有价值的路径提问。很多时候，是我们在人群协作中提炼出连贯的模式，agent 只是辅助去补全它。

  

**黄柯鑫：** 对，我觉得大家讲得很好。agent 是能提出问题的，但我们更关心它能不能提出特别好的问题。就像诺奖级的科学发现，和我们日常提出的小问题，差别就在于复杂度和跳跃跨度。

  

有些问题只需要一次跳跃就能关联起来（single-hop reasoning），但真正有突破的问题，可能需要上百步推理（multi-hop），越复杂、越远的逻辑链，对 agent 的要求越高。而在像生物这样的领域，光靠推理还不够，必须有实验反馈形成闭环。很多重大成果，其实都是“推理—实验—再推理”的长周期过程。

  

所以未来如果真出现一个 agent 提出诺奖级发现，大概率是它在一个复杂环境里独立运行很久，通过多轮反馈才形成真正有创造性的问题。不是不能实现，但这类高质量问题的产出，一定是稀缺的，不可能批量生产。 问题不在于“能不能问”，而是“能不能问得好”。

  

**邢曜鹏：** 今天大家其实也提到一个评估智能进展的思路——我们可以通过模型或 agent 能够持续独立思考和推理的时间来判断其能力是否在提升，比如从一分钟延长到一小时，未来也许能持续思考一年，做推理、做实验，而且不会因为干扰因素而“跑偏”。但我也很好奇， **这种进步是随着 testing scaling 的推进自然发生的吗？还是说它背后还有很多未解决的挑战，不管是作为 researcher 还是 engineer，都需要投入大量时间去攻克？**

**张佳钇：** 我认为这需要专门设计和解决，不太可能是能力“自然涌现”。就像我刚才说的 scanning，虽然听起来像是在主动探索问题，但其实很大程度还是人类提出 idea、设计路径。每个研究者的推理风格和思维方式都不同，所以我们还需要很多工程化工作来引导，比如限定它按某条路径进行思考，或者用特定方法深化推理过程。

  

**谢云飞：** 是的，简单说就是：如果让一个 agent 长时间持续思考，它真的能把问题解决掉吗？就目前来看，基于 autoregressive 架构的大模型，本质上是逐词生成内容的概率模型——每个词的生成都依赖于前面词的概率分布。这种方式很容易出现“累积误差”：只要中间某一步错了，后面就会越走越偏。

  

所以在这类模型中，test-time scaling（测试时扩展）并不一定意味着性能提升，甚至可能因为误差积累导致结果更糟。

  

但我们也看到了希望，比如 diffusion-based 架构的语言模型就很有前景。它不是一个词一个词地输出，而是以更全局的方式更新一整段文本，更容易控制整体生成的连贯性和正确性，或许能解决 autoregressive 的一些固有局限。

  

**黄柯鑫：** 我也很同意。人类文明不是靠某个单一的 LLM 一口气完成复杂推理演化出来的。它更像是一个模块化（modularized）系统，通过层层结构叠加演进的。

  

所以如果我们希望 agent 执行一项长达一年的任务，肯定不只是靠一个 LLM，而是需要一个 multi-agent system，或者是一个能不断积累知识、持续组织信息的 agent system。它每天做结构化的任务，不断记录和优化，而不是靠一次性输出完成全部。

  

在这个过程中，最大的挑战可能是 context engineering ：怎么管理长时间任务中的上下文？如何协调海量知识和观察结果的组织与调度？这就像建一家真正的公司，不可能靠一个人搞定，而需要有分工、有结构、有协作的系统，才能完成复杂而长线的目标。

  

  

**04 顿悟、转向、未来**

  

**邢曜鹏:** **你们在做 AI 研究的过程中，有没有经历过什么灵光一现的 “aha moment”？**

**张佳钇:** 我真正开始搞科研是从大四才开始的——前三年基本都在混日子，还忙着学生会的事，成绩也不理想。大四为了保研才开始补科研技能。我记得第一个“aha moment”是在写我的第一篇完整论文的时候，大概是 2024 年 9 月下旬到 10 月初之间。当时没人帮我改稿，我写得特别绝望。那一刻我突然意识到：科研这件事，最终只能靠自己。你的论文，你的思路、执行、推理，必须自己负责，老师和老板也帮不了你。从那一刻开始，我对科研的认知发生了很大的转变。这种顿悟不是来源于某个新颖的 idea，而是对“科研主体性”的一种深刻体会。

  

**谢云飞:** 我现在回想，觉得可以讲讲我们工作里的一个“aha moment”。我们曾训练一个 agent 玩贪吃蛇游戏，原本目标只是优化它在游戏中的表现。但后来，我们试着将这个 agent 放到一些数学任务上做测试，结果惊人地好——它在泛化能力上甚至优于基础模型。而且，它从未见过任何数学数据，训练完全基于游戏。

  

很多人问我们，为什么想到要把游戏智能体应用到数学任务上？其实一开始我们也没这个想法。我甚至有点抵触这个项目，觉得“玩游戏”的研究太小众。但转折点是，我突然意识到：我更在意的是通用能力。于是我临时起意，去测试它在通用任务上的表现，结果效果出乎意料。所以对我来说，这种“aha moment”并不是某种神来之笔，而是长期关注通用智能和推理之后自然产生的延伸尝试。

  

**黄柯鑫:** 我也能分享一个经历。我差不多七八年前就开始做科研了，一直聚焦在AI加生物医药这个方向。刚开始的前四五年，我主要在build a foundation model for biological data。这中间有个“aha moment”。当时我们发表了一项成果后，我和一位生物学家聊天。那时我们正在开展另一个合作项目，项目里有个基础的生物数据分析任务，他让我帮忙处理一下。我当时有点偷懒，就说：“要不我让我的agent来处理吧。”

  

等agent处理完，我把结果拿给这位生物学家看。他当时的反应，虽说不至于尖叫，但能明显感觉到他特别惊喜，觉得这东西能立马派上用场。他还说，原本得让他的一个学生花三四个月才能完成这项工作。从那时起，我就意识到这个智能体具有显著的经济价值和实用价值。

  

这和我之前做foundation model for medicine时的情况截然不同。以前我把那些成果拿给生物学家看，他们顶多说一句“very cool”，就没了下文，这种差别对待特别明显。就在那一刻，我感觉到，这个智能体具备真正的实用价值和经济价值。从那时起，我坚定地转向“agent + biology”这个方向。

  

**谢云飞：** 我还是科研新手，现在正处在技术和论文爆炸的时代。但我更希望自己能坚持下去，不受环境干扰。我给自己设的十年目标是：做出几篇踏实、solid 的研究成果，用这些成果作为支点，推动一个小领域的进步。 在这个浮躁的时代里，不焦虑、不盲目追热点，是我希望坚持的初心。

  

**张佳钇：** 我给自己设的是三年目标：在毕业那年，build 一家属于自己的公司。无论是被收购还是还在运营，只要曾经存在过，它就是我的一个锚点。如果非要说十年后的愿望，那就是： 我创办的这家公司，能对世界产生一些积极影响。

  

**黄柯鑫：** 我想成为那种 mission-driven 的人。我的梦想是，十年后，生物学家每天醒来，不再是手动设计实验，而是打开我们平台，查看 agent 昨晚完成了哪些工作，再指挥它们执行新的任务。 科学研究的方式可能迎来几百年来的第一次变革，从人工执行走向智能体协作。 我想参与并推动这场变革——它既深刻又有趣，也许能改变科研的根本方式。我希望十年后能为此留下自己的一笔。

  

![图片](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdfM1NOXofxQuToSZ0mTRF6SOaKsoF4TySiaNOfnXicwnY3v5tvWu1FClVSEUPKKETq73euD0PHPhAvA/640?wx_fmt=png&from=appmsg&randomid=ny4xhjj4&wxfrom=5&wx_lazy=1&tp=webp) ![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdckRrrlDjs0euJL0BnQictynQhlwnh9wMgfllkAQGUHricz4GZbsVHWPsDfKVQjmMbRQpZobhetpyww/640?wx_fmt=png&from=appmsg&randomid=n18894ha&tp=webp&wxfrom=5&wx_lazy=1)

[![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdeibVJaBMSOJtV04439pia9nichC3RMibd1OoianFJvx9mkgcsuYh7QslPnXpx75w8meYWDx5jsGKL7Bkg/640?wx_fmt=png&from=appmsg&randomid=aik2kylf&tp=webp&wxfrom=5&wx_lazy=1)](https://mp.weixin.qq.com/s?__biz=MzkwMDI2ODE0OQ==&mid=2247502655&idx=1&sn=dbd7ef5d8c7d70b192debae242204791&scene=21#wechat_redirect)

  

  

![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdckRrrlDjs0euJL0BnQictync2Vlg4VibTDpyCmqkzhtcpKV5YZC6Bibu1mINFx5RRHqDEPf8jSZd2uw/640?wx_fmt=png&from=appmsg&randomid=ejzcfhvb&tp=webp&wxfrom=5&wx_lazy=1)

  

五源寻找、支持、激励孤独的创业者，为其提供从精神到所有经营运作的支持。我们相信，如果别人眼中疯狂的你，开始被相信，世界将会别开生面。

  

BEIJING·SHANGHAI·SHENZHEN·HONGKONG

WWW.5YCAP.COM

  

![Image](https://mmbiz.qpic.cn/mmbiz_png/uB3CQ3SCbdckRrrlDjs0euJL0BnQictynETnKLIPT27ddh9q9dJdDg1GSoKvJppEEFw0PfW3B1TjmibzmvTibVhaQ/640?wx_fmt=png&from=appmsg&randomid=rfpkjtc0&tp=webp&wxfrom=5&wx_lazy=1)

继续滑动看下一个

五源资本 5Y Capital

向上滑动看下一个