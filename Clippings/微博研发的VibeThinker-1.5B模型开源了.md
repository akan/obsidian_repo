---
title: "微博研发的VibeThinker-1.5B模型开源了"
source: "https://mp.weixin.qq.com/s/ZirCqMLR0GwIOOhW3IgM2Q"
author:
  - "[[高效码农]]"
published:
created: 2025-11-12
description: "一、 引子：AI世界的“以大为美”魔咒你可能听说过，现在的AI圈子，流行一个近乎狂热的理念——“大即是美，大即"
tags:
  - "小模型逆袭"
  - "推理能力突破"
  - "成本效益显著"
abstract: "微博开源的VibeThinker-1.5B小模型通过创新的SSP训练方法，以极低成本在数学推理任务中超越参数量大400倍的巨头模型，打破了AI领域'大即是美'的魔咒。"
---
Original 高效码农 *2025年11月12日 14:29*

![Image](https://mmbiz.qpic.cn/mmbiz_png/1ZuBzWHu8OGypRoYGjP5e6eOUW4nuOHGWsvawSliax0xqfGaWElW2UyapSd9ZFw4FJcoics0EKTQcdrTAyaKJ73w/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

## 一、 引子：AI世界的“以大为美”魔咒

你可能听说过，现在的AI圈子，流行一个近乎狂热的理念—— **“大即是美，大即是强”** 。

这就像一个武林神话：想要拥有绝世武功（比如，强大的逻辑推理能力），你的内力（参数规模）就必须深厚到令人发指。

我们看看那些顶尖高手的数据：DeepSeek R1的参数规模高达6710亿，而Kimi K2更是突破了1万亿。在这样的背景下，行业内形成了一个根深蒂固的 **共识** ：小模型天生就是个“陪跑的”，别指望它能有什么强大的推理能力。这种观念，几乎成了AI领域不可撼动的“缩放定律”——模型越大，能力越强。

但是，今天的故事，就是要打破这个“大模型”的迷信。

想象一下：一个身材精瘦、体重只有150斤的选手，在短跑比赛中，不仅紧追那些体重超一吨的巨无霸，甚至在几个关键回合里，直接冲线夺冠。你是不是会好奇，这“小个子”到底吃了什么秘密药方？

这个“小个子”就是我们今天要深扒的主角： **VibeThinker-1.5B** 。它是一个只有15亿参数的密集型模型。是的，你没听错， **15亿** 。当别人在玩“万亿”的时候，它只用了零头的零头。更让人震惊的是，在最硬核的数学推理基准测试中，它成功超越了参数量大它 **400多倍** 的DeepSeek R1初始版本。

这不仅仅是“励志故事”，这是AI领域一场革命性的方法论胜利。它告诉我们一个颠覆性的事实： **强大的逻辑能力，不一定非得靠堆砌资源来实现。**

## 二、 秘密武器解密：从“广撒网”到“信号塔”（SSP原理）

VibeThinker-1.5B能实现“小体格，大智慧”，靠的不是运气，而是一套极其精妙的后训练方法论，我们称之为—— **“从频谱到信号原理”（Spectrum-to-Signal Principle, SSP）** 。

这个原理，完美地解释了VibeThinker如何跳出传统AI的思维定势。传统的训练模式，往往像一个急躁的猎人，一枪出去就想命中靶心。但SSP的设计者说： **慢点，我们先来一场大规模的“头脑风暴”！**

SSP把训练过程分成了两大步，环环相扣：

### 1\. 第一步：广开思路，构建“解题频谱”（SFT阶段的变革）

在传统的监督微调（SFT）阶段，模型的主要目标通常是追求 **“首次通过率”（Pass@1）** ，即一次性给出正确答案的概率。

但SSP在这里做了本质上的调整，将SFT定义为 **“频谱阶段”** 。

**什么是“频谱”？** 想象一下，一个难题摆在面前，传统模型只会给出一个它认为最有可能的答案A。而VibeThinker在“频谱阶段”，会被训练成一个超级能发散思维的解题能手。它会生成：答案A、答案B、答案C、答案D……它提供了一个 **广泛的、多样的、充满可能性的“解决方案集”** 。

这种能力，是通过一种叫 **“两阶段多样性探索蒸馏”** 的技术实现的。它的核心思想是： **与其逼着模型一次答对，不如鼓励它多提方案** 。即使有些方案最终是错的，也没关系，因为这片“解决方案的海洋”，将为下一步的优化提供无比肥沃的土壤。

### 2\. 第二步：智慧聚焦，放大“正确信号”（RL阶段的精髓）

有了第一步生成的“频谱”，我们就进入了SSP的第二阶段—— **“信号阶段”** ，也就是强化学习（RL）阶段。

这一步的目标非常清晰：在刚才那片“解决方案的海洋”里，识别出最正确的、最具效率的推理路径，并给它一个 **超强的信号放大器** ，确保下次它能以更高的概率被选中。

这个“信号放大器”背后的核心技术，就是 **“最大熵引导的策略优化框架”（MaxEnt-Guided Policy Optimization, MGPO）** 。它像是给模型请来了一位“最有智慧的教练”。

#### （1） MGPO的核心技术（A）：自己人评自己人（GRPO）

在传统的强化学习中，你需要一个 **外部的、独立的“批评者模型”（Critic）** 来评估模型的每一次尝试，这个批评者往往很昂贵、很难训练。

VibeThinker-1.5B用了一种更巧妙、更经济的方法，叫 **“群组相对策略优化”（Group Relative Policy Optimization, GRPO）** 。

**怎么理解？** 想象一下，你做了一套试卷，得到了五个不同的解题思路（五个响应）。GRPO不是请一位外部专家来打分，而是让这五个思路 **互相比较** 。它基于这群“自己人”的平均分和波动（标准差 和 ），来计算每个解法有多大的 **相对优势** 。

这种“内部裁判机制”，不仅让优势值的估算 **方差更低、更稳定** ，而且 **彻底消除了对外部批评者模型的依赖** 。这一下子就省下了巨大的计算资源和训练成本！

#### （2） MGPO的核心技术（B）：只挑最难的学（熵偏差正则化）

这位“智慧教练”最厉害的地方，在于它的“挑题”眼光。它不会平均用力，而是把学习的资源和权重， **最大程度地集中在那些模型“最摇摆不定”的问题上** 。

这就是 **“熵偏差正则化”（Entropy Deviation Regularization）** 。

在信息论中，“熵”可以理解为“不确定性”。

- 如果模型给一个问题的答案是99%对，1%错，它的熵就很低，因为它很有把握，学到的东西不多。
- 如果模型给一个问题的答案是51%对，49%错，它的熵就很高，因为它“非常纠结”，正处于“似是而非”的瓶颈期。

MGPO的策略就是：它会计算模型的 **“最大熵偏差距离”** ，即模型实际的准确率 与理想的 **最大不确定状态** 之间的差距。 **差距越小（越接近50%），说明这个问题对模型最有挑战性，最有学习价值。**

于是，模型就会把最强的训练信号，集中到这些“临门一脚”就能攻克的瓶颈问题上。这极大地提高了 **学习的针对性和效率** 。

通过SSP的这两大步，VibeThinker-1.5B成功将 **多样性（广度）** 和 **高效聚焦（深度）** 完美结合，最终打造出超乎体量限制的逻辑推理能力。

## 三、 数据说话：1.5B的“逆天”战绩

方法论再精妙，最终还是要看疗效。VibeThinker-1.5B的跑分结果，堪称AI界的“黑马逆袭”。

### 1\. 数学推理：400倍巨头的“尴尬时刻”

在AI领域，数学推理任务被公认为是逻辑和泛化能力的最苛刻试金石。VibeThinker-1.5B在三大高难度基准测试中，直接让一众巨头感受到了压力：

| 模型名称 | 参数量 | AIME24得分 | AIME25得分 | HMMT25得分 |
| --- | --- | --- | --- | --- |
| **VibeThinker-1.5B** | **15亿 (1.5B)** | **80.3** | **74.4** | **50.4** |
| DeepSeek R1-0120 | 6710亿 (671B) | 79.8 | 70.0 | 41.7 |

**划重点：**

- **反向超越：** 在AIME24、AIME25和HMMT25这三个代表性数学测试中，VibeThinker-1.5B的得分 **全部超越了** 参数量是它400多倍的DeepSeek R1初始版本。尤其是HMMT25这个高难度测试，VibeThinker以50.4分的成绩，甩开DeepSeek R1（41.7分）一大截。
- **硬刚商业模型：** 它的推理能力与GPT OSS-20B Medium等开源顶尖模型 **不相上下** 。更厉害的是，它在AIME24上拿下了80.3分， **显著高于** 国内流行的Kimi K2-Instruct（69.6分），甚至在逻辑推理上表现 **优于** 一些专有闭源模型（Magistral Medium和Claude Opus 4）。
- **自身的飞跃：** 相比它的“底子”（基座模型Qwen2.5-Math-1.5B），VibeThinker-1.5B简直是脱胎换骨。AIME25得分从 **4.3分** 狂飙到 **74.4分** ，HMMT25得分从 **0.6分** 暴增到 **50.4分** 。这说明，SSP方法论对模型能力的激发是 **颠覆性** 的。

### 2\. 编程能力：小而精悍的“代码工匠”

在LiveCodeBench V6编程基准测试中，VibeThinker-1.5B同样展现了强大的竞争力，因为它逻辑推理强悍，解决代码难题自然得心应手。

- 它的得分为 **51.1** 分， **略高于** 闭源模型Magistral Medium的50.3分。
- 与参数量相近的开源模型Qwen3-1.7B（26.9分）相比，VibeThinker-1.5B的 **优势是压倒性的** 。

这再次证明，在需要复杂逻辑的编程领域，精妙的算法设计能让小模型爆发出惊人的潜力。

## 四、 真正的价值：打破AI世界的“贵族垄断”

VibeThinker-1.5B的价值，远超几个测试分数。它最深刻的意义在于，它正在重新定义AI研究的 **效率与公平** 。

### 1\. 成本：从“天文数字”到“人人都玩得起”

“大模型”最大的问题，就是 **烧钱** 。训练一个巨型模型，成本高得吓人，普通公司和大学根本玩不起。我们来看一组令人咋舌的对比：

| 模型名称 | 参数量 | AIME25得分 | GPU小时 | **总成本** |
| --- | --- | --- | --- | --- |
| MiniMax-M1 | 4560亿 (456B) | 74.6 | 258K | **53.5万美元** |
| DeepSeek-R1 | 6710亿 (671B) | 70.0 | 147K | **29.4万美元** |
| **VibeThinker** | **15亿 (1.5B)** | **74.4** | **3.9K** | **7,800美元** |

**请注意最右边一列：**

- MiniMax-M1的训练成本是 **53.5万美元** ，约合人民币 **三百多万元** 。
- VibeThinker-1.5B的 **后训练总成本仅为7,800美元** ，约合人民币 **五万多元** 。

**两者在AIME25上的分数几乎持平（74.6 vs. 74.4），但成本差距是天文数字般的** **68倍！**

这意味着什么？这意味着以前只有拥有数十亿美元预算的科技巨头才能玩的“大模型竞赛”，现在，一个中小型企业、一个优秀的AI实验室，甚至是一位拥有几张高端显卡的个人研究者，也能以 **极低的成本** 参与到最前沿的推理能力研究中来。

### 2\. 公平：将AI研究带回校园与社区

对模型参数无休止的追求，已经造成了AI研究的“贵族垄断” **。最顶尖的研究资源和话语权，被集中在少数几家拥有海量计算资源的公司手中。这无疑会** 边缘化\*\*许多拥有优秀人才但缺乏硬件支撑的大学和初创企业。

VibeThinker-1.5B的成功，就是在这种垄断的高墙上，凿开了一个口子。它证明了 **“巧思”可以战胜“蛮力”** 。

它在数学、代码和科学任务中展现出的强大逻辑推理能力，是用 **精妙的算法设计** 换来的，而不是堆叠昂贵的硬件。这种低成本、高性能的模式，将极大地 **拓宽AI研究的参与度** 。

当更多人能够以更低的门槛参与到AI模型的开发和优化中，整个行业的技术进步速度只会更快。这不仅是成本效益的胜利，更是 **AI研究民主化** 的伟大一步。

## 五、 理性看待：小模型的“知识”边界在哪里？

当然，我们不能因为VibeThinker在推理上表现出色，就认为它全面碾压了万亿参数巨头。 **体积的限制，依然是客观存在的。**

如果说逻辑推理能力是“智商”，那么广泛的知识储备就是“见识”或“阅历”。

### 知识库的先天不足

为了公平地衡量模型在处理 **广泛、百科全书式知识** 和 **高难度专业知识** 方面的能力，研究人员使用了 **GPQA-Diamond** 基准。这是一个包含198个博士级别的生物、物理、化学问题的研究生级测试。

数据显示：VibeThinker-1.5B与当前的领先模型之间，在GPQA分数上 **存在20到40分的显著差距** 。

- VibeThinker-1.5B的GPQA得分是46.7分。
- 它的基座模型Qwen2.5-Math-1.5B得分只有16.4分（说明后训练有提升，但底子薄）。

**怎么理解这个差距？** 15亿参数的模型，就像一个逻辑能力极强的“数学天才”，但他的脑容量毕竟有限，无法像万亿参数模型那样，把整个互联网上的百科知识、历史文献、专业资料都“背”下来。

在处理那些需要 **海量、跨领域、记忆驱动** 的专业问题时，小模型仍然会显得力不从心。

### 对未来的启示：扬长避短，专项突破

这个知识上的差距，恰恰给未来的研究指明了方向：

1. **继续强化专业能力：** 既然小模型能以超高性价比实现强大的逻辑推理，那么在细分领域（如金融分析、垂直医疗诊断、特定语言翻译）的 **专用小模型** ，将是极具前景的方向。
2. **融合与协作：** 未来小型模型可能不会孤军奋战，而是与大型知识库（RAG）或知识图谱结合，让\*\*“聪明的大脑” **（推理能力）去高效利用** “巨大的图书馆”\*\*（知识库），实现能力互补。

研究人员也坦诚，VibeThinker的基座模型主要在数学数据上进行预训练，对代码的接触有限，如果能进一步强化基座模型的代码基础能力，它的综合性能还会被显著提升。这说明， **小模型的潜力，远未被挖掘殆尽。**

## 总结：AI的未来不只是“大”

VibeThinker-1.5B的横空出世，是一声响亮的号角。它以 **15亿** 参数， **7,800美元** 的成本，以及对超大模型的 **反向超越** ，向世界证明了：

**在AI领域，算法的“深度”和“巧劲”，完全可以弥补参数“广度”的不足。**

它所依仗的 **SSP原理** （广撒网与精筛选），尤其是 **MGPO框架** （内部裁判与聚焦瓶颈），为我们提供了一条全新的思路： **与其盲目追求规模，不如精雕细琢方法。**

这场由VibeThinker发起的“小模型”逆袭，不仅为追求成本效益的企业带来了曙光，更关键的是，它让AI技术的进步不再是少数巨头的专属游戏。它正在把AI的舞台，重新还给所有富有创造力的研究者和开发者。

AI的未来，不只是“大”，它更需要 **智慧、高效和普惠** 。VibeThinker-1.5B，就是这场新浪潮的第一个弄潮儿。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

作者提示: 个人观点，仅供参考

继续滑动看下一个

高效码农

向上滑动看下一个