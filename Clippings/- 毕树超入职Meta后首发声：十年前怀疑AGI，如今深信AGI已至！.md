---
title: 毕树超入职Meta后首发声：十年前怀疑AGI，如今深信AGI已至！
source: https://juejin.cn/post/7532169341590241330
author:
  - "[[新智元]]"
published: 2025-07-29
created: 2025-07-31
description: Meta超级智能团队成员毕树超，回溯70年AI进化：从AlexNet掀起深度学习革命，到Transformer与Scaling Law驱动大模型爆发，再到强化学习＋预训练通向AGI。
tags:
  - Meta
  - AGI
  - 强化学习
  - 预训练模型
  - AI进化
abstract: 就算被困住，这些「局部极小值」其实离全局最优根本不远！所以现在没人再纠结非凸优化问题了。
---
![横幅](https://p9-piu.byteimg.com/tos-cn-i-8jisjyls3a/8c759ddb57d0440986f4768fc644f879~tplv-8jisjyls3a-2:0:0:q75.image)

[新智元](https://juejin.cn/user/952600743642312/posts)

70 阅读13分钟

![](https://p3-piu.byteimg.com/tos-cn-i-8jisjyls3a/b37ce6cd3dfa46f699d8fc9c7c888f2f~tplv-8jisjyls3a-3:0:0:q75.png)

##### 【新智元导读】Meta超级智能团队成员毕树超，回溯70年AI进化：从AlexNet掀起深度学习革命，到Transformer与Scaling Law驱动大模型爆发，再到强化学习＋预训练通向AGI。他相信智能并非人类都独有，AGI曙光已现！

加入Meta超级智能实验室后，毕树超首次发声：大多数人可能低估了AI的影响！

十年前，他非常怀疑AGI，但在过去十年中，他逐渐接受了AGI，日渐笃定，甚至宣称：2025，AGI已来。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/3cbc126ba6c748769f25b86fb6751efc~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=zVopTXxi91B8KoXQsMeHY8ZnEgM%3D)

上个月，他在哥伦比亚大学和哈佛大学就人工智能发表了两次演讲。

许多参加的人都后来联系他，声称这次演讲改变了他们的AI观念。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/5a7bd46d18fa4b1486540ce5ca37b70a~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=u6pwYNHMkET0MvnJXUhsbHTdScs%3D)

在题为《推进硅基智能前沿：过去、开放问题与未来》的演讲中，毕树超系统阐述了过去15年的技术进展、当前待解难题以及未来发展趋势

目前，他在Meta从事强化学习/后训练/智能体研究。之前，他在OpenAI领导多模态研究；他还是YouTube Shorts的主要负责人。

他本科从浙江大学数学专业毕业，之后在加州大学伯克利分校获得统计学硕士和数学博士学位。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/d4c5468e600742bc8ba6cc2daae66c73~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=eGH%2BFO5FVbfnpz7GPwgwpEc%2BpDk%3D) **AGI曙光**

最近，David Silver等人发表了《Welcome to the Era of Experience》。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/f55afd06d7fa455590ec7b5bdf5ed8a5~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=wuwfRFFGir6CIiCt4ntaF1snOV8%3D)

他们的核心观点是：高质量的人类数据非常稀缺。

尽管人类文明已有几千年，但真正积累的高质量数据并不多，而且大部分文本快消耗殆尽。

所以问题是：如何生成更多的数据？

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/8c7d823b2f194203b2d431007859761f~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=wrzlmN43oqMnfzDlhdxI3qK6kFI%3D)

答案可能在于人类本身。人类的数据来源于人脑的思考，以及从真实环境中获得的反馈和奖励。

算力正在变得越来越廉价，计算机与环境的交互或许可自动生成新的知识与数据。这种方式将可能比人类自身产生数据的速度更快。

这也是为什么毕树超如此看好通用人工智能（AGI）和超人工智能（Artificial Superintelligence，ASI）的原因。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/e36db0c35c2b48c3bf01c1ad78a9bcbe~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=F8isEUvbDgmt7HVGY42Io%2FBMOl0%3D)

他分享了个人对AGI研究的心路历程。

一开始对通用人工智能持怀疑态度，因为这个领域存在大量炒作。

对他个人来说，最大的障碍是他曾坚定地相信：人脑是特别的，人类智能是独一无二的。

毕竟，目前许多技术，从数学角度来看，只不过改进了Tensor运算和梯度优化，本质上并不复杂。他不禁怀疑：人类真的那么难以复制吗？

但随着对AI理解的加深，他开始意识到：模拟人脑的方式不止一种。如果能够用计算机模仿人类的学习方式，那为什么不这样做呢？

这就是他如今更加相信AGI的原因：

一方面，也许大脑并不是独一无二的，它只是生物进化的结果。虽然复杂，但归根结底它也不过是一台「生物计算机」，并不比硅基计算机更神秘。

另一方面，也许真正关键的因素不是结构的复杂程度，而是系统是否具备足够的规模。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/76e27a13a3534b50bbd2a8eb7e6616a2~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=vMcXtuKElBogLVabkr8ImGkYBkU%3D) **AI双城记**

在哥伦比亚大学，他追溯了人工智能（AI）的思想根源。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/c933ae5c83c84b7ea14038264fbded08~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=%2F5z8IpuEr7DxSpMPqYiXaS9N4aU%3D)

这一切都始于1948-1950年左右。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/8a0b43507b4f4b67acf43055d0470e4d~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=K72meOCa7ayRnlC9TN3HGUraYfo%3D)

当时，Alan Turing提出了一个问题：机器能思考吗？

图灵提出，人工智能不应试图模仿成人的大脑（包含复杂的经验和偏见），而应设计一个简单的模型，尽量减少人为预设的结构，让模型通过数据自主学习。

毕树超对观众说：「这正是机器学习的核心。你构建一个几乎不含人类先验知识的系统，让它从数据中学习。」

他重点讲了自监督学习和强化学习。

他回顾了自监督学习、深度网络以及像Transformer这样的里程碑式架构的兴起。

他展示了计算能力和数据规模的提升（而非人工编码的知识）如何带来性能的飞跃。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/8f4a7b7a594f4d51ac04516eafc3042f~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=%2BkWaumqPFW%2BF6HXXayFVpVhO7QA%3D) ![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/906360f0216e4f6d9ee1531571bec2d4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=FWfClWF5wB6thUzppDZhtCIa0VE%3D) **自监督学习**

2012年，出现了AlexNet。

基本上可以说，这是第一个大规模深度学习模型，使用了GPU和大量数据。

AlexNet错误率令人惊叹，性能之好史无前例。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/f936ff4a59b54e0d9ff7c5df8617b78d~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=D8Ye2DBCybN2PSqI4PWW%2Bj78yNI%3D)

从中，大家得到了一个启示：只要有足够的数据和计算能力，神经网络就会超越人类过去几十年手工设计的视觉算法。

在当时，对于从事视觉研究的研究人员来说，是一场灾难，几十年付诸东流。

这重新唤起了人们对神经网络的兴趣，深度学习革命开始了。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/5a1a37bd66594abfbbfe46a392f866f3~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=cGaCU5rJ1sWWSETcdbJnx93vDmo%3D)

大多数人认为2012年标志着深度学习革命的开始。

然后到了2013年，谷歌发表了Word2Vec。

简单来说，「Word2Vec」用一个嵌入向量，来表示单词。

从此，单词可以进行算术运算，比如「king-man=queen-woman」。

向量运算竟然能捕捉语义关系！更关键的是，这些词嵌入在下游任务中表现惊人。

这引发了另外两个趋势：

（1）Word2Vec演变到一切皆可向量化（everything2Vec）。

（2）强化了计算+数据的优势，这种结合远比归纳偏差表现要好。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/1fb624e80372494b9e370c12e42d2b47~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=aobr%2B8yEhPQFotoTiZx5t2N8QG8%3D)

这回应了图灵的设想：我们不想模拟成人的大脑，这意味着我们不希望在模型中加入人类的归纳偏差。

2014年，生成模型GAN出现了。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/f2c2b68818a64ea1be8480e801a9f523~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=lRhATYC6weAr91z6u8WIXpAEqZU%3D)

GAN在生成领域石破天惊，但与自监督学习关系不大

2015年，深度学习「加速器」Adam优化器已经诞生了，开始流行。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/9e467fef0041482783bd9ab97262b452~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=vFcYrNPNEc%2FFixY790kGdipYIaU%3D)

它标准化了训练流程，终于不用再手工调参了！特别适合处理海量数据和稀疏梯度，直到今天大多数优化器都是Adam的变种。

同年的ResNet更是神来之笔！

当时深层网络训练就像走钢丝——梯度要么消失要么爆炸。而ResNet的「跳跃连接」（skip connection）就像给神经网络装了电梯：浅层特征可以直接跨层传输。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/9d63b158334e4a66991f3643c3ceaad5~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=SNNDHgfvk8CWZf8abK4kNhV%2ByfI%3D)

残差连接让优化变得非常容易：右图(a)没有残差连接时崎岖不平，(b)引入残差后如瓷碗一般平滑。

如果采用这种结构，可以确保学习起来容易得多。而且这种技巧几乎适用于所有网络架构。这就是为什么现在几乎所有网络都采用这种结构。

不过当年，很多数学背景的人都质疑过深度学习中的这类技巧。

**![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/149c42b4e0764f60b07adb16fe0f64d4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=Hug7YQAAK3zrMU4HaSIUUrUhaDc%3D)**

**豁然开朗**

演讲的前一天，毕树超和物理教授聊天才意识到：在低维空间建立的统计直觉，在万亿参数的高维空间根本不适用！

原因是大家都生活在低维空间中，低维度的直觉难以推广到高维空间。

毕树超花了好几年才克服了这些错误的直观。

他之所以困惑一大原因在于深度神经网络需要的是非凸优化（non-convex optimization）。

当处理非凸优化时，首先担心是陷入随机的局部最小值。如果最好的结果不过是随机的局部最小值，怎么能信任结果呢？然后，有很多关于这个的研究。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/fbb52e4a0729447cb558c866e7d55264~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=trohrEap6BqHoSbpbanQcPHTOeo%3D)

让他重拾信心的第一个发现是：在高维空间里，陷入局部最优其实非常难。在三维世界看二维曲面时，局部极小值确实像深坑难爬出来。但在十亿维空间里，有无数个逃生通道！

第二个发现更妙：就算被困住，这些「局部极小值」其实离全局最优根本不远！

所以现在没人再纠结非凸优化问题了。

那再说个更颠覆的现象——过参数不会带来过拟合。

在传统的统计分析领域中，如果参数数量大于数据点数量，那是一场灾难。从理论上讲，这会导致过拟合。

但深度学习模型参数动不动就是样本量的百倍！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/b8a17f4c420043fbbd6fb44c09b8338c~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=15DL%2F0wuT6KJakpafUAwHTHzjX0%3D)

作为数学统计双背景的人，这曾让他困惑不已、夜不能寐...

直到发现：即便用随机标签训练，网络也会优先学习真实模式，

这就是著名的「双下降现象」：当过参数化模型达到插值点后，会进入广阔的零损失解空间，并自动选择泛化性最优的解。

现在，终于可以说：过参数化不是bug，是feature！

**![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/8dd5401a119d49808ed468ed90d65e89~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=pbBg37ktRYk%2BYv0Wdjy%2FytxaRlI%3D)**

**ChatGPT前传**

2014年，出现了第一篇关于注意力机制的论文。

从2014年到2016年，当时的主要挑战是，这些模型很难并行训练，以及梯度消失。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/c3a3069275e948c3ac672d517219da6a~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=vqKIsI%2FFYso5dgGrkFGsFjbjzi8%3D)

LSTM有所帮助，但也没有完全解决问题。

然后，Transformer就出现了。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/79b502e547764678a2bbce4d57b7b7f2~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=zfV7H892jfagSQf7665jbKhmtu0%3D)

这是过去十年中最重要的论文之一。它完全消除了递归，完全依赖于自注意力。

Transformer是一个转折点，优雅地解决了之前的局限性。

毕树超盛赞：「这是过去十年最重要的架构。它高度可并行化、数据效率高，并且扩展性极佳。」

2018年，出现了GPT-1。2019年，出现了GPT-2。2020年，出现了GPT-3。

毕树超认为GenAI的本质通用性（generalizable）。

以前，只要有数据，每个领域都可以构建一个专门的模型。这并不具备可扩展性。而GPT系列模型非常通用，可以通过零样本或少样本学习完成任务。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/0328e0451f414f359a41f14b2b4c1d66~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=HeuqLdpsd9ozIkt2P%2F1BzMMjODk%3D)

2020年，Scaling Law论文揭示惊人规律：算力、参数量、数据量每增加10倍，损失函数就线性下降！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/3914bfc7d485450aaa6e1516108d5d7d~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=WrKBI31Y3jx9MP5L5cfuVNG5Ay4%3D)

这个定律精准预测了GPT-4的性能。虽然它终将触及天花板，但在此之前，10万亿美元级的算力投入都将持续获得回报！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/f25a7e64434c472a832e51f541fd7323~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=BKEFdmyey9WSymSecg4xNguPJuk%3D)

这也是《The Bitter Lesson》这篇雄文的核心：70年AI史就是「算力碾压人类精巧设计的算法」的历史！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/23defa5d9cc2414e84b3acc244cf25d6~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=yrsU1cySNfk%2BFHq09LrWdVwELS4%3D)

当然，作为数学系毕业生的毕树超总在追问scaling的源头——或许答案藏在数据分布的本征结构中。

**![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/580067d077b646c0bd55750c60b252cb~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=F%2BPqjk12XkS%2B4payKRCVoCq84lM%3D)**

**Scaling Law如何让模型顿悟？**

看看数据分布：顶尖医生解决罕见病，普通医生处理常见病；

算术书籍浩如烟海，代数几何专著却凤毛麟角。

智能的分布恰如幂律曲线！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/2e3a2248eac74d21befc8bc13e57fe6e~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=TldB1oUrUXYELrhP4ciP9qeFBSo%3D)

Scaling law的本质或许在此：每挖掘高一个数量级的「智能稀有度」，就需要十倍算力投入！

这解释了为何模型总先学通用模式。

三年前，全网争论的「能力涌现」，其实只是幂律数据遇到对数坐标的视觉把戏！

当算力突破临界点，AI「突然」学会微积分不过是捕获了数据长尾中的高阶模式！

这只是一个视角问题。它并不是突然出现的，它实际上只是反映了底层数据。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/2465a41e657a4accb099cdeeed59b1c4~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=Tv4W9v54PoJAQKle%2FGiPktX8JY4%3D)

Ilya有一句名言：「模型只是想学习。」

Transformer架构终于让AI回归本能：吃数据，吐智能！。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/a895525e6fb04a16b128b880ac620a33~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=7AH4Jyav66QQ4yC6ShuvKcJkM0w%3D)

过去十年，我们逐渐打破了很多对机器学习的误解。如今，主流观点是：预测本身的压缩，其实等同于理解，甚至是智能的体现。

从信息论的角度来看，Shannon把「信息」定义为「不可预测性」。「智能」可以理解为：让这个世界变得越来越不让你感到惊讶的能力。

从这个意义上看，大语言模型在预测下一个词时，其实是在压缩语言中的各种模式。这正是人类理解世界的方式之一。

从认知科学的角度，人类的学习过程本质上也是压缩过程。物理定律、数学公理等方式把世界的观察总结成最小的一组规则。

因此，从信息到学习，从预测到理解，「压缩」是背后共同的核心逻辑。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/82a8b5a30fa84040be7f5ec5444f027d~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=yKWEWzuRo7dDVhjtAl9NUWofG6A%3D) **强化学习**

整个深度强化学习从2015年开始。

当时，出现了DQN网络。它可以玩多种雅达利游戏，玩得比人类好多了。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/dfb3a1615f9a4906be3bd33e3ef8e8c6~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=RXt5qyr7zPu0r9nH1K%2Bm8BAkYAM%3D)

这些模型发现了很多人类想不到的策略，因此人们称之为「外星智能」（alien intelligence）。

真正的核爆点在围棋上。AlphaGo的表现让人们第一次意识到：「这些模型真的有智能。」

AlphaGo起初是从人类棋谱中训练起来的，它结合了深度神经网络、、自我博弈（self-play）和蒙特卡洛树搜索（Monte Carlo Tree Search），最终击败了世界冠军。

到了2017年，AlphaGo Zero出现了。模型进一步升级，完全不再依赖人类数据，所有训练都来自自我对弈，堪称「AI界周伯通」！

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/da5a99508cad4adbb18f92c17e91f00c~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=e28HV0VzHkiqNZXdoeGXn8vVSxs%3D)

2018年，AlphaZero再进一步。

2019年，强化学习扩展到了电子游戏，比如《星际争霸》。

但这股热潮很快退却了，因为人们发现：AI虽然能「打游戏」，却在现实中没有太大用处。

直到强化学习与预训练模型结合，这一切才真正发生了变化，开启了「预训练与强化学习结合的新时代」。

**![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/c364fad97274491bab11ed1e6d0d4714~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=tR6qW1XocE8s9t5r3R4kD2fUhoM%3D)**

**低算力RL\*\*\*\*比如2022年的InstructGPT，它让大语言模型不仅仅是「自动补全工具」，而是能够理解和执行人类指令。** ![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/482edb01159144cb9dfa6b6c2daa1040~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=zFMrEC9FugfWf9ZN8muF9xE%2BMuU%3D)

而2022年发布的ChatGPT，更是通过强化学习（特别是人类反馈强化学习，RLHF）进一步提升了交互能力。

当时，这个项目只是John Schulman等人的一个低调研究预览。谁曾想，它如今每周有超过5亿用户使用，彻底改变了人们获取信息的方式。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/dc1ecc9bbd9742dab89a678ac081dbb8~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=1XqoKXJ3s4QYRUe%2BLdtGcHLmfi0%3D)

但仔细一想，这跟之前提到的「游戏里的强化学习」到底有什么不同呢？

强化学习+预训练模型，可以应用到现实中更广泛、更有价值的场景中。

关于当前AI模型的训练方式，强化学习所占的计算资源比例其实非常小，就像蛋糕上点缀的樱桃。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/2a20f7fafaee4241bb35dc9ffd3a667e~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=76PNsFMsCwq5TXXeGYTkN8cPsWQ%3D)

但未来如果要构建真正的AGI乃至ASI，强化学习必须发挥更大的作用，尤其是在适应未知环境方面。

**![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/9825d6d3e0f0425babe972209ab10a78~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=9n%2FQAl4fRcqLelklWaSSnRK0yqA%3D)**

**高算力RL**

在过去六七十年的AI发展中，有两类技术最能随着算力增长而不断进步：

- 「学习」：也就是预训练；
- 「搜索」：通过策略探索获得新解。

而「搜索」这一方向，目前还远远不够好。

这也是为什么我们要进入AI发展的「第二阶段范式」：让预训练与高计算量强化学习真正结合起来。

从2014年的o系列模型开始，这种趋势已经出现。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/fdcb9d900df74f99beec85387ed5d133~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=5Fxans7NxvMGHmDMfgXfjMQovIw%3D)

在数学基准上AIME中的表现，开源的DeepSeek R1已经超过o1。

![图片](https://p6-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/fdf64417d8a24c3e95264582f7c9cd87~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg5paw5pm65YWD:q75.awebp?rk3s=f64ab15b&x-expires=1754361070&x-signature=ga%2F8C5N0mSntiz4WcN6Yp3npfVI%3D)

这并不是一件简单的事，它代表了全新的计算范式：「高算力RL」。

这种范式然显著增强了模型的「个体学习」能力。

虽然问题还有很多值得探索，但毕树超在演讲中表示：「每隔几个月，我们就看到一些曾经被认为不可能的事情成为现实。这应该让我们重新审视所有我们仍然认为不可能的事情。 」

也许很多我们以为的不可能，其实只是知识的局限。

参考资料： [youtu.be/E22AOHAEtu4…](https://link.juejin.cn/?target=https%3A%2F%2Fyoutu.be%2FE22AOHAEtu4https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7336814222590341120%2Fhttps%3A%2F%2Fx.com%2Fshuchaobi%2Fstatus%2F1949493389894058487https%3A%2F%2Fwww.engineering.columbia.edu%2Fabout%2Fnews%2Fexploring-past-and-future-ai "https://youtu.be/E22AOHAEtu4https://www.linkedin.com/feed/update/urn:li:activity:7336814222590341120/https://x.com/shuchaobi/status/1949493389894058487https://www.engineering.columbia.edu/about/news/exploring-past-and-future-ai")

评论 0

![avatar](https://p6-passport.byteacctimg.com/img/user-avatar/596dd11ec1eb86109467f46963b9da45~100x100.awebp)

0 / 1000

暂无评论数据

为你推荐

- [OpenAI 计划推出 GPT-4o 语音模式，开启无缝 AI 语音聊天｜AGI 掘金资讯 7.29](https://juejin.cn/post/7396609176745279526 "OpenAI 计划推出 GPT-4o 语音模式，开启无缝 AI 语音聊天｜AGI 掘金资讯 7.29")
		[新的一周开始啦，给酱酱们带来 AGI 掘金 的今日热点资讯啦，欢迎阅读交流哦！ OpenAI 计划推出GPT-4o 语音模式，开启无缝 AI 语音聊天…](https://juejin.cn/post/7396609176745279526)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 2.6k
	- 4
	- 评论
	![OpenAI 计划推出 GPT-4o 语音模式，开启无缝 AI 语音聊天｜AGI 掘金资讯 7.29](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/7c07ccfc72bf4ba9accbf3e895b7ad95~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=JU7KdLGyGHZzpVEJUUu%2BREV7hCw%3D)
- [四面楚歌，奥特曼妥协了！OpenAI 公布重大公司调整，放弃成为营利性公司](https://juejin.cn/post/7500874757707202587 "四面楚歌，奥特曼妥协了！OpenAI 公布重大公司调整，放弃成为营利性公司")
		[刚刚，OpenAI 终于放弃成为营利性公司！CEO Sam Altman 的理想主义又回来了：我们想为世界打造一个大脑，并让人们能够非常轻松地用它来做他们想做的任何事情。](https://juejin.cn/post/7500874757707202587)
	- [
		新智元
		](https://juejin.cn/user/952600743642312)
	- 1.4k
	- 8
	- 5
- [半数清华，8 位华人 AI 天团集体投奔 Meta！奥特曼：砸钱抢人不如培养死忠](https://juejin.cn/post/7523519254878437403 "半数清华，8 位华人 AI 天团集体投奔 Meta！奥特曼：砸钱抢人不如培养死忠")
		[硅谷挖角戏码升级！相比 Meta3 亿美元「血本挖角」，OpenAI 来了波反向操作——选择培养人才，奥特曼悄然推进一个名为「驻留计划」（Residency Program）的项目。](https://juejin.cn/post/7523519254878437403)
	- [
		新智元
		](https://juejin.cn/user/952600743642312)
	- 556
	- 7
	- 4
- [奥特曼秀5颗草莓疯狂暗示GPT-5？匿名新模型神秘现身，数学超强！](https://juejin.cn/post/7400578173926834187 "奥特曼秀5颗草莓疯狂暗示GPT-5？匿名新模型神秘现身，数学超强！")
		[【新智元导读】 奥特曼又来搞事情了！一张5颗草莓照片，让全网掀起热议狂澜。这不是明摆着暗示，神秘Strawberry项目真实存在。难道GPT-5真的要来了吗？\*\*\*\* 或许，GPT-5真的不远了。今天](https://juejin.cn/post/7400578173926834187)
	- [
		新智元
		](https://juejin.cn/user/952600743642312)
	- 193
	- 点赞
	- 评论
- [无需开颅，瘫痪患者也能控制数字设备了！GPT-4o mini 登顶大模型竞技场背后的秘密｜AGI 掘金资讯 7.30](https://juejin.cn/post/7397024981580775436 "无需开颅，瘫痪患者也能控制数字设备了！GPT-4o mini 登顶大模型竞技场背后的秘密｜AGI 掘金资讯 7.30")
		[酱酱们上午好，给大家带来 AGI 掘金 的今日热点资讯啦，欢迎阅读交流哦！ 无需开颅，瘫痪患者也能控制数字设备了！GPT-4o mini 登顶大模型竞技场背后的秘密…](https://juejin.cn/post/7397024981580775436)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 3.1k
	- 4
	- 评论
	![无需开颅，瘫痪患者也能控制数字设备了！GPT-4o mini 登顶大模型竞技场背后的秘密｜AGI 掘金资讯 7.30](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/bb139bc5d7ff45fba723f8d564ba0018~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=mJPr2RWbiVERx9BEW%2BAKj%2B%2F4N%2FM%3D)
- [网友已玩疯：Midjourney V6.1 和摄影几乎没区别；周鸿祎突然宣布：360 安全大模型免费！｜AGI 掘金资讯 8.1](https://juejin.cn/post/7397676488295546916 "网友已玩疯：Midjourney V6.1 和摄影几乎没区别；周鸿祎突然宣布：360 安全大模型免费！｜AGI 掘金资讯 8.1")
		[酱酱们中午好，给大家带来 AGI 掘金 的今日热点资讯啦，欢迎阅读交流哦！ 网友已玩疯：Midjourney V6.1 和摄影几乎没区别；周鸿祎突然宣布：360 安全大模型免费…](https://juejin.cn/post/7397676488295546916)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 3.8k
	- 9
	- 评论
	![网友已玩疯：Midjourney V6.1 和摄影几乎没区别；周鸿祎突然宣布：360 安全大模型免费！｜AGI 掘金资讯 8.1](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/f59f9f7ced68410aa5a219f0b9d8890a~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=HS3L3qZs2d3fHOjZuz5VyKU9t1Y%3D)
- [AGI 掘金资讯 7.23｜马斯克：特斯拉 Optimus 机器人计划 2026 年量产销售](https://juejin.cn/post/7394366490394607651 "AGI 掘金资讯 7.23｜马斯克：特斯拉 Optimus 机器人计划 2026 年量产销售")
		[今日份 AGI 掘金热点资讯｜马斯克：特斯拉 Optimus 机器人计划 2026 年量产销售；大模型时代结束，小模型的崛起？Llama 3.1 泄密…](https://juejin.cn/post/7394366490394607651)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 154
	- 4
	- 评论
	![AGI 掘金资讯 7.23｜马斯克：特斯拉 Optimus 机器人计划 2026 年量产销售](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/ddb9257e8fe6450a9529f023289f5442~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=ePT5NzbC1XFdxdtaKBxtUgVyjTk%3D)
- [刚刚，OpenAI放弃营利性转型！奥特曼：非营利组织继续掌控，AGI造福全人类使命不变](https://juejin.cn/post/7500425545563373605 "刚刚，OpenAI放弃营利性转型！奥特曼：非营利组织继续掌控，AGI造福全人类使命不变")
		[OpenAI 终于「妥协」了。 最近，OpenAI 向营利性公司的倾斜遭到了很多人的诟病，尤其是马斯克。他曾于 2024 年 2 月在加州法院起诉 OpenAI 及 CEO 山姆・奥特曼，指控其背离了](https://juejin.cn/post/7500425545563373605)
	- [
		机器之心
		](https://juejin.cn/user/1873223543167902)
	- 135
	- 1
	- 评论
- [OpenAI掌门人Sam Altman：AI的下一个发展阶段](https://juejin.cn/post/7177279420678275127 "OpenAI掌门人Sam Altman：AI的下一个发展阶段")
		[就在大家以为今年OpenAI将以沉寂收场时，聊天机器人模型ChatGPT横空出世，让人们看到了AI的更大创造力，聚光灯也再度打到了OpenAI的身上。](https://juejin.cn/post/7177279420678275127)
	- [
		OneFlow一流科技
		](https://juejin.cn/user/220363785507309)
	- 1.6k
	- 1
	- 评论
- [谷歌推世界首个 AI 游戏引擎，2000 亿游戏产业恐颠覆！0 代码生成游戏，老黄预言成真｜AGI 掘金资讯 8.30](https://juejin.cn/post/7408463818952900662 "谷歌推世界首个 AI 游戏引擎，2000 亿游戏产业恐颠覆！0 代码生成游戏，老黄预言成真｜AGI 掘金资讯 8.30")
		[酱酱们中午好～今天的 AGI 掘金热点资讯来啦，我们知识库上线了 AI 小助手，欢迎来撩！谷歌推世界首个 AI 游戏引擎，2000 亿游戏产业恐颠覆！0 代码生成游戏，老黄预言成真…](https://juejin.cn/post/7408463818952900662)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 699
	- 5
	- 评论
	![谷歌推世界首个 AI 游戏引擎，2000 亿游戏产业恐颠覆！0 代码生成游戏，老黄预言成真｜AGI 掘金资讯 8.30](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/b580209774a54627bac3e29d5b807db2~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=iWEl8arcm18oWP9o%2FVh%2FW%2BL6%2Fg0%3D)
- [对话DeepMind创始人Hassabis：AGI、宇宙模拟与人类文明的下一个十年](https://juejin.cn/post/7530516153065504802 "对话DeepMind创始人Hassabis：AGI、宇宙模拟与人类文明的下一个十年")
		[AI Keymaker：对话DeepMind创始人Hassabis：AGI、宇宙模拟与人类文明的下一个十年 今天，著名播主Lex Fridman发布了与Demis Hassabis的深度对话，探讨了A](https://juejin.cn/post/7530516153065504802)
	- [
		AI\_Keymaker
		](https://juejin.cn/user/1303353321864601)
	- 54
	- 3
	- 评论
- [OpenAI 推出 ChatGPT 高级语音模式，Plus 用户已率先体验 GPT-4o 超逼真语音交互｜AGI 掘金资讯 7.31](https://juejin.cn/post/7397335019894177802 "OpenAI 推出 ChatGPT 高级语音模式，Plus 用户已率先体验 GPT-4o 超逼真语音交互｜AGI 掘金资讯 7.31")
		[酱酱们中午好，给大家带来 AGI 掘金 的今日热点资讯啦，欢迎阅读交流哦！ OpenAI 推出 ChatGPT 高级语音模式，Plus 用户已率先体验 GPT-4o 超逼真语音交互…](https://juejin.cn/post/7397335019894177802)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 2.4k
	- 6
	- 评论
	![OpenAI 推出 ChatGPT 高级语音模式，Plus 用户已率先体验 GPT-4o 超逼真语音交互｜AGI 掘金资讯 7.31](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/195b5cfd8af8429692bd395caafbbdc0~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=tw328yMi9DrH4EY0JDzdHbo8paI%3D)
- [刚刚，OpenAI 任命新 CEO！](https://juejin.cn/post/7501649258278682675 "刚刚，OpenAI 任命新 CEO！")
		[刚刚，OpenAI 迎来新 CEO。奥特曼发文称，Fidji Simo 将以「应用 CEO」全新身份加入 OpenAI，向他本人汇报。](https://juejin.cn/post/7501649258278682675)
	- [
		新智元
		](https://juejin.cn/user/952600743642312)
	- 120
	- 点赞
	- 评论
- [40 亿美金打造，马斯克亲自展示！特斯拉 Cortex AI 超级集群内部视频曝光｜AGI 掘金资讯 8.27](https://juejin.cn/post/7407385581078036517 "40 亿美金打造，马斯克亲自展示！特斯拉 Cortex AI 超级集群内部视频曝光｜AGI 掘金资讯 8.27")
		[酱酱们中午好～今天的 AGI 掘金热点资讯来啦，我们知识库上线了 AI 小助手，欢迎来撩！40 亿美金打造，马斯克亲自展示！特斯拉 Cortex AI 超级集群内部视频曝光…](https://juejin.cn/post/7407385581078036517)
	- [
		酱酱们的AI编程淘金
		](https://juejin.cn/user/2819602825362840)
	- 296
	- 4
	- 评论
	![40 亿美金打造，马斯克亲自展示！特斯拉 Cortex AI 超级集群内部视频曝光｜AGI 掘金资讯 8.27](https://p9-xtjj-sign.byteimg.com/tos-cn-i-73owjymdk6/70a8bbc6edef4b9fbbd27a83653eb3eb~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6YWx6YWx5Lus55qEQUnnvJbnqIvmt5jph5E=:q75.awebp?rk3s=f64ab15b&x-expires=1754556330&x-signature=8A9ATbjhBNg1b8opLSYuzte8QF4%3D)
- [奥特曼：再也不和小扎说话！OpenAI 偷袭小扎马斯克，反手挖 4 核心员工](https://juejin.cn/post/7524864401615847450 "奥特曼：再也不和小扎说话！OpenAI 偷袭小扎马斯克，反手挖 4 核心员工")
		[刚刚，OpenAI 反手就是一记王炸！奥特曼亲自下场，怒挖特斯拉、xAI、Meta 四名技术大牛，和小扎的混战中，马斯克也无辜躺枪了。](https://juejin.cn/post/7524864401615847450)
	- [
		新智元
		](https://juejin.cn/user/952600743642312)
	- 167
	- 点赞
	- 评论