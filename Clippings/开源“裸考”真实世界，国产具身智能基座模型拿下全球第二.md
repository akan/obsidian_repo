---
title: "开源“裸考”真实世界，国产具身智能基座模型拿下全球第二！"
source: "https://mp.weixin.qq.com/s/Wp9edClPZpu1H-mHJAyizQ"
author:
  - "[[关注前沿科技]]"
published:
created: 2026-01-09
description: "具身智能前沿发展，正由开源模型共同推动向前"
tags:
  - "具身智能"
  - "开源模型"
  - "机器人评测"
abstract: "国产开源具身智能基础模型WALL-OSS在RoboChallenge真机评测中取得全球第二的成绩，展示了其在真实物理世界任务中的强大能力。"
---
Original 关注前沿科技 *2026年1月8日 19:00*

##### 嘻疯 发自 凹非寺量子位 | 公众号 QbitAI

国产具身智能基座模型，再次突破！

RoboChallenge真机评测榜单上，来自 **自变 量机器人的 端到端具身智能基础模型WALL-OSS** ，以46.43分的成绩，超越美国具身智能明星公司Physical Intelligence的pi0 （π0） ， 总分 排名 全球第二 。

![Image](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAqFvhUzJ7gBb1xsEW1gXDmGqicSmluKqwq3Ml9wfqkK8plqMzdlia9hU89Thn9P8NciadIcm15qfJQw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

在叠洗碗巾、挂口杯、按按钮、浇盆栽、移物入盒、开瓶器进抽屉等 多个单任务中， WAL L-OSS均拿下 单项第一 。

![Image](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAqFvhUzJ7gBb1xsEW1gXDmicwlg9XthhlG8cze2bokw0qwLyyiaeZ6WHLpDHvDlQAIdM2EH0SgkWdA/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)

要知道，这可不是一场普通的测试。

RoboChallenge由Dexmal原力灵机联合Hugging Face发起，是首个在 真实物理环境 中，由真实机器人执行操作的大规模、多任务基准测试。

与LLM测评不同，具身模型测评更像是一场“ 开卷考 ”，任务描述和场景环境都是提前公开的。

参赛方无需提交模型权重，只需提供可驱动机器人的算法；最终，平台通过统一的真机执行，以动作视频和任务完成率作为评分依据。

格外关键的是， **WALL-OSS是一个开源模型** 。

相较于闭源模型的测评结果存在较大操作空间 *（其性能可能源于对第三方模型的微调、 接口层的特殊 适配，或者存在黑箱内的未公开优化）* ，模型本身的原生能力不容易被外界验证，开源模型的成绩建立在完全透明的代码与参数之上， 其能力可被任何研究者复现、检验和深入研究 。

而且，WALL-OSS的开源程度也相当彻底：不仅开放了预训练模型权重、完整训练代码和数据集接口，甚至还提供了详尽的部署文档。 **仅需RTX 4090级别的消费 级显卡 ，就可以完成从训练到推理部署的完整流程。**

另外，当前榜单前三名，包括 pi0、pi0.5，也都是来自开源体系 。  

具身智能的前沿发展，正在由开源模型共同推动向前 。

## “机器人脑”物理世界大PK

下面先具体来看WALL-OSS在测试中的实际表现。

RoboChallenge首发的Table 30任务集，包含30个真实日常操作任务，而在行业常见的真机评测中，任务数量通常只有3–5个。

该任务集从四个维度构建评估体系：VLA方案难点、机器人类型、任务场景环境、目标物体属性，覆盖了具身模型在真实世界中可能遇到的多样复杂情况。

以难度较高的“叠抹布”任务为例，WALL-OSS目前位列该单项第一。

在该任务中，WALL-OSS以41分的成绩领先pi0。尽管其任务成功率仍只有10%，但已是当前所有参赛模型中的最优表现；相比之下，pi0在该任务中的成功率为0%，仅获得部分步骤分。

![Image](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAqFvhUzJ7gBb1xsEW1gXDmqzAEtCMo2HGR9RI6JibJgZNQw2BbIUagkTylVibIrU9gj8l5ATSnve3w/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=2)

RoboChallenge平台集成了UR5、Franka Panda、Aloha、ARX-5等多款主流机器人，用于远程真机评测。

并且，其 公开了 所有 任务演示 数 据及测试中间结果 ，所有人都能看到机器人执行任务的全过程监控记录。

打开任务执行详情，可以看到左侧上方是多视角视频画面，展示了任务现场的实际场景， 能直观看到机器人的操作过程 。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

右侧上方的arm图表，记录了机械臂6个关节 （joint1–joint6） 的角度变化，曲线波动对应关节运动；右侧下方的arm\_gripper图表，则记录了夹爪的开合状态。

最右侧信息栏则展示任务ID、执行时长等基础信息。

底部时间轴可以精准定位某一时刻，同步查看该时间点的视频画面与机械臂/夹爪状态，快速找到动作异常的环节。

从公开视频中可以看到，WALL-OSS成功完成了抹布的一次抓取与对折操作：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

在相对简单一些的“连续按下三个按钮”任务中，WALL-OSS的优势更加明显，得分显著领先其它模型。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

实际操作be like （以下展示均为加速画面） ：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

在“将不同形状杂物收纳至筐中”的任务里，WALL-OSS同样表现稳定：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

该任务中，无论是得分还是成功率，WALL-OSS都高于pi0。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

在“拉开抽屉并放入杂物”等需要连续规划与空间判断的任务中，也能看到其完整完成操作流程：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

值得一提的是，RoboChallenge的真机测试规则本身并未限制模型进行针对性优化或微调。开发者可以使用官方提供的任务示范数据对模型进行训练。

模型训练完成后，需对接平台标准化API。平台提供统一的框架代码，参赛方仅需补充自身逻辑，确保模型实现观察-推理-停止的完整交互闭环，并可通过模拟测试进行验证。

评估请求进入人工调度队列后，任务将在真实场景中执行，最终结果由平台自动发布。

也正是在这样的规则下，开源模型的成绩，含金量才显得尤为突出。

目前，自变量团队已表示， WA LL-OS S提交 的复现结果示例，微调代码和模型权重也将在近期全部开源 。除检验测试结果的真实性，开发者们也可以在平台上根据源代码和各个任务的微调代码，结合自己的数据完成复现微调。

接下来问题来了，WALL-OSS是如何做到的？

## 拆解背后技术突破

在模型的具体实现层面，官方已发布技术报告，对WALL-OSS的设计思路与训练路径进行了系统披露。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

从视觉语言模型 （VLM） 走向视觉语言动作模型 （VLA） ，并不是一次简单的能力叠加。

在这一迁移过程中，行业普遍面临两大核心挑战：

其一是 灾难性 遗 忘 。VLM在向动作生成扩展时，往往会牺牲原有的语言理解与视觉推理能力，导致模型“会动了，却不再真正理解任务”。

其二是 模态解耦 。不少模型虽然表面上同时具备视觉、语言与动作模块，但各模态之间协同不足，推理、规划与执行往往割裂存在，难以形成真正端到端的决策闭环。

这也直接导致了一个现实困境：认知能力强的模型，动作精度往往不足；而动作控制表现稳定的模型，又难以承担复杂任务的理解与规划。

如何在模态统一、动作精度和能力泛化之间达成平衡？ 是VLA模型设计中最具挑战性的问题之一。

针对上述问题，WALL-OSS首先在模型架构层面进行了重构。

不同于传统多模态模型常见的“模块拼接”方案，WALL-OSS采用了 共享注意力+专家分流 （FFN） 的架构设计。语言、视觉与动作信息被嵌入到同一表示空间中，通过共享注意力机制实现深度跨模态交互；同时，再借助专家FFN对不同任务需求进行高效分流计算。

最终，模型得以在统一框架下同时承担理解、规划与动作生成任务，形成紧耦合的认知—行动闭环。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

在训练策略上，WALL-OSS设计了 “ 启发 阶段 （Inspiration） →整合阶段 （Integration） ”的阶段式范式 。

启发阶段通过具身VQA、指令跟随等任务强化空间推理，结合FAST tokenization离散动作训练，让模型保留原有认知能力的同时，建立空间与动作基础认知。

随后，整合阶段聚焦连续动作建模，先冻结VLM仅训练Action FFN下的流匹配 （Flow Matching） 头，精修高频动作生成。

最终，解冻VLM联合优化，将认知能力与动作执行能力在同一模型中稳定整合。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

这种“ 先离散、后连续、再联合 ”的训练路径，让VLM的语言视觉能力能够无损地迁移并扩展到物理动作层面，避免了传统端到端训练中常见的能力塌缩问题。

结果是，模型既保留了懂任务的认知深度，又具备了会执行的动作精度。

在此基础上，WALL-OSS进一步将思维链 （Chain-of-Thought） 能力内化到具身决策过程中。

WALL-OSS构建了一套 统一的跨层级思维链框架 ：从指令理解，到中间推理，再到子任务拆解与规划，最终映射为连续的物理动作执行。

这一机制使模型能够在高层语义决策与底层动作控制之间自由切换，在同一可微分框架内完成跨抽象层级的推理与执行。

因此，在面对未知环境或从未见过的任务组合时，WALL-OSS不再依赖预设流程，而是能够自主拆解问题、逐步思考，并在执行过程中动态调整策略，从而具备了承担长程、复杂具身任务的能力。

实验结果显示，在Embodied VQA基准测试及6类机器人操作任务中，WALL-OSS均表现突出。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

## 开源破壁，真正推动具身智能发展的路径

最后再来介绍一下WALL-OSS背后的团队—— 自变量机器人 。

这是一家成立时间不长、但在具身智能领域推进速度极快的明星公司。核心团队长期深耕机器人与多模态智能方向，并明确将“通用具身智能基座”作为长期目标。

创始人兼CEO王潜 ，本硕毕业于清华大学，后在美国南加州大学攻读博士，从事Robotics Learning相关研究。他在神经网络注意力机制相关研究领域较早开展探索，是较早将Attention思想引入神经网络体系的研究者之一。

联合创始人兼CTO王昊 ，为北京大学计算物理博士，曾任职于粤港澳大湾区数字经济研究院 （IDEA研究院） ，担任大模型团队负责人，曾带领团队发布过多个开源大模型，在基础模型与系统工程层面具备深厚积累。

目前团队已完成多轮融资。几个月前，刚宣布了 近10亿元A+轮融资 ， 阿里云、国科投资领投，国开金融、红杉、渶策、美团、联想之星、君联资本均有参与。

相比单一场景或垂直应用，自变量团队更关注 如何构建一个可以被反复验证、持续演化 的“机器 人通用大脑” 。

也正因为如此，WALL-OSS从一开始就被定位为面向真实物理世界、端到端统一的基座模型，而不是为某个Demo、某个任务定制优化的解法。

如果仅从榜单成绩来看，WALL-OSS已经足够亮眼。但真正值得被反复讨论的，并不是名次本身，而是它选择 以开源的方式，参与真实物理世界的能力验证 。

在RoboChallenge这样的第三方测评中，WALL-OSS的表现很难被简单归因为调参、特化或运气好。它更像一次赤裸而直接的证明： 一个开源的、可复现的具身基础模型，确实可以在真实世界任务中具备很强的竞争力 。

而把视角拉远一步，长期以来，具身智能领域一直存在一个结构性矛盾：

真正有想法、有算法能力的高校与中小团队，往往缺算力、缺数据、缺机器人；而具备资源的大公司，又很难把底层能力完全开放出来，供行业共同验证和改进。

在这样的背景下，一个可以在消费级显卡上完成训练、推理和部署的开源具身模型，在行业中的意义就不仅是共享成果，而是弥补了行业空白，实质性地 降低整个行 业的创 新门槛 。

研究者不必从零构建，创业团队不必重复造轮子，更多精力可以投入到真正有价值的问题上，比如：如何提升泛化能力？处理更长程、更复杂的任务？如何让机器人在不可控环境中更可靠地工作？

这正是开源生态最理想的状态，不是把精力消耗在基础设施的重复建设上，而是 在同一个高起点上竞争真正的创新 。

正如自变量机器人联合创始人&CTO王昊曾在硅谷101播客中所说：

> 我一直都觉得开源是非常重要的事情， **开源意味着我们可以站在巨人的肩膀上继续前进** 。我们可以基于已有成果做更多的改进，社区开发者的反馈也会帮助到开源的公司，开源公司可以从中吸取到经验，然后把这个技术路线思考得更加深入。

而对自变量自身而言，选择开源同样不是一笔短期收益最大化的生意。

在多次访谈中，自变量团队反复强调，他们并不把开源视为一次技术展示或品牌露出，而是将其视为一种 “行业 基础设施 ”的长期投入 。

他们更关心的是，这个模型是否足够先进，足够稀缺，从而足够有资格成为“基座”；或者模型又能否真的能被社区用起来，经得起复现、质疑和改造，在真实世界的任务中不断暴露问题，最终通过生态的反向推动，从而完成自我迭代与进化。

在具身智能这样一个高度依赖真实世界反馈的领域， 没有什么比开源社区的持续检验更残酷、也更 有 效 。

社区会放大模型的优点，也会毫不留情地揭示它的短板。而正是这种持续地被使用、被对抗、被改造，才有可能推动模型真正走向成熟。

从这个角度看，WALL-OSS的开源，本质上是一种姿态—— 愿意把模型交给世界，用真实应用来检验技术路线是否成立 。

具身智能的长期发展中，拥抱开源，或许不是理想主义，而是一条绕不开的现实路径。

至少，WALL-OSS已经用一次真实世界的大考，给出了一个有分量的示范答案。

最后话说回来，以后打榜是不是要给开源和闭源搞个分赛道？裸奔的，和穿着绒裤、棉裤、毛裤、秋裤、打底裤的相比，到底是不一样。

**一键三连** **「点赞」「转发」「小心心」**

**欢迎在评论区留下你的想法！**

— **完** —

**🌟 点亮星标 🌟**

**科技前沿进展每日见**

继续滑动看下一个

量子位

向上滑动看下一个