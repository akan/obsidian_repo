---
title: "Agent泡沫方显架构师本色"
source: "https://mp.weixin.qq.com/s/ZNG7tMocvNsUfr5id3_nVQ"
author:
  - "[[观星]]"
published:
created: 2025-08-07
description: "2025被称作Agent元年，所有人都在吹捧。每当出现重大技术浪潮时总会伴随着泡沫，Agent显然不会例外，而那些在不在聚光灯之下的理性头脑，通常都是少数，正因如此，他们的声音才格外值得审视。"
tags:
  - "Agent泡沫"
  - "架构师"
  - "可靠性"
abstract: "文章探讨了Agent技术在2025年可能面临的泡沫问题，强调了架构师在确保系统可靠性中的关键作用。"
---
![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/43wyfeC6uZaibicBEJnuaS6zSMhUqCKABfxv7zqzPcSAsrldwSAYeBsfzUczUFq8mzF19tWRia1rOT2XPx37d6hwA/0?wx_fmt=jpeg)

Original 观星 [赛博味儿酒咖](https://mp.weixin.qq.com/s/) *2025年08月06日 09:31*

> 2025被称作Agent元年，所有人都在吹捧。每当出现重大技术浪潮时总会伴随着泡沫，Agent显然不会例外，而那些在不在聚光灯之下的理性头脑，通常都是少数，正因如此，他们的声音才格外值得审视。

最近，一篇题为《为什么我赌2025年的AI代理会失败（尽管我正在构建它们）》的文章及其相关的社交媒体帖子，在技术圈引发了广泛而深入的讨论。这篇文章使用较为炒作的标题，却理性而扎实的讲述Agent系统那些被泡沫所掩藏的陷阱，揭示那些所有在聚光灯下的Agent宠儿们永远都不会告诉你的真相。

本文不是简单的转载和翻译，而是一篇深度解读，读者可以点击”阅读原文“来查看作者的英文原文。

## 作者其人

作者Utkarsh Kanwat毕业于印度理工学院孟买分校（印度顶尖名校），专注于计算机视觉和医学影像的学术研究，目前在澳新银行（ANZ Bank）担任工程师，他在专有的银行文档上微调谷歌的Gemini模型，将答案相关性提升了18%；构建了生产级的检索增强生成（RAG）系统，以应对复杂的上下文感知需求；主导了企业数据平台的现代化，用Node.js和Python取代了传统的IBM基础设施，并为超过180个微服务架构实现了部署管道的自动化；他亲手构建了超过12个覆盖开发、DevOps和数据操作等不同领域的AI代理系统，并开源了自己的AI Agent编排平台Genbase。

Utkarsh Kanwat是一个有着扎实的学术背景和丰富的Agent工程经验的技术专家，他的观点应当被认真倾听。

## 动态规划不确定性

用户视角的一次请求，在系统内部可能是一个复杂的业务流程，我们将这个流程抽象为多个步骤（Step）组合起来的工作流（Workflow），每个步骤完成一个确定的业务逻辑。这在传统工程中我们可以通过全代码的方式来实现，相对固定的部分，可以做成可配置的Workflow以提升扩展性，传统工程中这次请求被处理的可靠性为100%。

在Agent系统中，我们倾向于仅实现确定的Step，然后让大模型（LLM）针对每一次请求动态的将这些Step拼接成Workflow，这样就使得系统具有”自主性“（也就是智能性），但这样每一个Step执行或者不执行就存在了不确定性，Agent系统的不可靠性是一个难题。借助于LLM做决策和规划的干扰因素非常的多，典型如：模型能力、System Prompt的质量、用户Query的复杂性、上下文干扰、Tool的质量等等，这意味着在一开始就让模型规划出一个多步骤的路径并期望它能够最终完成用户的诉求是非常理想的。

**Kanwat用数学证明，让Agent实现多步骤的动态规划还能确保99%的可靠性，是人们的一厢情愿，是Agent系统最美丽动听的泡泡。**

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/43wyfeC6uZaibicBEJnuaS6zSMhUqCKABfcfPAg57MSaeP9SumCtcut5kYFLxGTDSPcSeKcgqLypyMqYUUKNIsiaA/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

如果智能体工作流中的每一步都有95%的可靠性（95%都是高估了），那么：

- • 5 步 = 0.95^5 = 77%
- • 10 步 = 0.95^10 = 59%
- • 20 步 = 0.95^20 = 36%

而生产系统需要99.9%以上的可靠性。即使你奇迹般地实现了每步99%的可靠性（这是没人能做到的），20步后你也只能获得82%的成功率。这不是一个提示工程问题，也不是一个模型能力问题，而是数学现实。

Kanwat解决不可靠性的思路没有黑魔法，相信很多真正开发过Agent系统的人都曾想到过： **围绕工程构建工作流，在合适的位置引入LLM并总是保持对它的可控性。错误的做法，则是以LLM为核心构建工作流，核心流程是LLM-Tool循环，整个实现几乎没有工程的可扩展点，试图通过评测驱动开发的模式，效果不好就改系统提示词，更换模型。彻底放弃传统软件工程的所有可靠性最佳实践——你的Agent系统躺枪了吗？**

### Kanwat的解法

Kanwat用自己开发的一个DevOps Agent来介绍他是如何解决Agent不可靠性问题的。但在剖析之前，我们需要浅浅的了解下DevOps做的事情是怎样的一个Workflow。

假设我们有这样的一个运维需求： **先创建一台2核4G内存的服务器，然后为它绑定一个IP地址，再把它加入到安全组X中** 。在以往我们需要一系列的工具，配合一些Shell的脚本来完成这一些列的操作，并且这些操作重复枯燥还容易出错。后来出现了以Terraform为代表的工具，他们喊出了”基础设施即代码“（Infrastructure as Code, IaC）的口号，它允许开发者和运维人员使用代码来定义、配置和管理数据中心或云端的基础设施，就像开发应用程序一样，你不再需要手动登录控制台去点击创建服务器、配置网络，而是将所有资源（如虚拟机、数据库、网络、负载均衡器等）在配置文件中描述出来，然后由Terraform自动完成创建、变更和销毁。

IaC的出现，使得Agent系统实现更可靠的DevOps成为可能——众所周知，LLM最擅长写代码了——Kanwat也是这么做的。他首先抽象了3~5个独立的步骤，每个步骤都支持回滚以及HITL（Human-In-The-Loop），然后让LLM来编写执行执行这些独立步骤的代码，最后交给IaC工具来执行。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/43wyfeC6uZaibicBEJnuaS6zSMhUqCKABfXR8v3yLPtwoPyFQdvO2fxmAiagxknJyukYibF6W7agibum7w4s7xTL7Ww/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

由于每一个步骤都可回滚，并且支持HITL，所以这个系统非常的可靠。这个例子完美诠释了作者的核心观点：不要让AI代理去执行端到端的、不可靠的任务，而应将其用在最擅长的地方—— **处理非结构化到结构化的转换，作为一个强大但有明确边界的工具** ，然后将生成的结构化产物（代码）交给稳定、可靠的传统软件去执行。

## Token成本黑洞

如果说Agent不可靠性是技术上的“死穴”，那么成本问题就是经济上的“否决票”。Kanwat指出，许多对话式代理为了维持记忆和状态，采用了一种看似简单直接的方法：在每一次交互中，将全部历史对话记录重新注入到模型的上下文窗口中。 **这种做法导致了Token成本随对话长度呈二次方增长，而非线性增长** 。

他举了一个具体的例子：一场持续100轮的对话，仅仅是Token成本就可能高达50至100美元 。这种成本结构使得长时间运行、需要保持深度记忆的自主代理在经济上变得完全不可持续。一 **个技术即使在功能上可行，如果其使用成本高到无法规模化，那么它在商业上就是失败的** 。这也解释了为什么AI基础设施专家Prashanth Manohar会强调“无状态执行”的重要性 ，因为业界已经深刻认识到，依赖无限增长的上下文窗口来维持状态是一条死胡同。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/43wyfeC6uZaibicBEJnuaS6zSMhUqCKABfYCjib5SHDV3L2xPUQVI0JYYpKFIMWQLCCWASmmj3Lia4NHr6ibV7IfzRw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

### Kanwat的解法

在以LLM为核心的Agent系统中，一个会话内每一轮对话都是带有状态的（Stateful），因为每次都会带着对话历史。Kanwat则尽可能的使用无状态的架构设计理念，将每一个用户请求都视为一个独立的、原子性的任务，而非一个连续对话的一部分。

在此工作流中，Agent接收一个明确的任务“描述”；接着，LLM的角色不再是进行开放式对话，而是作为一个高效的解析器，将该自然语言描述转化为一个或多个精确的、结构化的“函数”调用指令，并生成所需的参数 ；最后，应用层的代码执行这些指令，任务即告“完成”。 这个工作流被Kanwat描述为“描述→函数→完成”（description → function → completion）。

Kanwat的这个解法就更加容易想到，我们会比较自然的在一些无状态的场景中使用这种方式，因为不是所有的场景都要做成”对话伙伴“这一种人机交互范式，总有一些场景是”一次性做好一件事就离开的智能工具“。作为架构师要做的就是明确判断不同场景的区别，使用合适的解决方案。

## 还有什么陷阱

### 被低估的Tool工程开发

或许正是Agent以及大模型的能力被远远高估的原因，Tool工程的重要性才被远远低估了。Kanwat提出了一个“70/30法则”：在一个成功的Agent系统中，AI（即大型语言模型本身）可能只完成了30%的工作，而剩下 **70%的工作是工具工程（Tool Engineering）** 。

进而的，Kanwat倡导每个工具应当被精心打造，以提供正确的反馈，同时又不会使上下文窗口过载。具体的，开发一个工具工程，我们需要考虑：

- • 当一个工具（API调用）部分成功时，代理如何得知并作出正确反应？
- • 如何有效地向代理传达复杂的状态变化，而又不至于让上下文窗口过载？
- • 当工具调用失败时，代理需要哪些信息才能进行恢复或重试？信息太少，它会卡住；信息太多，你会浪费上下文。
- • 如何处理那些具有相互依赖性的操作，比如数据库事务或文件锁？

你的Agent工程是否又一次躺枪？

这些问题是传统软件工程的核心，它们枯燥但至关重要。正是这些“隐藏的冰山”决定了一个AI应用是停留在炫酷的演示阶段，还是能成为一个真正可靠的生产级产品。那些承诺”只需连接你的 API，我们的智能体就能搞定一切“的公司，并没有完成这项工程工作。在吹牛的时候，他们更像是将工具视为人类接口，而非AI接口。结果就是，这些Agent虽然在技术上能成功调用API，但实际上却无法完成复杂的工作流程，因为它们不理解发生了什么。

### 遗留系统改造

AI代理的演示视频几乎总是在一个理想化的环境中进行：使用设计良好、文档齐全的现代化API。然而，真实的企业IT环境与此截然相反。Kanwat将其描述为充满了“怪癖、部分故障模式、不断变化的认证流程、随时间变化的速率限制以及不符合提示模板的合规性要求的遗留系统” 。

他的这一观点极具说服力，因为这正是他在澳新银行每天都要面对的现实。试图将一个基于概率的AI模型与一个充满确定性规则和历史遗留问题的复杂银行系统连接起来，其难度远超外界想象。因此，当许多AI代理平台声称能够“与您的整个技术栈无缝集成”时，Kanwat认为这种承诺要么是过于天真，要么就是没有真正尝试过构建生产级系统。

## Kanwat给出的架构原则

**一句话版本：AI处理复杂性，人类掌握控制权，软件工程确保可靠性。**

- • **AI处理复杂性** ：将AI（大型语言模型）用于其最擅长的领域——理解模糊的人类意图、解析非结构化数据、生成创造性的内容或方案
- • **人类掌握控制权** ：在关键的决策节点和验证环节，必须保留人类的监督和控制 ，确保了系统的最终可靠性和责任归属
- • **软件工程确保可靠性** ：所有要求高可靠性的任务，如状态管理、任务执行、错误处理、事务操作等，都应该交由确定性的、传统的软件工程来处理
- ![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

下面是详细版本，即便是对于产品经理也非常有指导意义，Kanwat建议 **将开发的焦点从追求“自主性”转向构建“可靠性”：**

1. 1\. **定义清晰的边界** 。一个设计良好的代理系统必须清楚地知道自己的能力边界在哪里。它需要明确在何种情况下可以自主处理，以及在何种情况下必须将控制权移交给人类或确定性的软件系统
2. 2\. **优先考虑可靠性而非自主性** 。用户对工具的信任建立在可预测性和稳定性之上。一个99.9%时间能正常工作的工具，远比一个80%时间能创造奇迹、但剩下20%时间会灾难性失败的系统更有价值
3. 3\. **为失败和经济可行性而设计** 。从项目一开始，就应该承认AI会犯错（比如20-40%的失败率），并内置相应的回滚和补偿机制。同时，必须持续评估每次交互的成本，并尽可能采用无状态设计，以确保系统在经济上是可持续的
4. 4\. **建立在坚实的软件工程基础之上** 。再次强调“70/30法则”，大型语言模型只是产品的一个功能特性，而不是产品的全部。整个系统的基石必须是稳健的架构、严格的错误处理和全面的可观测性等传统软件工程的最佳实践

## 泡沫过后方显架构师本色

潮水退去，裸泳的是那些鼓吹Agent通用能力搞定一切，却解决不了可靠性与成本问题的公司，以及那些停留在营销Demo和玩具开发层面却根本没有深入架构和开发过企业级Agent系统的人。

围绕传统工程构建起来的高可靠性的Agent系统并不fancy，说出来不会赢得投资人的喜欢，会削减大众的热情，甚至让慕名而来的开发者因为没有黑科技而扫兴。然而真正的Agent架构师不会高调的标榜自己的能力，不会因为没有黑科技而失去耐心， **因为真的踩过坑并解决问题的人，会越发的看到AI时代自己是无法被替代的存在** ，Agent工程继承了传统工程的所有，又引入新的不确定性，平衡好工程与大模型的优缺点，是一种优雅的艺术。

停止构建那些华而不实、成本高昂的聊天玩具，重拾经典工程学，泡沫过后方显架构师本色。

  

[Read more](https://mp.weixin.qq.com/s/)

继续滑动看下一个

赛博味儿酒咖

向上滑动看下一个