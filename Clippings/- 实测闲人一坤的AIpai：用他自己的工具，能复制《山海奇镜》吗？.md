---
title: "实测闲人一坤的AIpai：用他自己的工具，能复制《山海奇镜》吗？"
source: "https://mp.weixin.qq.com/s/Wg02AD6BJKUzsIN3vKFMZg"
author:
  - "[[黄小艺]]"
published:
created: 2025-08-05
description: "20分钟，用闲人一坤的Agent复制“山海奇镜”"
tags:
  - "AI视频创作"
  - "交互式工具"
  - "影视行业经验"
abstract: "闲人一坤开发了一款名为AIpai的交互式AI视频创作工具，旨在降低专业视频制作的门槛。"
---
![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/jopKOlhibRBJe6mAyTxOUpsfj0OLFjmibrjfyCJ4bY0KpJFqialicEanou8l8TG26qNjkT5xEosmOBYC6CWeEicic0Yw/0?wx_fmt=jpeg)

Original 黄小艺 [硅星人Pro](https://mp.weixin.qq.com/s/) *2025年08月05日 10:09*

![Image](https://mmbiz.qpic.cn/mmbiz_png/jopKOlhibRBJe6mAyTxOUpsfj0OLFjmibrfDbFbN8GXLULtdw9lsmBr9zFB9kbGz2cQhLpP4Xb3dibON4REiaSrUBg/640?wx_fmt=png&from=appmsg&randomid=wrw3a9j2&tp=webp&wxfrom=5&wx_lazy=1)

作者 *｜* 黄小艺  
邮箱 *｜* huangxiaoyi@pingwest.com

一分钟视频报价十余万，闲人一坤本可以靠AI创作，过上一种让同行羡慕的“躺赚”生活。

他就是那部曾刷屏的AI短片《山海奇镜》的导演，也是国内最早把AI视频玩明白、并成功商业化的那批人。当所有人都以为他会在这条路上继续创作时，他掉头去做了一款叫“AIpai”的产品。

“我发现，大多数人对AI视频的认知都是错的。”闲人一坤说道。在他看来，整个行业都陷入了一种“一键生成”的迷思，而这从根本上就是个伪命题。

“你输入的几个字和最终视频的信息量差了多少个数量级？这就像站在10公里外拿飞镖射靶子，怎么可能射得准？”

更大的行业现实是，AI和影视两个圈层的割裂：懂AI技术的人，不懂影视创作的门道；而影视圈的专业人士，又在用一套很快就过时的知识去“调教”AI。

这种认知差，就是他做AIpai的理由。比起开班卖课，变成另一个“李一舟”，不如把过去20年的影视经验和近两年的AI实战经验灌注到一个产品里。

AIpai是一个以对话交互为主的涵盖了从剧本、分镜、构图、成片全流程的视频Agent工具，沉淀了一套人人都能上手的AI操作流程。

这个想法听起来很对，也很有野心。但从一个顶尖创作者脑中的方法论，到一个普通用户也能顺畅使用的产品，中间的距离有多远？理论上的“最优解”在实际操作中体验如何？

带着这些疑问，他向我们展示了他刚用AIpai做的新鲜案例，一个权力游戏片头：

以下视频来源于

闲人一坤

在网页中，你也可以通过社区模版直接观看他的操作流程，甚至复制他的模版继续你的创作。

我们上手实测了一番，并与闲人一坤聊了聊他对当下视频Agent的理解，试图理解他这套“反主流”的产品哲学，究竟是一条更务实的路径，还是一次停留在理念层面的实验。

1

**实测AIpai：纯小白也能轻松上手**

为了真实体验AIpai的工作流程，我们设计了两个核心场景。第一个是模拟普通用户，脑中只有一个模糊的想法；第二个是模拟有明确需求的创作者，看AI如何辅助执行。

## 测试一：从一个模糊概念开始，AI如何当“导演”？

话不多说，我们先看生成效果。

我的第一个任务，是想复刻《山海奇镜》的感觉，但我手头没有剧本，也没有具体的人物设定。这是一个很多小白刚开始创作时的典型起点。

我向AIpai发出了第一个指令：“做一个类似山海奇镜的短片。”

AI没有立刻开始画图，而是先像一个制片人一样，回来与我沟通，确认核心风格：“动漫”还是“写实”？

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

我选择了“动漫风格”。这是一个很实际的考量，因为目前AI生成写实风格时，在物理效果和人物一致性上还不够稳定，动漫风更能保证最终成片的连贯性。

确认风格后，AI开始引导我搭建故事的核心框架，分别是 **主角、情节、场景** 。这正是传统影视创作的基石。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

这里最值得称道的一点是，AI在每一步都会提供具体的选项让你选择，而不是抛出一个开放性问题。比如它会问你，希望主角是“踏上寻仙问道之旅”，还是“守护家园对抗妖兽”。这极大地降低了创作的启动门槛，避免了新手面对空白屏幕不知所措的窘境。

我依次确认了AI的建议后，它便开始搭建具体的项目框架。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

这时，AIpai的核心设计就体现出来了：我在右侧对话框中确认的每一个分镜，都会被结构化地整理到左侧的项目栏中。你可以清晰地看到“地点、角色、景别、镜头运动、画面描述”等专业信息。这个设计，就是它试图填平“想法”与“专业制作”之间鸿沟的体现。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

在生成每个分镜图时，AI也会提供几种不同的视觉方案供你选择。如果用户没有特定的形象要求，基本可以信赖AI的选择，这省去了在其他工具里为了一个完美画面反复“抽卡”的时间。

我还注意到，AI在这个过程中会根据任务类型，自主选择和调用不同的底层模型。例如，它判断出我的需求是“动漫风格”且要“平衡性价比”，就自动选择了豆包的模型来执行。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

整个过程耗时约30分钟。除了在关键节点进行选择和确认，我几乎不需要思考具体的技术实现，比如用哪个模型、写哪种提示词。不过，这种步步为营的引导式创作，也意味着用户需要全程在场，随时准备与AI互动。

## 测试二：当需求明确时，AI如何做“执行”？

接下来，我尝试了另一种更常见的商业场景：我已经有了一个明确的主题和核心素材。

我先用AI工具生成了一张“粉嫩软萌的小熊咖啡”图片，把它作为这个虚拟广告片的核心“商品”。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

这次，我的需求非常清晰和直接。接到需求后，AI进入了执行模式，首先拆解需求，确定了主体和场景。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

这些关键要素同样被同步呈现在左侧的项目板上，让整个项目结构一目了然。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

随后，AI开始了一套连贯的自动化流程： **生成脚本 → 生成分镜图 → 生成配音 → 图生视频 → 匹配音乐 → 完成剪辑** 。这个过程几乎不需要人为干预。

在生成过程中，你能看到AI在后台自行判断和选择生图模型，并检查各环节的产出效果，就像一个尽职的后期团队。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

当然，首次“一气呵成”的成片并不完美，主要问题在于整体调性的一致性上还稍有欠缺。

这时，就轮到自然语言修改发挥作用了。我直接在对话框里输入修改意见，告诉它风格需要调整。值得一提的是，我输入的指令里甚至包含了错别字，但AI依然准确理解了我的意图，并对分镜进行了修改。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

经过一轮调整，模型生成的新图片就基本符合我的预期了。

最终生成的广告短片是这样的。回顾整个过程，我只输入了两句核心指令，并进行了一次修改确认，其余工作全部由AI自主完成。

我们可以看到，AIpai确实在尝试填平专业导演与普通用户之间的鸿沟。虽然鸿沟依然存在，但它已经搭建起了桥墩。它给用户的，不是一键生成的炫酷效果，而是一套可以上手实践的、通往专业创作的脚手架。

1

**对话闲人一坤**

****硅星人**** ：你之前做个人创作，据说一分钟视频的报价是十多万？

**闲 人一 坤** ：（笑）那是我故意报高的。我不想接太多项目，所以就报个超高的价格。能接受这个价格的客户不多，这样我就能筛选掉大部分需求。我想把时间和精力集中在真正有价值的项目上。

**硅星人** ：那为什么要从这样一个舒适的状态转向做产品？

**闲人一坤** ：主要是两个原因。首先，我做个人创作时需要开很多窗口，用很多不同的工具，效率很低。我最开始只是想做一个一站式的平台，把所有模型都集成起来。

但后来我发现，即使解决了工具整合的问题，大部分人还是不会做。很多人问我："你这个视频怎么做的？能不能教教我？"我不想去卖课。我想，为什么不把我的能力变成一个AI，让它去帮助更多人。

**硅星人** ：这个转变的契机是什么？

**闲人一坤** ：我错过了短视频时代，当时我在长视频领域太忙了。到了AI时代，我觉得这可能是影响整个人类社会的变革，不是某个单一领域的变化。我不想再错过这次机会。

## 一种新的AI视频创作方式

**硅星人** ：你们的产品和市面上的AI视频工具有什么根本差异？

**闲人一** **坤** ：最大的理念差异是交互性。很多产品追求一键生成，你输入一段话，它给你输出一个视频。我们从根本上认为这是错误的。

你想想，你输入的文字token和最后生成视频的信息量差多少数量级？就像站在10公里外用飞镖射靶子，怎么可能射得准？你必须逐步接近，10米投一次，走近了再10米投一次。

**硅星人** ：具体是怎么做的？

**闲人一坤** ：我们按照影视行业发展一百多年的工作流程来设计：从idea到剧本，从剧本到分镜，从分镜到图片，从图片到视频，再到配音配乐。每一步都是信息密度的放大，每一步都增强确定性。

更重要的是，我们支持非线性创作。你可以在任何节点修改，甚至做完整个视频后，你说"我觉得主角长得不好看"，它会重新生成整个项目。

**硅星人** ：这听起来比一键生成更复杂，用户会接受吗？

**闲人一坤** ：我们发现用户在我们平台上的平均使用时长是40分钟以上。真正有创作需求的人，他们愿意花时间去精雕细琢。我们要服务的不是那些只想要"快餐"的用户。

**硅星人 ：** 这个搭档是很懂创作的，它懂AI视频创作的规则，有自己的workflow，用户可以是一个不专业的甲方，直接提需求？

**闲人一坤** **：** 差不多，我们的产品本身就是为了解决视频生成创作门槛太高，环节太多的问题的，你可以把agent当作一个真正的搭档，用自然语言就能指导他修改。

## 懂基模技术的人，未必懂怎么用好模型

**硅星人** ：你所说的实战经验是什么呢，怎么融入到产品里的吗？

**闲人一坤** ：在内容创作领域，大多数人其实不知道什么是对的。如果你基于所有用户的行为数据来优化产品，你优化的很可能是错误的方向。

比如很多人写视频提示词时会写得特别复杂，描述灯光、机位、运镜等等。但在AI视频时代，这些传统影视的知识很多是没用的，甚至是有害的。

**硅星人** ：能举个例子吗？你觉得基模的人也不懂吗？

**闲人一坤** ：懂技术的人，未必懂如何用好模型。有些官方建议提示词甚至现在都太复杂了。比如说，图生视频时，图片的权重远远大于提示词。你在提示词里写得天花乱坠，描述什么"红色白色相间的火箭，落在白色地面上"，这些信息图片里都有了。你还这么写，如果AI的理解和你的理解不一致，反而会影响生成效果。

正确的做法是什么？"火箭缓缓着陆，烟尘从扩散到逐渐消散"，就这么简单。主体加运动，就够了。

我做《山海奇境》时就有意识地适应AI的能力限制。有的AI视频，做的极其复杂，多主角，多故事线，大家都看懵了。但我就一个主角、一个时空、一条故事线，只有这样观众才能看得懂。

AI时代的创作逻辑和传统影视完全不一样。传统的那套东西，放到AI里很多是行不通的。

## 商业模式创新，从“作品经济”到“流程经济”

**硅星人** ：你们现在的定价和目标市场是怎么样的？  
  
闲人一坤 ：AIpai现在刚上订阅，所有图片和视频模型，都是8折优惠，希望更多的用户能来体验和Agent一起创作的乐趣。现在整个AI视频制作当中，成本占比最大的部分是视频模型。视频模型本身之间价格有较大差异，最贵的VEO3接近30元/条。最便宜的模型才1元/条。Aipai会根据用户所做的内容给到不同模型的匹配和推荐，也会在每次生成视频之前给到大家大致积分的一个预估。当然，如果用户偏好某款模型，也可以指定。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**硅星人 ：** 目前是以海外市场为主，是吧，这好像是视频Agent的共同路线。

**闲人一坤 ：** 对。  
  
**硅星人 ：** 我看到你们有一个模版库，这似乎是当下AI视频应用公认的道路，就像是抖音做特效一样，降低用户的创作门槛。

**闲 人一坤** ：对，但我们还不太一样。我们的模版不只是开放了一种效果，也是开放了创作的全流程。你可以在我的权游模版里看到，我每一步操作和对话，你可以接着往下做，也可以替换掉其中的某个角色，某个主题。

从创作的角度来看，传统创作者只能通过最终的作品盈利。但我们可以把整个创作过程分享出去，其他人可以基于你的"模板"进行二次创作，从而盈利。

硅星人 ：这个应用场景是？可以举个具体的例子吗？

闲人一坤 ：比如我做了一个宠物去世后在天堂快乐生活的短片，如果用户也有同样的经历，也想念他的宠物，他就可以把自家宠物的照片上传，基于我的创作过程快速生成一个新版本，而我可以从这个使用过程中获得分成。

抖音特效是同质化的，我们的是可以个性化定制的。而且我们要建立的是一个创作者生态，优质的创作过程会被更多人使用，创作者就能获得更多收益。

**硅星人** ：如何判断什么是"优质的创作过程"？

**闲人一坤** ：看衍生内容的数量。如果基于你的创作产生了很多衍生作品，说明你的东西有价值。我们不会基于大多数用户的行为数据来判断，而是基于追随者的数量。在创作领域，追随你的人越多，说明你的东西越好。

**硅星人** ：这个很有意思，你对当下AI视频Agent涌现怎么看？从模型能力和商业化上，现在是一个关键节点吗？

**闲人一坤** ：我会觉得现在仍然很早期，每家都有自己的特色，产品理念都不一样。当然，这种差异化是好事，说明这个赛道足够大，容得下不同的解决方案。在这么早期的阶段就开始同质化竞争，对谁都没好处。

我们在其中的优势主要在于对行业的理解和经验的沉淀。今天所有的AI Agent都是三个部分：大语言模型（LLM）、上下文（Context）和工具（Tools）。大语言模型我们无法改变，只能调用API。我们能做的是优化Context和Tools。Context就是我们的"员工手册"，告诉AI它有什么能力，用户有什么需求，怎么用工具满足需求。

**硅星人** ：这个手册是怎样的？

**闲人一坤** ：这个手册是我们的核心竞争力，但具体内容不方便透露。我们的理念是用最少的东西激发大模型的最大能力，而不是用最多的限制去约束它。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) ![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)** 点个 **“ 爱心 ”** ，再走 吧

[Read more](https://mp.weixin.qq.com/s/)

继续滑动看下一个

硅星人Pro

向上滑动看下一个