---
title: "2025 年 AI 编程报告出炉：开发者效率暴涨 76%，但背后藏着你不知道的真相"
source: "https://mp.weixin.qq.com/s/M6PWSvuS-2bWNaD9BKpapw"
author:
  - "[[loonggg]]"
published:
created: 2025-12-30
description: "Greptile 最近发布了一份 2025 年 AI 编程状况报告，里面有个数字特别扎眼。"
tags:
  - "AI编程"
  - "效率提升"
  - "代码审查"
  - "模型竞争"
  - "前沿技术"
abstract: "2025年AI编程报告显示开发者效率大幅提升，但同时也带来了代码审查难度增加、模型竞争加剧等新挑战。"
---
Original loonggg *2025年12月30日 11:31*

Greptile 最近发布了一份 2025 年 AI 编程状况报告，里面有个数字特别扎眼： 从今年 3 月到 11 月，开发者的人均代码产出增长了 76%，从 4450 行直接跳到 7839 行。

这个增长速度，放在软件开发史上看，真的很夸张。过去几十年，开发工具的进化，从命令行到 IDE，从版本控制到持续集成，每一次工具升级带来的效率提升，可能也就 10%到 20%。但 AI 编程工具，一年时间就把这个数字拉到了 76%。

不过，这份报告真正有意思的地方，不只是这个数字本身，更在于它揭示的整个 AI 编程生态的变化。我们一点点往下看。

## 产出暴涨的背后，代码在变厚

除了人均代码量增长 76%，报告还给出了几个配套数据：

PR 的规模增加了 33%，从平均 57 行改动涨到 76 行。单个文件的修改行数也增加了 20%，从 18 行涨到 22 行。中型团队（6 到 15 人）的产出增长最明显，涨了 89%，从人均 7005 行涨到 13227 行。

这几个数字放一起看，能看出一个趋势： 开发者在做更大的改动 。

以前写代码，可能习惯小步快跑，一个 PR 解决一个小问题，几十行代码搞定。但有了 AI 工具，开发者开始敢做更大的重构，一次性处理更复杂的功能。

这其实是个双刃剑。好处是效率确实上去了，很多以前要拆成好几个任务的活，现在一口气就能干完。但坏处是，PR 变大之后，代码审查的难度也跟着上去了。以前看个几十行的代码，十分钟能过一遍；现在一个 PR 上百行，可能得花半小时甚至更久。

而且，代码越密集，出错的概率也越大。 AI 能帮你写代码，但它不一定能保证每一行都是对的。当你一次性提交上百行改动，里面可能藏着几个不容易发现的 bug。

所以效率的提升，其实是在考验团队的其他能力。代码审查能不能跟上？测试覆盖能不能保证质量？这些都是新的挑战。

## AI 编程工具的生态格局

报告的第二部分，详细列举了当前 AI 编程工具的市场格局。这部分挺有意思，因为它反映了开发者到底在用什么工具。

先说 AI 内存管理。mem0 占了 59%的市场份额，基本上是这个领域的主导者。AI 内存管理是个相对新的概念，简单说就是让 AI 能记住你之前说过的话，做过的事，不用每次都从头开始。这个功能在编程场景特别重要，因为你可能在一个项目里反复调用 AI，如果它每次都不记得上下文，体验会很糟糕。

向量数据库的情况就复杂多了。Weaviate 领先，占了 25%的份额，但后面还有 5、6 个玩家，每个都占 10%到 25%之间。这说明向量数据库的市场还没定型，大家都还在抢地盘。

向量数据库是 AI 应用的基础设施，负责存储和检索高维向量数据。但到底哪家的技术更好，哪家的生态更完善，现在还没有明确答案。这种群雄逐鹿的局面，其实对开发者是好事，因为竞争会推动技术进步，也会让价格更合理。

再说 AI 规则文件。报告显示，67%的代码库在用 CLAUDE.md 这个格式。这是个挺有意思的现象。 CLAUDE.md 是 Anthropic 推广的一种 AI 指令文件格式，用来告诉 AI 这个项目的规范、风格、要求。

这个数据说明，开发者已经开始系统化地管理 AI 在项目中的行为。不再是随便问问 AI，想到什么问什么，而是用标准化的方式，让 AI 理解整个项目的上下文和规则。这种标准化，本身就是 AI 工具融入开发流程的一个标志。

SDK 的增长数据也很说明问题。Anthropic 的 SDK 增长了 8 倍，达到 4300 万月下载量。Pydantic AI 爆发式增长 3.7 倍，达到 600 万。LiteLLM 增长 4 倍，达到 4100 万。

这些工具都是帮开发者更方便地使用 AI 模型的。增长速度这么快，说明 AI 工具已经从尝鲜变成了日常。开发者不再是偶尔用用，而是把它们集成到了自己的工作流程里。

## 大模型竞争：差距在缩小

报告的第三部分对比了各大模型的使用情况和性能表现。

从 SDK 下载量看，OpenAI 依然领先，月下载量 1.3 亿。但 Anthropic 的增长速度更惊人，从 2023 年 4 月到现在，增长了 1547 倍。

更关键的是比例变化。2024 年 1 月，OpenAI 和 Anthropic 的下载量比例是 47 比 1，现在已经缩小到 4.2 比 1。这个变化速度，快得有点出乎意料。

这说明什么？Anthropic 在开发者群体中的接受度快速上升。可能是因为 Claude 的能力确实不错，也可能是因为 Anthropic 在开发者生态上下了功夫，还可能是因为开发者开始寻求 OpenAI 之外的替代方案。

不管原因是什么，这个趋势对整个行业都是好事。一家独大的局面，往往意味着创新的放缓和价格的坚挺。有竞争，才会有持续的进步。

性能对比方面，报告给出了几个关键指标。

响应速度（TTFT，首字延迟）方面，Anthropic 的 Opus 4.5 和 Sonnet 4.5 表现最好，中位数在 2 秒左右。OpenAI 的 GPT-5 和 GPT-5.1 要慢一倍多，5 到 7 秒。Google 的 Gemini 3 Pro 更慢，要 13 秒左右。

这个差距在实际使用中很明显。如果你在写代码的过程中频繁调用 AI，2 秒和 7 秒的差别，就是能不能保持专注的差别。等太久，思路就断了。

但吞吐量（每秒生成的 token 数）方面，OpenAI 又占优势。GPT-5 和 GPT-5.1 能达到 60 多 token 每秒，Anthropic 在 20 左右，Gemini 只有 4 到 5。

吞吐量高意味着长文本生成更快。如果你需要 AI 帮你写大段代码或者文档，吞吐量就变得很重要。等十几秒看到结果，和等几十秒看到结果，体验差很多。

成本方面，以 8000 个输入 token、1000 个输出 token 的工作负载为基准，GPT-5 系列的成本倍数是 1 倍，Gemini 3 Pro 是 1.4 倍，Claude Sonnet 4.5 是 2 倍，Claude Opus 4.5 是 3.3 倍。

所以选模型，其实是在做权衡。要快速响应还是要高吞吐？要便宜还是要性能？不同的场景，答案不一样。

## 前沿技术突破的实际意义

报告的后半部分列举了一堆前沿研究，看起来很学术，但其实每一个都指向实际问题。

DeepSeek-V3 是个 671B 参数的模型，但它每次只激活 37B 参数。这个设计思路叫混合专家模型，核心想法是不需要所有参数都参与计算，只调用相关的专家就够了。

这个方向很重要，因为模型越来越大，计算成本也越来越高。如果能在保持能力的前提下，降低实际计算量，那就能让更多人用得起这些模型。

Qwen2.5-Omni 是个多模态模型，能同时处理文字、语音、视频。它的架构设计很巧妙，把感知（看和听）和推理（思考）分开，每个部分专注做自己擅长的事。

这个方向也很有意义，因为真实世界的信息不只是文字。如果 AI 能直接理解图片、视频、语音，那它能解决的问题范围就大得多。

长上下文和 RAG（检索增强生成）的对比研究，结论是两者各有优势。长上下文在处理连续、结构化的内容时表现更好，比如一本书或者一篇长文。RAG 在处理碎片化、多来源的内容时更有优势，比如搜索结果或者对话记录。

这个结论听起来不那么激动人心，但它帮我们理解了什么时候该用什么方法。技术选型不是越新越好，而是要看场景。

RetroLM 提出了一个新思路：不要检索原始文本，直接检索模型的内部表示（KV 缓存）。这个想法很聪明，因为模型内部的表示，已经包含了对文本的理解，比原始文本更精炼。

Self-MoA 的研究发现，不需要用多个不同的模型，反复采样一个好模型也能达到类似的效果。这个发现挺有意思，因为它挑战了一个直觉：多样性一定更好。有时候，一个强模型的内在多样性，就足够了。

应用层的几个创新也值得关注。

GEPA 用提示词进化替代强化学习。强化学习虽然强大，但成本很高，需要大量的训练资源。提示词进化是个轻量级的替代方案，让模型分析自己的执行轨迹，然后改进提示词。这个思路成本低得多，但效果不差。

SFR-DeepResearch 训练了一个能做深度网络研究的单智能体。它能决定什么时候搜索，什么时候浏览网页，什么时候执行代码，还能自己管理长时程的上下文。这种能力，其实是在把 AI 从工具变成助手。

LDAR 关注的是检索中的干扰问题。当相关内容和无关内容混在一起，模型的表现会下降。LDAR 提出了一种注意力感知的检索方法，能筛选出真正有用的部分，过滤掉干扰。

MEM1 解决的是长时程任务中的内存问题。它训练模型在保持能力的前提下，压缩上下文，让内存使用量几乎保持恒定。这对需要处理长任务的 AI 应用很重要。

Search-R1 训练模型在推理过程中主动搜索。它不是先搜索再推理，也不是先推理再搜索，而是边推理边搜索，根据当前的思考决定需要什么信息。这种动态结合，比静态的检索增强要灵活得多。

这些研究看起来很学术，但它们都在解决实际问题：如何让 AI 更高效，如何让 AI 能处理更复杂的任务，如何让 AI 的行为更可控。

## 这些变化对我们意味着什么

看完这份报告，最直接的感受是，AI 编程工具已经从实验阶段进入了实用阶段。开发者不再是尝鲜，而是真的在依赖这些工具。

但效率的提升，不只是写代码更快了这么简单。它会改变整个开发流程。

以前，一个功能可能要拆成好几个小任务，慢慢做。现在，开发者敢一次性做更大的改动。这意味着项目的迭代速度会加快，但同时对代码审查、测试、文档的要求也更高了。

对团队来说，这是个新挑战。你不能只盯着代码产出，还得看质量能不能跟上。AI 能帮你写代码，但它不能替你做决策，不能替你保证架构的合理性，不能替你维护代码的可读性。

技术生态的变化也值得关注。OpenAI 和 Anthropic 的差距在缩小，说明竞争在加剧。这对开发者是好事，因为竞争会推动价格下降、性能提升、功能创新。

但同时，技术选型也变得更复杂了。以前可能就用 OpenAI，现在你得考虑 Anthropic、Google、DeepSeek，每个都有自己的优势和劣势。你得根据场景选择，根据预算选择，根据性能要求选择。

前沿研究的方向也给了我们一些启示。 效率不一定要靠堆参数，混合专家模型就是个例子。创新不一定要推翻旧方法，很多时候是在旧方法上做微调，比如 RetroLM 的 KV 级检索，比如 Self-MoA 的单模型采样。

对普通人来说，这些变化也有借鉴意义。

第一个是工具的选择。 不要盲目追求最新最贵的工具，要看场景。就像长上下文和 RAG 各有优势，适合的工具才是最好的工具。

第二个是效率和质量的平衡。 AI 能让你更快，但快不等于好。产出增加了，你得确保质量也跟上。这在任何领域都一样。

第三个是持续学习的必要性。 技术生态变化这么快，今天的最佳实践，明天可能就过时了。保持敏感，保持学习，才能跟上节奏。

第四个是创新的方式。 很多突破不是从零开始，而是在现有基础上改进。GEPA 用提示词进化替代强化学习，SFR-DeepResearch 训练单智能体做复杂任务，这些都是在已有技术上找到新的组合方式。

## 一个快速变化的时代

这份报告最大的价值，不在于某个具体的数据，而在于它呈现的整体图景。

AI 编程工具正在从边缘走向中心，从辅助变成核心。开发者的工作方式在改变，团队的协作模式在改变，技术生态的竞争格局在改变。

这个变化的速度，比我们想象的要快。76%的效率提升，只是一年的结果。接下来呢？明年会不会再涨 50%？后年呢？

当工具的能力增长速度远超我们的预期，我们需要思考的不只是如何用好这些工具，还有如何在这个快速变化的环境中保持方向感。

技术会继续进步，工具会继续迭代，但有些东西不会变。比如对质量的追求，对问题本质的理解，对用户需求的洞察。这些才是真正的核心竞争力。

AI 能帮你写代码，但它不能替你决定该写什么代码。它能帮你提高效率，但它不能替你判断什么是真正重要的事情。

所以，面对这些变化，我们既要拥抱新工具，也要保持清醒。不要被效率的提升冲昏头脑，不要忘记为什么而做。

2025 年才刚开始，这份报告只是给了我们一个中期快照。接下来的变化，可能更快，也更出乎意料。

报告地址： https://www.greptile.com/state-of-ai-coding-2025

---

最后，介绍一下，我的星球：「AIGC·掘金成长研习社」 ，主要分享什么内容呢？三个板块的内容：

1、副业赚钱领域的内容。 我做自媒体十几年了，有很多副业赚钱方面的经验和干货，而且每周都会定期详细带大家拆解一个副业赚钱案例，持续更新的那种，目前，已经分享了上百篇跟副业赚钱相关的帖子和文章了。

2、AI 落地和实操相关的内容。 我在里面也分享了很多 AI的各种玩法和落地场景，包括用 AI 做副业的案例也都有。

3、个人成长。 我会分享很多我做超级个体和自由职业的一些思考和成长类的内容，目前我已经做自由职业 5 年了，有太多的感慨和内容分享。

如果你想学习如何搞副业，如何使用 AI ，甚至如何使用 AI 搞副业，那一定要加入我这个超值的星球。目前，已经更新了 1600 多条干货和文章了，加入成员 840+ 。感兴趣的可以加入。

最近限时最大优惠，原价 149 ，今天加入 可以立减 50 元 ，只需要 99 元， 春节后，会涨价到 199 元 。我认为我的星球是目前副业和 AI 领域 最超值和具有性价比 的星球，价格不贵，同时内容也不比几千块钱的星球差。

大家可以扫码，查看，支持 3 天无理由退款，内容好不好，先进来看看再说，不适合自己退了也没毛病。

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

作者提示: 个人观点，仅供参考

继续滑动看下一个

非著名程序员

向上滑动看下一个