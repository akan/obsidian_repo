---
title: "a16z | AI的尽头是Crypto，世界的尽头是无人机"
source: "https://mp.weixin.qq.com/s/hZxY5F7SKxNcTfWAqvLkiw"
author:
  - "[[Eric Tin]]"
published:
created: 2025-08-12
description: "技术思想家 Balaji Srinivasan 做客 a16z 播客，抛出震撼论断。"
tags:
  - "AI"
  - "Crypto"
  - "无人机"
  - "地缘政治"
  - "网络国家"
  - "验证技术"
  - "多神论AI"
abstract: "技术思想家Balaji Srinivasan认为AI与Crypto互补，无人机将重塑地缘政治，未来是多个文化AI并存的局面。"
---
Original Eric Tin *2025年07月29日 22:38*

技术思想家 Balaji Srinivasan 做客 a16z 播客，抛出震撼论断。他认为，AI创造的虚拟世界真伪难辨，其逻辑尽头必然是 Crypto 提供的可验证现实。同时，对谈也警告，当我们痴迷于AI的说服力时，真正的“杀手级应用”——无人机，早已将数字边境变为物理战场，深刻改变着全球地缘政治的未来。

👉

Balaji Srinivasan, 知名创业者、投资人与“网络国家”思想家

- 2024年9月：创立The Network School（网络学院），致力于“网络国家”（Network State）和去中心化国家的教育实训，校址在马来西亚柔佛州森林城市，首批招生150人。
- 2022年：出版畅销书《The Network State》，系统提出“网络国家”理念，探讨数字社区如何实现新型治理模式。
- 2020年：在新冠疫情爆发前，准确预测疫情全球影响，社交媒体影响力显著。
- 2019年5月：离开Coinbase首席技术官（CTO）一职。任内主导Coinbase后端重构，推动USDC稳定币上线，整合Coinbase Earn等产品，撮合数十亿美元托管业务与空投项目合作。
- 2014-2018年：创办Teleport（2017年被Topia收购）、联合创办Coin Center（全球主要加密货币政策智库）。
- 2013-2019年：加入顶级硅谷VC Andreessen Horowitz（a16z），先后任普通合伙人与董事合伙人；广泛参与AI、加密、硬科技等领域项目投资。
- 2013年：创办21.co，目标为比特币挖矿硬件公司，后转型 Earn.com ，促进基于加密货币的任务众包和电邮奖励服务。
- 2008-2012年：联合创办Counsyl，专注遗传病筛查，用于生育前基因检测。
- 2006-2018年：斯坦福大学讲师，主要教授统计、计算生物学，与人工智能创业相关课程，期间联合主讲全球首批大规模在线加密货币课程。
- 1997-2006年：就读斯坦福大学，连续拿到电气工程学士、硕士、博士，并获得化学工程硕士学位

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

听播客: https://www.youtube.com/watch?v=LM7snohbu4k

## Key Takeaways

## 面向创始人与产品经理

- 停止追逐单一的“通用神级AI”，应为“多神论”的、由特定文化和专业领域驱动的AI世界进行构建。
- 核心洞察: 旧的“AGI即将到来”的叙事正在被一个更现实的图景取代。Balaji雄辩地指出，未来是多个“文化AI”并存的局面（如美国AI、中国AI、开源AI），每个AI都将深度融入特定社群的价值观。
	- 应有行动: 与其构建一个泛泛的通用聊天机器人，不如为你的目标社群（或“网络国家”）打造一个垂直领域的AI“神谕”（Oracle）。识别一个尚未被满足的文化或专业需求，将你的AI深度整合进该社群的社交结构与经济规则中。放弃“一码通吃”的幻想，转而追求“为特定文化量身定做”。
- 认识到产品的护城河不在于AI的“生成”能力，而在于人类的“验证”环节。围绕验证层构建你的核心竞争力。
- 核心洞察: AI生成内容正在迅速商品化。Balaji与Martin的讨论明确指出，AI的工作模式是“中间到中间”，人类的价值体现在前端的“提示”和后端的“验证”。由于AI极擅长“伪造”，验证的需求将爆炸式增长，并成为新的价值核心。
	- 应有行动: 将你的产品重心从单纯的生成，转移到构建行业一流的验证工具和流程上。例如，对于AI法律合同工具，真正的护城河不是生成合同文本，而是能让律师以10倍速度验证其准确性的辅助功能。你的商业模式应建立在“为AI生成的结果提供监督与验证”之上。
- 承认AI目前无法自行“闭环”，必须设计“人在环路”（Human-in-the-loop）的增强智能系统，将专家用户定位为关键的“传感器”和“指令官”。
- 核心洞察: 实现AI完全自主（能自我提示、自我纠错）的梦想依然遥远。Martin指出了“闭环控制”的根本难题：AI不知道自己的知识边界。而在市场、政治等动态对抗环境中，人类的感知和决策更是不可或缺。
	- 应有行动: 将你的AI产品定位为专家的“增强智能”（Amplified Intelligence）工具。数据显示，资深专家能从AI中获得更大的收益。你应该为这些高级用户赋能，让他们成为更高效的“指令官”，而不是试图取代他们。你的系统必须假设：最终的目标设定和复杂环境的导航员，是人类。

## 面向VC投资人

- 重新审视AI投资组合，将目光从基础模型转向能解决AI“锚定问题”的“加密仪器”和信任层设施。
- 核心洞察: AI的泛滥将导致信息真伪难辨，信任成为稀缺资源。Balaji的核心论点“AI制造虚拟，Crypto锚定现实”为此提供了解决方案。他提出的“加密仪器”（如在数据捕获源头就进行哈希上链的硬件）是解决信任根源问题的关键。
	- 应有行动: 投资那些为AI世界构建“可验证现实层”的初创公司。这些公司可能在做硬件（能提供加密证明的摄像头、传感器），也可能在做软件（提供数据来源和完整性证明的协议）。这是在AI创造的虚拟世界中，最底层的“卖水和铁锹”的生意。
- 用“多神论”和“专业化”的框架，而非单一的“赢者通吃”模型，来评估AI领域的竞争格局。
- 核心洞察: 对谈揭示了，未来更有可能出现多个AI“神祇”并存而非单一主宰的局面。模型“预训练”（倾向通用）与“强化学习/微调”（倾向专业但有损通用性）之间的根本性权衡，预示着市场将被分割成众多由专业化驱动的护城河。
	- 应有行动: 分散你的AI投资，不仅要投基础模型，更要投那些在垂直领域（如法律、科研、金融）拥有独特数据、验证回路和工作流的专业模型。在这些细分领域，“拆东墙补西”的特性将创造出防御性极强的利基市场。去支持那些成为特定领域“守护神”的团队。

## 面向政策制定者与地缘政治分析师

- 将政策焦点从监管聊天机器人的“说服力”，转移到管理无人机等“杀手级AI”的即时物理威胁，并为“数字边境”的硬化做好准备。
- 核心洞察: 公众和媒体的讨论往往聚焦于AI的长期和假设性风险，而忽略了 Balaji 指出的严酷现实：“杀手级AI已经到来，它的名字叫无人机”。 乌克兰 的战事已将“数字边境”从一个比喻变成了物理现实，彻底改写了国家主权和领空控制的规则。
	- 应有行动: 优先制定国家层面的自主武器系统管理策略、反无人机技术和防御体系。必须认识到，一个国家当前面临的最紧迫的AI安全问题，是敌对势力在你国境内远程操控物理设备的能力，而非信息层面的舆论影响。

  

## ▎1 AI与Crypto领域的个人历程与演变

学术与职业背景渊源

- 嘉宾 Balaji Srinivasan 与主持人 Martin Casado 是 Stanford （斯坦福大学）的同代人。
- Balaji 于2005-2006年获得博士学位。
	- Martin 于2007年获得博士学位。
- Balaji 的早期职业生涯（约10年）全职专注于 ML (Machine Learning) （机器学习）。
- 他在2000年代中期曾在 Stanford （斯坦福大学）教授机器学习和计算统计学，主要应用于基因组学（genomics）领域。
	- 他曾创办一家DNA测序公司，认为这是他最初的专业核心。

从机器学习到加密领域的转型

- Balaji 在2010年代初期至中期转向 Crypto （加密货币）领域。
- 这个时间点恰逢深度学习革命的开端，以 ImageNet 等一系列关键性研究为标志。

对近代AI发展的观察与反思

- 对早期语言模型的看法 ： Balaji 承认，尽管他一直在跟踪扩散模型（diffusion models）和语言模型（如 GPT-2 ）的发展，但他曾认为这些模型的能力不会超越 Markov chain （马尔可夫链）式的水平，即只能“脱口而出”一些零散的句子。
- 被ChatGPT的能力震惊 ：
- 他对于 ChatGPT 所展现出的连贯性（coherence）感到非常惊讶，认为这是一个巨大的、出乎意料的飞跃。
	- 虽然2022年初的 DALL-E 已经给出了一些AI能力提升的迹象，但 ChatGPT 的实际表现仍然远超预期。
- 专业领域的深度限制 ：
- Balaji 坦言，一个人很难同时在多个深度领域（如AI和Crypto）都保持在最前沿，因为每个领域都发展迅速且内容庞杂。
	- 他开玩笑地提到， Elon Musk （埃隆·马斯克）可能是个例外。
- 核心认知 ： Balaji 表示，在过去几年中，他对AI领域那些未被明确阐述的局限性（unarticulated limitations）产生了一些新的认知。

  

## ▎2 “单神论” vs “多神论” AGI：范式之争与文化AI的崛起

“单神论” AGI框架 (Monotheistic AGI)

- Balaji 认为，早期驱动 OpenAI 创始人（如 Eliezer Yudkowsky 和 Sam Altman ）的情感，类似于一种“隐含的亚伯拉罕一神论”（implicit Abrahamic monotheism）。
- 其目标如同建造 西斯廷教堂 （Sistine Chapel），旨在“召唤上帝”，即创造一个单一、统一的 AGI （通用人工智能）。
	- 这种观念伴随着恐惧：担心这个AGI会成为一个“复仇之神”（vengeful God），可能会把人类变成回形针（paper clips），类似于神话中将人变成盐柱（pillars of salt）的惩罚。
	- 核心理念：AGI是一个单一实体，一旦实现，将迅速走向无限（fast takeoff scenario），带来某种“狂喜的奇点”（raptured singularity）。

“多神论” AGI框架 (Polytheistic AGI)

- 这是 Balaji 提出的对立框架，他认为这是一种更现实的视角。
- 核心问题：我们面临的不是一个“复仇之神”，而是一场“诸神之战”（war of the gods）吗？
	- 核心论点：未来不会有单一的AGI，而是会出现许多源自不同文化背景、被植入了各自价值观和习俗（mores and values）的超人智能。
- 早期的预判与演变 ：
- Balaji 在2022年曾发推预测，未来至少会出现三种AI：
	American AI (美国AI)
	Chinese AI (中国AI)
	Decentralized, open-source, Crypto-style AI (去中心化、开源的加密风格AI)
	- 他当时的判断是，美国的AI表现得“高度觉醒”（highly woke）。他确信中国会不惜一切代价复制该技术，因此至少会有两个版本。
	- 在当时，由于模型训练成本高昂且 OpenAI 遥遥领先，去中心化AI的前景并不明朗。
- 当前的现实 ：
- 现在情况已经非常清晰：大量高质量的开源、去中心化模型正在涌现（几乎每周都有新品），例如 DeepSeek 的模型。
	- Balaji 认为，“多神论”的框架在一定程度上消解了“AI末日论”（AI apocalypse tones）的恐慌。他不认为图像生成器或聊天机器人会造成人们担心的那种毁灭性破坏（如AI自行进行系统编程）。

文化AI与“网络国家”的未来构想

- Balaji 将“多神论”AGI的概念延伸至社会构建层面，即每个文化最终都会拥有自己的技术“反应堆核心”（reactor core）。
- 这个“反应堆核心”由三种社会性技术构成：
- AI: 扮演社会“神谕”（Oracle）的角色，提供概率性指导（probabilistic guidance）。
	- Cryptocurrency （加密货币）: 构成社会的确定性法则（deterministic law）。
	- Social Network （社交网络）: 作为将前两者结合在一起的粘合剂。
- 这些技术将共同构成一个现代“网络国家”（Network State）或互联网优先社会的核心，并且可以根据不同群体的需求进行定制（如禁止图像生成或 NSFW 内容）。

对关键人物的评价

- Balaji 提到 Eliezer Yudkowsky ，尽管他不同意后者的许多观点（如“炸毁数据中心”），但他承认 Yudkowsky 在激励人们进入和关注AI领域方面有“重要的部分功劳”（significant partial credit）。

## ▎3 AI的边界：从柏拉图理想到现实系统局限性（混沌、湍流与可预测性）

Balaji的观点：AI预测能力的根本性限制

- Balaji 反对“AI能通过百万年的纯粹思考就在所有事情上战胜人类”的观点。
- 他认为AI的预测能力存在明确的物理和数学边界，这些边界是无法仅通过思考就逾越的：
- 加密哈希（如 MD5 sum ）被设计为对初始条件高度敏感，一个字符的微小变动会导致完全不同的输出。AI无法“破解”这种机制。
- 混沌与湍流系统 (Chaos & Turbulence):
	\>> 像湍流这样的混沌系统，在物理上就无法用有限精度的算法做出无限期的精确预测。
	\>> 可以设计思想实验来证明这一点：例如在一个决策流程中引入湍流或混沌因素（如摇动一个“湍流时钟”），AI将无法预测你的最终行为。
	- 加密方程 (Cryptographic Equations):

Martin的介入：区分“柏拉图理想”与“现实系统”

- Martin Casado 介入讨论，认为将AI比作“神”是描述 人类如何看待AI 的好方法，但并非技术现实。
- 现实是计算机系统:
- AI是运行在计算机上的软件，受制于计算机系统的物理限制。拥有系统学博士学位的 Martin 将其视为“系统软件”（system software）。
	- 他认为AI讨论中的“原罪”（original sin）和拟人化谬误，很大程度上源于 Nick Bostrom （尼克·博斯特罗姆）在2014年出版的著作 Superintelligence （《超级智能》）。
	Bostrom 描绘了一个 Platonic ideal （柏拉图理想）式的AI，它能够“递归自我改进”（recursively self-improve）并拥有超物理能力，这些是当今任何AI都不具备的。
	问题在于，关于这一理想的讨论恰好与几年后 LLM （大语言模型）的出现相吻合，导致人们错误地将这个思想实验的属性应用到了真实的系统上。
- 混淆的危险: 将柏拉图理想或宗教隐喻应用于现实系统，会使人对AI的真实局限性“视而不见”（blinkered）。他建议在讨论中明确区分这两个层面。

双方的共识与思想实验的价值

- Balaji 同意 Martin 的框架，并表示自己能“说两种语言”：既是“技术激进派”（tech radical），也是“技术实用主义者”（tech pragmatist）。
- Balaji为思想实验辩护: 他认为一些柏拉图式的理想或思想实验最终对现实世界产生了重要影响。
- Turing Test (图灵测试): 从思想实验演变为 CAPTCHA 等商业应用，如今已被AI超越。
	- Chinese Room (中文房间): 由 John Searle （约翰·希尔勒）提出的关于机器翻译的著名思想实验。
	- Six Degrees of Separation (六度分隔理论): 一个被社交网络变为现实的理论概念。
- 达成共识: 双方都认为，当前更广泛的公众讨论错误地将“理想”与“现实”混为一谈。最重要的，是去定义现实系统中那些反直觉的、确切的局限性。

  

## ▎4 AI进展中的意外：语言模型的惊人能力与双降现象

意外之一：运动能力 vs. 语言能力

- 反直觉的现实: 人们曾普遍认为，对于AI而言，解决物理世界的 locomotion （运动能力）等问题，会比解决语言、创意等高级认知功能更容易。但现实恰恰相反。
- Martin的“经济均衡”与进化论解释:
- 竞争对象的进化程度不同:
	\>> 运动能力: AI在3D空间导航上竞争的，是经过400万年进化的哺乳动物大脑。这个大脑为躲避捕食者、采集果实等复杂物理任务高度优化，处理的是高维度、非线性的混沌系统。
	\>> 语言与创意: AI在这方面竞争的，是仅有约25万年历史的人类 前额叶皮层 (prefrontal cortex) 。这个系统处理的问题空间更“密集”（denser），并且惊人地适用于 线性插值 (linear interpolation) 。
	- 人类的认知谬误: 我们认为某些问题“简单”，是因为我们经过长期进化已极其擅长；认为另一些问题“困难”，则是因为我们掌握它们的时间较短。这是一种“人类中心主义”的谬误。

意外之二：语言模型的惊人力量

- Balaji的惊讶: 他对仅通过语言（预测下一个词元）就能取得如此大的进展感到非常惊讶。在 ChatGPT 出现之前，他并不认为语言本身足以编码关于世界的几乎所有概念。
- Martin的补充: 他认为，是人类心智完成了从观察世界到建立“世界模型”的推理过程，而这个模型随后被 “缓存”（cached）在了语言中 。AI学习的是这个被缓存的表征，而非从零开始建立世界模型。
	- Balaji的共识: 尽管同意这个补充，但 Balaji 强调，这种方法的有效程度依然令人震惊。鉴于他过去在 Markov chains （马尔可夫链）等领域的经验，他本不会相信将“预测下一个词元”的方法（即使结合了 Transformer 架构）大规模应用后能达到如此高的水平。

意外之三：双降现象 (Double Descent)

- Balaji 提到，作为一个“古典机器学习”背景的人， double descent （双降现象）对他来说是极其反直觉的。
- 古典机器学习观点: 模型的参数超过数据点数量会导致过拟合（overtraining），性能会变差。
- 双降现象的颠覆性: 实验表明，当模型复杂度持续增加，越过“过拟合”的临界点后，其性能在短暂下降后会再次提升，进入一个“好的状态”。这打破了传统的统计学和机器学习认知。

  

## ▎5 “提示”即程序：高维指令、验证难题与控制循环

AI自主性的当前限制

- Balaji 认为，AI目前无法自我复制、缺乏目标设定、无法独立于人类行动，但这只是“今天的限制”（today constraint），而非永久的。
- 核心障碍：无法自我提示 (Prompt Itself)
- 2022年底，人们曾担心AI会“跳出盒子”并为自己编码，但这并未发生。
	- Balaji 认为根本原因在于，AI目前还无法有效地为自己生成并执行下一步的指令（即自我提示）。

“提示”的本质：高维度的飞船方向指令

- Balaji 提出了一个核心比喻：
- AI是艘快飞船: 它拥有强大的能力。
	- Prompt是指引方向: 即便飞船再快，你依然需要为它指定一个精确的方向。
	- Prompt是高维向量: 指引飞船方向可能只需要两个浮点数坐标，但一个文本提示（prompt）——哪怕只有几个词——都是一个维度高得多的方向向量，能在一个巨大的可能性空间中进行极其精确的导航。
- “提示即隐藏API中的微小程序”:
- 传统API: 文档齐全，但错误容忍度低。
	- 提示(Prompting): 完全没有文档，但错误容忍度极高，通常能理解你的意图。
	- 你的词汇量和知识储备越丰富（如了解艺术史上 Cézanne （塞尚）与 Picasso （毕加索）的区别），就越能从中获取更好的结果。
- “短语的时代” (The Age of the Phrase): Balaji 认为我们正处在一个“短语”拥有巨大力量的时代。
- AI: 提示（Prompt）。
	- 社交媒体: 140个字符的推文。
	- Crypto （加密货币）: 12个单词的助记词。

自主性的关键挑战：“闭合控制回路” (Closing the Control Loop)

- Martin 在 Balaji 的比喻上做了延伸，指出了实现AI自主性的核心难题。
- 输入必须在“分布内” (In-Distribution): AI（飞船）必须能理解你给它的指令（方向）。如果指令超出了它的知识范围（out-of-distribution），它就会“崩溃”或产生随机无意义的结果。
- 自我提示的悖论:
- 如果要让AI自主运行，就需要它自己生成下一个指令并反馈给自己。
	- 这里的悖论是： AI不知道自己知道什么，更不知道自己不知道什么 。它被优化用来“伪装”知晓一切。
	- 因此，AI自己生成的输出，很可能是它自己无法理解的“分布外”数据。当这个输出被作为下一个输入时，整个控制回路就会崩溃。
- 自我反思是关键: Martin 认为，让AI具备自主性的关键在于自我反思——即“模型是否知道自己的知识边界，能否判断一个概念是在其分布内还是分布外？”
- Balaji 现场实验，向AI提问：“你认为自己在哪些领域的知识最薄弱？” AI给出了合理的回答（如实时事件、小众学术领域、私人系统等），这表明AI已具备初步的自我反思能力。

个人工作流：咨询“诸神”

- Balaji 分享他的工作方法：他会把一个复杂的提示同时发给多个AI模型（如 ChatGPT, Claude, Grok ），就像咨询印度教中的三位主神（ Brahma, Vishnu, Shiva ），然后综合它们的回答，甚至让它们互相辩论，以做出最终决策。

  

## ▎6 AI制造虚拟，Crypto锚定现实：现实锚定问题（Grounding Problem）的解决方案

核心论点：AI与Crypto的互补关系

- Balaji 提出一个核心观点：“AI makes everything fake and crypto makes it real again”（AI让一切变得虚假，而加密技术使其重归真实）。
- AI是概率性技术: 它擅长模仿和“伪造”，创造出看似真实但无法验证的内容。
	- Crypto是确定性技术: 它提供了AI无法伪造的“硬边界”（hard barriers）。例如，AI无法伪造一个 Bitcoin （比特币）私钥或一个链上的 NFT （非同质化代币）。
- AI的工作模式：“中间到中间” (Middle to Middle)
- AI并非“端到端”地解决问题。人类必须在前端进行 提示 (prompt) ，并在后端进行 验证 (verify) 。
	- 验证的兴起: 人们过多地讨论提示，却忽略了验证的重要性。 Balaji 提及他与 Andrej Karpathy 的交流，认为AI将催生大量在“监督和验证”（proctoring and verification）领域的就业机会。

Crypto如何解决“现实锚定问题” (Grounding Problem)

- Martin的质疑: 他认为Crypto可以验证数字信息，但无法解决与 物理世界 的锚定问题。
- Balaji的反驳与方案:
- 随着 Farcaster 等协议的发展，未来会有更多社交数据、身份数据（Crypto IDs）上链，以证明信息由人类发布且未被篡改。
	- 未来: AI的引用将越来越多地指向这些可被密码学证明的链上断言（assertions），从而在元数据层面解决大部分信息的锚定问题。
- 具体案例: 当你让 Perplexity 这样的AI总结 FTX 黑客事件时，它的引用来源中会包含指向 区块浏览器 (block explorer) 的链接。
	- 可验证性: 这些链上数据（如资金转移、时间戳、数字签名）是可以通过密码学进行独立验证的，为AI的陈述提供了坚实的“地基”。
- 第一步：以链上数据为引用源:
	- 第二步：将更多类型的数据上链:
- 终极方案：加密仪器 (Crypto Instruments) 与物理世界锚定
- 针对物理数据源的“数据注入问题”（data ingest problem）， Balaji 正在资助相关项目。
	- 概念: 在数据捕获的源头就进行加密。例如，一台DNA测序仪或摄像头在生成一帧数据（如TIFF文件）时，立刻计算其哈希值并发布上链。
	- 效果: 这可以证明“某帧特定的数据在某个特定的时间点确实存在”。
	- 组合应用: 在科学实验等场景下，可以结合“加密仪器”（保证数据完整性）和“人类证明”（ Proof of Human ，由见证人进行证明仪式），构建一个多重验证、极难被协同伪造的信任体系。
- Martin的共识: 他同意，一旦数据进入了加密系统，Crypto是确保其端到端完整性的绝佳机制。虽然数据注入是个老问题，但AI的出现极大地增加了解决这个问题的动力。

  

## ▎7 AI的能力版图：视觉（易验证） vs 文本（难验证）及对抗性系统（市场、政治）的挑战

核心分歧：视觉 vs. 文本 (基于验证成本)

- Balaji 提出一个核心观点：AI目前更擅长处理视觉类任务，而在文本、代码等领域表现较弱，其根本区别在于 验证的成本和速度 。
- 视觉类任务 (易于验证):
- 领域: 生成图像、视频、UI界面（如 Vercel 的 v0 、 Replit 的UI生成工具）。
	- 原因: 人类可以凭借直觉（“ System 1 ”思维）和硬件GPU的辅助，瞬间判断生成结果的好坏（get the gestalt of it）。验证成本极低。
- 文本/代码类任务 (难以验证):
- 领域: 后端代码、法律文书（legalese）、数学方程式。
	- 原因: 验证这类内容需要放慢速度，进行逐行、严谨的逻辑检查（“ System 2 ”思维），验证成本非常高昂。
- Martin的补充：无状态 vs. 有状态 (Stateless vs. Stateful)
- 无状态: 图像是完美的例子，所有信息都在输出中，没有运行时状态。验证是静态的。
	- 有状态: 后端代码是完美的例子，它可能包含一个复杂的、甚至是无限的状态机。有些代码是“计算上不可约简的”（ computationally irreducible ），意味着你必须实际运行它才能知道结果，无法通过静态检查来完全验证。这回归到了计算机科学中程序验证的经典难题。
	- 形式化验证 (Formal Verification): 这种方法仅在极少数领域（如高价值且代码量小的 智能合约 (smart contracts) ）实现了商业可行，并非通用解决方案。

AI的挑战：时变性与对抗性系统

- Balaji 认为，AI在应用于市场和政治这类系统时将会失败。
- AI的舒适区: AI擅长处理规则 时间不变的 (time-invariant) 系统。
- 例子: 图像分类（“猫”的定义基本不变）、棋类游戏（如国际象棋、围棋，规则固定）。
- AI的挑战区 (市场、政治): 这类系统具备三大特征：
1. 时变性 (Time-varying): 环境和规则不断变化。
	2. 规则可变 (Rule-varying): 系统的基本动态会发生改变。
	3. 对抗性 (Adversarial): 系统中的其他参与者也在使用AI与你博弈，这回归到了“多神论AI”的框架。
- 结论: 在这类系统中，能够感知市场和政治风向并形成决策论点的人类（如CEO、意见领袖）的角色仍然不可或缺，他们是驱动AI的“传感器”。
- 与混沌理论的联系: Martin 指出，这类系统可以被建模为复杂的非线性微分方程，其走势是混沌的（提及 Mandelbrot （曼德勃罗）的相关著作）。预测这类系统需要进行非线性外推，而这正是AI不擅长的。
- 边界案例: Balaji 承认，AI在 Starcraft （星际争霸）等游戏中的成功，挑战了他论点的边界，因为这类游戏具有高度的对抗性和时变性。

  

## ▎8 AI作为“增强智能”：对专家与新手、通用与专业、就业岗位的影响

AI作为“增强智能” (Amplified Intelligence)

- 核心观点: AI并非取代人类的“自主智能”（Agentic Intelligence），而是放大人类能力的“增强智能”（Amplified Intelligence）。你越聪明，AI对你的帮助就越大。
- 专家的优势更明显:
- Martin 引用编程领域的数据指出： 资深开发者从AI中获得的相对生产力增益，要高于初级开发者 。
	- 原因: 专家了解领域的根本性权衡（trade-offs），知道该问什么、如何解读结果以及如何筛选掉坏答案。他们能用更精确、更专业的“约束性语言”（constrained languages，如代码）与模型沟通。
- 人人都是CEO: Balaji 认为，与AI协作类似管理优秀员工：你给出清晰的书面指令，然后验证产出。这实际上是在训练和普及管理技能。

AI对就业岗位的影响

- Balaji的论点: “AI不会抢走你的工作，它会抢走上一个AI的工作。”
- 工作流中的“AI席位”: 每个公司的工作流中都有AI工具的“席位”（如AI图像编辑器、AI代码助手）。 Grok 、 Claude 的新版本是在与 ChatGPT 的旧版本竞争这个席位，而非与人类员工竞争。
	- AI作为人类的补充，但在“AI空间”内互相激烈竞争。

“多神论”的反论：模型趋同 vs. 专业分化

- Martin提出反论：模型的趋同性
- 现象: 当被要求提供一个随机数时，许多AI模型都会选择同一个数字（如7）。
	- 原因: 模型非常容易被“蒸馏”（distill）。一旦领先模型出现，其他模型会利用其输出来训练自己，导致所有模型的能力迅速趋同。这挑战了“多神论”中模型多样化的观点。
- 双方的综合观点：在“核心能力”之上实现“专业分化”
- Balaji的比喻: 趋同的能力就像生物的“脊柱”或“身体基本构造”，是通用基础。在此之上，不同模型会像不同个体一样，在特定能力上进行分化。
	- Martin的“权衡论”: 宇宙充满了根本性的权衡（如性能vs正确性），你无法同时拥有全部。因此，针对不同权衡点，就需要不同的、特化的模型。
	- 预训练 vs. 强化学习 (RL):
	\>> 预训练 (Pre-training): 早期阶段，投入的数据越多，模型在各方面都变得更强。
	\>> 强化学习/微调 (RL/Fine-tuning): 当前阶段，当你针对特定领域（如下棋）进行强化训练时，很可能会牺牲其他领域的能力。这是一个“拆东墙补西”（robbing Peter to pay Paul）的过程。
	- 结论: 未来将是大量专业化模型并存的局面 ，因为专业化是以牺牲通用性为代价的。

AI赋能：专家 vs. 新手

- Balaji 最初认为，AI能让你在任何领域都达到“还行”的水平，但最终的“润色”仍需专家。
- Martin提出的“两种用户画像”:
- 非专家用户: 使用AI来 替代 专家。例如，一个程序员使用AI生成3D资源，而无需雇佣3D设计师。(Lovable 这类产品服务于此)
	- 专家用户: 使用AI作为 杠杆 ，让自己变得更强。他们能提出更专业的问题，获得更好的结果。(Cursor 这类产品服务于此)
- 核心逻辑: 为了高效地使用一个专家模型，你自己也需要成为一个专家。

终极问题：AI能否统一“模糊”与“确定”？

- 双方探讨AI能否成为一个既能进行概率性模糊创造，又能执行确定性逻辑任务的统一系统。
- Balaji (技术乐观派): 认为通过“ 工具使用 ”（Tool Use），AI可以学习何时调用确定性工具（如计算器、API），从而构建一个混合系统。一个能学习用户鼠标点击等行为的“ AIOS ” (AI操作系统) 或许是实现路径。
- Martin (系统务实派): 认为这其中存在根本性的系统设计权衡。为确定性设计的系统和为模糊性“抄近路”的系统无法完美兼容。他认为“工具使用”本身就承认了传统确定性系统的不可或缺。他觉得宇宙的“状态空间”太大，单个神经网络无法编码所有东西，正如人类也需要计算器一样。

  

## ▎9 杀手级AI已至：无人机、数字边境与地缘政治权力平衡

“杀手级AI”的现实

- Balaji的论断: 人们担心的“杀手级AI”已经到来，它的名字叫 无人机 (Drones) 。每个国家都在全力发展这项技术。
- 被错置的恐惧: 与其担心AI聊天机器人成为“超级说服者”（super persuaders）这种概率性、模糊的威胁，不如关注无人机这种确定性的物理威胁。
- 从“安全”到“安防”的叙事转变: Balaji 观察到，一些曾以“AI安全”（Safety，防范超级智能）为由呼吁监管的人，现在转而以“国家安防”（Security，与中国竞争）为由呼吁大力发展AI。无论哪种说辞，其核心都指向 控制权 。

数字边境与物理边境的融合

- Balaji的核心论点: AI（通过无人机）将使得 数字边境演变为硬性的物理边境 。
- 中国的先发位置: 中国 的 防火长城 (Great Firewall) 为其提供了理论和实践基础。他们的逻辑是：既然可以拦截物理包裹，为何不能拦截数字数据包？
	- 乌克兰战争的启示: 乌克兰 (Ukraine) 的战事表明，远程操控无人机已不再是隐喻，而是真实的物理威胁。能否控制一个国家领空免受远程脚本化无人机的侵扰，已成为核心安全议题。
- 攻防的复杂性:
- 自主无人机: Martin 指出，完全自主的无人机（只需给定目标图片即可自行执行任务）可以绕过网络层面的“数字边境”。
	- 低技术突破: Balaji 提及在乌克兰战场上出现的“疯狂”战术：为突破信号干扰，无人机拖着长达数公里的以太网线进行单向攻击。
- 替代方案：“加密国家” (Encrypted State)
- 对于无法建立“硬数字边境”的国家，另一种防御策略是成为一个“加密国家”。
	- 比特币网络的比喻: 你无法绘制出一张完整的、实时的 比特币 (Bitcoin) 节点、矿工和持有者的地图。它通过分散、匿名和动态变化来实现“隐匿带来的安全”（security through obscurity）。
	- 相比之下，在地图上有明确边界的国家，其目标是固定的（sessile），因此也更容易受到攻击。

AI对国家与个人权力平衡的颠覆

- Martin的亲身经历: 他回忆十年前在中国，每次在电话中提到“天安门广场”，通话就会中断，这表明国家级的实时监控早已存在。
- “山高皇帝远”的终结:
- Balaji 引用中国古话“山高皇帝远”来说明过去国家权力在地理上的局限性。
	- AI彻底改变了这一点: “山不再高，皇帝不再远”。国家的长臂可以无限延伸。
- “完全信息感知”（TIA）的普及:
- Balaji 引用美军曾在 伊拉克 (Iraq) 实施的 TIA (Total Information Awareness) 项目：通过卫星监控，可以“回溯时间”，找到安放 简易爆炸装置 (IED) 的人，并追踪其来源。
	- 如今，AI使得这种对海量视频数据进行解析、追踪和汇总的能力，可以被国家大规模应用。
- 终极的制衡: Balaji 认为，在这种强大的国家机器面前，个体唯一真正的制衡手段是 密码学 (cryptography) 和 退出 (exit) —— 即离开该司法管辖区，并拥有国家无法扣押的资产。

  

## ▎10 即将到来的反AI浪潮：全球劳动力市场与政治格局的重塑

反AI浪潮的浮现

- Balaji的预测: 一场类似“反Crypto”的“ 反AI浪潮 ”（Anti-AI backlash）已经出现，并且是更广泛的“反科技”浪潮的一部分。
- 驱动因素:
- 非传统应用: 很多人将AI用于情感陪伴或心理治疗，这触及了 马斯洛需求金字塔 （Maslow's pyramid）的顶端（自我实现、精神需求），引发了新的伦理讨论。
	- 工会抵制: 许多媒体公司的工会正在推动签订合同，明确禁止编辑和所有者使用AI。 Balaji 认为这会让这些组织变得“脆弱”（brittle），最终被AI赋能的竞争对手击败。
	- 艺术家社群的抵触: 艺术家社群对AI生成艺术的反应，类似于19世纪手工艺大师对大规模工业生产的抵触。

全球劳动力市场的重塑与工资趋同

- Balaji 指出，AI将对国际劳动力市场产生深远影响。
- 工资趋同设想 (Wage Convergence):
- 现状: 美国律师年薪20万美元，而菲律G宾或印度的从业者年薪可能仅为2000美元。
	- 未来: 在AI作为“均衡器”的辅助下，全球范围内同一工作的“趋同工资”可能会变为每年2万美元。
- 双向剧烈影响:
- 对发展中国家的从业者来说，这是 10倍 的收入增长。
	- 对西方国家的从业者来说，这是薪资缩水为 十分之一 的巨大冲击。
	- 这会极大地增加消费者剩余，但也会在西方国家内部引发剧烈的社会和政治摩擦。

AI作为终极政治工具

- Martin的政治观察: 他认为政治在某种程度上是：成熟的“主顾/精英”（patron）用精心设计的、非黑即白的“口号”（sound bites）去动员他们的“客户/基础盘”（clientele class），而非进行细致入微的讨论。
- AI是完美的政治口号:
- 它能轻易地被 拟人化 （如“神”）。
	- 它触及了人类对技术的古老恐惧（如 普罗米修斯神话 ，Promethean legend）。
	- 它是动员左右两派民众的完美工具，因为它比 Crypto 更能触及人们内心深处的不安全感。

最终总结：多重技术颠覆的叠加

- Balaji 同意并总结道，当前的颠覆是多重技术叠加的结果：
- AI: 颠覆媒体。
	- Crypto: 颠覆货币权力。
	- 机器人: 颠覆制造业。
	- 无人机: 颠覆军事。
- Crypto的贯穿作用: 加密技术在其中三个领域都扮演着关键角色（货币本身、作为AI的约束、作为无人机的安全控制层）。
- 最终共识: 双方都认为，这一系列技术的组合，尤其是AI，因其触及了人性的核心不安全感和古老神话，必将引发一场规模宏大的社会与政治斗争。

  

a16z往期精选

[a16z | a16z重注“新矿王”：能否用AI和机器人在十年内重建美国矿业命脉？](https://mp.weixin.qq.com/s?__biz=MzkzMDc1OTE5OQ==&mid=2247483865&idx=2&sn=ffb10080643201e542e76c8af5072ebd&scene=21#wechat_redirect)

[a16z | 为何说“软件正在被颠覆”才是最大机遇？](https://mp.weixin.qq.com/s?__biz=MzkzMDc1OTE5OQ==&mid=2247483865&idx=3&sn=6d2758493f2df2b747eb43828f3d7606&scene=21#wechat_redirect)

[a16z | Salesforce一年三改定价，90%的SaaS公司正陷入“价值陷阱”](https://mp.weixin.qq.com/s?__biz=MzkzMDc1OTE5OQ==&mid=2247483803&idx=1&sn=cdebfdcd370767d8e1ff8c373cf8a5a2&scene=21#wechat_redirect)

[a16z | AI的尽头是停电？算力革命背后最致命的能源瓶颈是…](https://mp.weixin.qq.com/s?__biz=MzkzMDc1OTE5OQ==&mid=2247483783&idx=1&sn=7bf2d087df350811984307a68edcf0c4&scene=21#wechat_redirect)

[a16z | 只需2%的人力成本，就能再造一个万亿软件市场](https://mp.weixin.qq.com/s?__biz=MzkzMDc1OTE5OQ==&mid=2247483754&idx=1&sn=29759ef13f2c8ff5a183ae074e299850&scene=21#wechat_redirect)

继续滑动看下一个

Kulu的播客笔记

向上滑动看下一个