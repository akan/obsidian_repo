---
title: "范式颠覆！LIMI凭78样本完胜GPT-5，重塑AI能动性"
source: "https://mp.weixin.qq.com/s/vJvWGDZ7RWiRsZ8G6s_LEA"
author:
  - "[[Weixin Official Accounts Platform]]"
published:
created: 2025-10-15
description: "LIMI已上线始智AI-wisemodel开源社区，欢迎大家前去体验。"
tags:
  - "AI能动性"
  - "数据效率"
  - "协作编程"
  - "科学研究"
  - "范式转变"
abstract: "LIMI研究通过仅78个高质量训练样本在AI能动性基准测试中超越GPT-5，颠覆了传统数据规模决定模型性能的认知，确立了能动性效率新原则。"
---
*2025年10月14日 18:15*

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/4heHKEq5K4oRibrleiaDiaicmFww1ONIGtFwm6yK94rxRqCjosXK3gkMXZRhTMLZ8JEMfWmPAESQibgxEpPMpw7T10g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

始智AI wisemodel.cn社区是源自中国的中立开放的AI开源社区。正在 [招募 | 新一期开源共创志愿者计划](https://mp.weixin.qq.com/s?__biz=MzkwNzUwMDU4Mg==&mid=2247487603&idx=1&sn=30dff50f1ea956e339e9cdb521750977&scene=21#wechat_redirect) ，欢迎加入共同成长。 [wisemodel推出邀请注册奖励活动，最高可得算力券+token包380元奖励，欢迎参与和支持！](https://mp.weixin.qq.com/s?__biz=MzkwNzUwMDU4Mg==&mid=2247492522&idx=1&sn=9f48cc719cf516b6ced7d5ce039d8596&scene=21#wechat_redirect)

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/4heHKEq5K4q4ed8h822nshHL0G0MXR9GjrQAzHRgyx36dHia6spf8iaw5NXiauF9XNhMADK7UcQML6QIp09Sjvmvg/640?wx_fmt=jpeg&from=appmsg&wxfrom=5&wx_lazy=1&tp=webp#imgIndex=1)

从ChatGPT到Claude，从Codex到Claude Code，全球科技公司正在"能动性"领域展开激烈竞争。这一趋势反映了产业界的关键认知： 能动性能力正成为AI系统的核心竞争力 ，决定着AI能否从简单的对话工具演进为真正的工作伙伴。具备能动性的AI系统将重新定义人机协作模式，成为推动各行各业智能化转型的关键技术。

什么是"能动性"？它是AI系统主动发现问题、制定假设，并通过与环境和工具的自主交互执行解决方案的能力。 **这种能力的重要性在于，它使AI从被动响应工具转变为主动执行的智能助手** ，能够独立完成复杂的知识工作任务。例如， **让模型从零开始开发一个完整的五子棋游戏** 需要模型具备需求理解、架构设计、代码实现、调试优化等完整的自主执行能力。这种协作编程场景代表了现代知识工作的典型需求， **而具备这种能力的AI系统将能够承担大量现实世界的复杂任务** 。

同样，在科研工作流程中，模型需要完成从文献调研到实验设计，从数据分析到洞察生成的完整链路。 **能动性使AI能够独立推进科学研究进程，这对于加速科学发现具有重大意义** 。

**能动性能力的培养难度远超传统AI能力，因为它要求模型具备长期规划、多步推理、工具协调和自主纠错等高阶认知能力** 。当前主流方法普遍认为复杂的能动性能力需要大量训练数据支撑，遵循传统的规模化定律。这导致了资源密集型的训练流程：收集数万甚至数十万个训练样本，消耗大量计算资源，但效果往往不尽如人意。

LIMI的研究结果表明， **仅使用78个复杂多轮交互轨迹样本，** 模型就能在能动性基准测试AgencyBench上达到开源模型的最佳表现，还超越了GPT-5的性能。相比使用10,000个样本训练的模型，LIMI实现了53.7%的性能提升，数据使用量却仅为其1/128。 **LIMI** 已上线 **始智AI-wisemodel** 开源社区，欢迎大家前去体验。

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/4heHKEq5K4pb5PV0icfn4uynhvBJUF8odfDYn0MCHGEKsVv5QZ5iaO4CGiaX18Ppow9vDtzic1W8S1p9d3RtIJPIicQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=2)

**模型地址**

https://wisemodel.cn/models/GAIR/LIMI-106B

https://wisemodel.cn/models/GAIR/LIMI-355B

https://arxiv.org/abs/2509.17567

https://github.com/GAIR-NLP/LIMI

  

如图展示了一个模型从头开发的完整可运行的五子棋游戏， 这种端到端的自主执行能力正是未来AI系统的核心价值所在 ，证明了其在实际工作场景中的巨大应用潜力。

LIMI的发现挑战了"数据规模决定能力上限"的传统认知，提出了 能动性效率原则 ：模型能动性的发展更依赖于对能动性本质的理解和高质量数据的精准构造，而非简单的数据堆叠。 这一发现为大规模部署具备真正工作能力的AI系统开辟了可行路径 ，表明理解能动性的核心机制比简单扩大数据规模更为重要。

**01.**

**从被动响应到主动工作**

  

能动性大语言模型（Agentic LLMs）的出现，那些能够推理、行动并自主交互的系统，代表着从被动AI助手向具备主动能力模型的范式转变。研究团队将 **能动性** 定义为AI系统作为自主代理运作的新兴能力：主动发现问题、制定假设，并通过与环境和工具的自主交互执行解决方案。

这一根本能力标志着"AI 能动性时代"的到来，其驱动力来自一个关键的行业转变：迫切需要 **不仅会思考，更会工作** 的AI模型。虽然当前AI在推理和生成响应方面表现出色，但产业界需要能够执行任务、操作工具并推动现实世界成果的能动性模型。

然而，能动性模型的训练面临着关键挑战。当前方法普遍假设更多数据能让模型产生更强的能动性能力，遵循语言建模的传统扩展定律（scaling laws）。这种范式导致了日益复杂的训练流程和大量资源需求，但一个根本假设仍未得到检验： **模型的能动性能力是否一定需要大量训练数据，还是可以通过精心构造高质量样本更高效地涌现？**

相邻领域的新兴证据暗示了一个令人信服的替代范式。LIMA仅用1,000个精心策划的样本就实现了有效的模型对齐，而LIMO证明复杂数学推理能力能够从仅817个战略性选择的训练样本中涌现。这些发现表明，精心构造高质量数据可能在培养复杂AI能力方面比数据集规模根本上更强大。

研究团队的LIMI给出了答案： **模型的能动性能力可以通过与传统扩展方法不同的发展原则进行提升** 。通过战略性聚焦协作软件开发和科学研究工作流程，这些领域涵盖了大多数知识工作场景，研究表明复杂的能动性能力可以从少量但精心构造的高质量数据中涌现。

如图2所示，LIMI仅用78个训练样本就让模型在AgencyBench 上达到73.5%的性能，不仅超越了所有基线模型，而且相比使用10,000个样本训练的模型实现了53.7%的性能提升， **用128倍更少的数据让模型获得了卓越的能动性能力** ，彻底颠覆了"更多数据=更强能动性"的传统认知。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

图 2：LIMI 在 AgencyBench 超越 GPT-5 和众多开源模型

**02.**

**协作编程与科学研究工作流**

  

为了验证LIMI提出的战略性数据构造方法，该研究聚焦于两个需要完整能动性能力谱系并涵盖大多数知识工作场景的基本领域。

**协作编程** 代表LLMs与人类开发者在上下文丰富环境中协作的软件开发模式。这个领域需要：跨现有代码库的代码理解和生成，通过复杂工具生态系统的开发环境导航，通过调试和优化循环的迭代问题解决，以及技术协调的协作沟通。复杂性在于对开发上下文的整体理解和在不断变化需求下的原则性决策制定。

**科学研究工作流程** 涵盖复杂科学研究过程，包括文献搜索、数据分析、实验设计和洞察生成。这些工作流程需要：对多样化信息来源进行综合，采用适当方法论的实验设计，复杂结果的数据分析和解释，以及跨不同利益相关者格式的知识沟通。

这些任务展现出显著的 **时间复杂性** ，表现为需要连贯状态跟踪和累积推理的多轮交互。它们需要 **战略规划能力** ，将复杂目标分解为可管理的子目标，同时基于环境反馈适应性调整策略。 **工具编排能力** 变得至关重要，因为现实世界的能动性任务需要模型协调调用多个不同工具来完成复杂任务。

如图3所示的用户查询示例展现了单个查询的巨大复杂性——从基础到专家级递进的五子棋开发任务涵盖Web前端开发、数据过滤、状态管理、规则启发式AI和高级搜索算法等多个相互关联的子任务。这种复杂性覆盖了规划、执行和协作等维度，展现了高质量演示中学习信号的密集性。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

图3：用户查询示例，展示了单个查询如何在规划、执行和协作维度上包含多个相互关联的子任务，证明了高质量数据中学习信号的密集性。

**03.**

**精准数据构建的系统化方法**

  

LIMI方法的有效性根本依赖于战略性数据构造，通过真实世界协作任务捕捉本质的能动性行为。该研究团队围绕能动性交互的基本要素形式化数据构建过程，将每个完整交互定义为元组 **<用户查询，能动性轨迹>** ，其中用户查询启动协作工作流程，轨迹捕获完整交互序列。

如图4所示，LIMI的训练数据展现了显著的高质量特征：轨迹长度分布广泛，平均达到42.4k tokens，最长可达152k tokens，远超传统训练样本的长度。右侧的领域覆盖图显示了数据在协作编程和科学研究工作流程两个核心领域的广泛分布，涵盖了从前端开发、调试、工具调用到论文搜索、深度学习、实验工作流程等多个细分方向。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

图4：LIMI训练数据的特征。左图：轨迹长度分布显示交互复杂性（平均42.4k tokens）。右图：涵盖vibe编程和研究工作流的全面覆盖。

  

1、用户查询池构建：真实性与系统性的结合

**查询收集策略系统性地结合真实世界场景与战略性覆盖扩展，确保生态有效性和充足的训练多样性。**

**真实世界用户查询收集** ： LIMI从专业开发者和研究者在协作环境中遇到的实际场景收集60个查询。这些查询代表跨两个核心领域的真实挑战，具有自然复杂性和上下文丰富性。值得注意的是，大量研究查询来自真实学术论文，确保收集的用户查询具有可信的代表性。

**基于GitHub PR的查询合成** ： 为了在保持真实性的同时系统性扩展查询池，团队开发了使用GPT-5从GitHub Pull Requests合成额外查询的流水线。这种方法利用真实代码更改的丰富上下文，采用GPT-5的先进推理能力生成反映真实开发需求的协作场景。

系统性策划过程涉及多个质量保证阶段：（1）选择具有超过10,000 GitHub stars的高质量代码仓库，（2）确保软件开发领域的综合覆盖，（3）基于复杂性和实质性进行过滤，（4）采用四名计算机科学博士生作为专家标注员评估合成查询的质量，确保语义对齐和上下文准确性。

通过这种系统化方法，团队最终构建了包含78个高质量用户查询的综合池，每个查询都代表来自协作编程或科学研究工作流程的真实协作场景。

2、轨迹收集：捕获最优能动性行为

为了生成展示最优能动性行为的训练轨迹，研究需要能够支持真实人机协作的复杂执行环境。这个环境必须支持复杂工具交互、维护详细交互日志，并提供现实能动性智能评估所需的操作上下文。

团队选择 **SII CLI** 作为执行环境，基于其几个关键优势：（1）支持协作编程和研究工作流程的全面工具集成，（2）对高质量训练数据收集至关重要的详细轨迹日志能力，（3）启用自然交互模式的灵活人机协作界面，（4）对需要协调工具使用的复杂多步任务的强大支持。

在SII CLI环境内，四名博士生标注员作为人类协作者，与GPT-5作为能动性模型协作，在真实协作场景中完成78个用户查询的轨迹收集。

对于每个查询，采用 **迭代收集方法** ，持续收集轨迹直到任务成功完成。这种持续性方法确保收集的轨迹捕获真实人机交互模式，包括自然的来回沟通、迭代细化过程和表征有效能动性行为的协作问题解决策略。

正如图3左侧轨迹长度分布所示，这种方法产生了内容极其丰富、交互高度复杂的高质量训练轨迹数据，平均长度达到42.4k tokens，远超常规训练数据的复杂度，为模型提供了密集的能动性学习信号。

**04.**

**突破性实验结果**

  

1、实验设置与评估框架

为了验证LIMI假设并证明战略性数据构造方法的有效性，团队采用了全面的实验框架，跨多个评估维度将方法与强基线模型进行比较。

**基线模型评估** ： 团队评估了多样化的最先进基础模型，确保全面比较：GLM-4.5、GLM-4.5-Air、Qwen3-235B-A22B-Instruct、DeepSeek-V3.1、Kimi-K2-Instruct。这个选择涵盖了具有不同架构设计和训练方法的开源模型，支持对能动性能力的严格评估。

**模型训练与对比实验** ： 为了系统评估策划训练数据的影响，团队使用收集的数据对GLM-4.5和GLM-4.5-Air进行微调。所有微调实验使用slime框架进行，确保一致的训练条件、超参数优化和公平比较。

此外，为了评估数据策划策略的质量和有效性，团队通过在三个替代数据集上微调GLM-4.5进行比较实验：CC-Bench-trajectories、AFM-WebAgent-SFT-Dataset和AFM-CodeAgent-SFT-Dataset。这种实验设计支持战略性策划数据与现有大规模能动性训练数据集的直接比较。

**评估框架** ： 评估包含两个互补策略，全面验证LIMI方法的有效性：（1）在AgencyBench上的主要评估，专门设计用于评估协作场景中的能动性能力；（2）在涵盖工具使用、编程和科学计算的多个基准上的泛化能力评估，确保发现能够泛化到核心领域之外。

2、AgencyBench上的卓越表现

如表 1 所示，在AgencyBench基准测试中，LIMI取得了令人震撼的成绩：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

表1： LIMI 系列模型在AgencyBench上的综合比较。模型按评估目的分组：基线比较、泛化能力评估和数据效率验证。

LIMI达到了 **73.5%的平均得分** ，显著超越了所有基线模型：GLM-4.5（45.1%）、Kimi-K2-Instruct（24.1%）、DeepSeek-V3.1（11.9%）和Qwen3-235B-A22B-Instruct（27.5%）。

性能差距在 **首轮功能完整性（FTFC）** 方面特别明显，LIMI达到71.7%，相比GLM-4.5的最佳基线性能37.8%实现了显著的33.9个百分点改进。类似地，LIMI以74.6%的成功率展示了卓越的任务完成可靠性，大幅超越了最强基线模型GLM-4.5的47.4%。

3、数据效率的极致体现

最震撼的发现是数据效率对比结果，为核心LIMI假设提供了令人信服的实证证据： 战略性数据策划在开发能动性智能方面根本上比简单扩展训练数据量更有效。

LIMI使用仅78个精心策划的训练样本就达到了卓越性能，大幅超越了在数量级更大数据集上训练的模型。最引人注目的是与在AFM-CodeAgent-SFT-Dataset上训练的GLM-4.5-Code的比较：LIMI的73.5%平均AgencyBench性能戏剧性地超越了大规模方法实现的47.8%，尽管使用的数据集 小128倍 （78 vs. 10,000样本）。

**关键数据效率对比：**

- LIMI (78样本) vs GLM-4.5-Code (10,000样本)： 25.7个百分点优势，数据量仅1/128
- LIMI vs GLM-4.5-Web (7,610样本)： 23.5个百分点优势，数据量仅1/97
- LIMI vs GLM-4.5-CC (260样本)： 18.0个百分点优势，数据量仅30%

这些一致的改进证明了战略性数据策划能够比大规模数据收集实现更有效的能力迁移，确立了能动性智能开发中"少即是多"范式的广泛适用性。

4、跨领域泛化验证

如表2所示，LIMI的优势扩展到涵盖工具使用、编程和科学计算的多样化基准测试中，证明方法的广泛适用性。 LIMI达到 57.2%的平均性能 ，超越所有基线模型，包括GLM-4.5（43.0%）、Kimi-K2-Instruct（37.3%）、DeepSeek-V3.1（29.7%）和Qwen3-235B-A22B-Instruct（36.7%）。

值得注意的是， LIMI在关键编程基准上达到了最高性能（EvalPlus-HumanEval：92.1%，EvalPlus-MBPP：82.3%），并在工具使用任务上展示了竞争性结果（TAU2-bench-airline：34.0%，TAU2-bench-retail：45.6%）。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

表2：泛化基准测试的综合性能比较。HE代表EvalPlus-HumanEval，MP和SP分别代表SciCode的主要问题和子问题指标。平均值包含了 AgencyBench 的表现。  

  

不仅如此，LIMI方法出色的泛化能力还体现在跨规模泛化和跨架构泛化两个关键维度。在跨规模方面，Qwen3系列展现了显著的改进效果，从小型模型Qwen3-4B性能翻倍（从4.6%提升到8.6%，增幅达87%）、Qwen3-8B提升45.2%，到Qwen3-32B实现144%的大幅提升，GLM-4.5也达到63%的改进，证明该方法在整个模型规模谱系上都持续有效；在跨架构方面，无论是密集型transformer架构（Qwen3系列）还是专家混合架构（GLM系列）都表现出显著改进，证明该方法捕捉到的是与具体模型实现、参数分布或计算架构无关的基本智能体行为模式，从而验证了战略性数据策展在智能体开发中具有广泛的适用性和有效性。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

图5：不同模型在LIMI微调前后的性能对比。经LIMI训练的模型在AgencyBench（左图）和其他基准测试（右图）上均展现出一致的性能提升

**05.**

**能动性效率原则**

  

  

基于实验结果，研究建立了 能动性效率原则 ：模型能动性的涌现并非来自简单数据的堆砌，而是来自高质量能动性数据的精心构造。

这一发现根本重塑了开发能动性大模型以及AI Agent的方式，表明掌握能动性需要理解其本质，而不是简单的扩大训练数据规模。

LIMI促成了能动性训练范式的根本性转换：从"更多简单数据→更强能动性"的旧范式，转向"更高质量的能动性数据→更强能动性"的新范式。LIMI认为：能动性本质上是"潜伏"于预训练模型中的，关键挑战不是训练新能力，而是找到激活路径。

**06.**

**产业影响与未来展望**

  

  

1、对AI产业生态的重塑

LIMI的发现对整个AI产业生态具有深远影响：

**研发效率革命** ：小团队凭借精准方法可以与大公司竞争，降低了能动性技术的门槛，促进更多创新性方法的涌现。

**资源配置优化** ：将投入重点从数据收集转向高质量样本设计和生成，从"资源竞赛"转向"数据构造方法竞赛"。

**应用落地加速** ：为实际能动性系统的开发提供了高效可行的路径，在实际应用中提供了具体的指导原则：专注核心场景、完整流程轨迹、质量优先策略。

2、商业化前景与技术普惠

LIMI方法的商业化前景广阔：降低开发成本，减少对大规模数据和计算资源的依赖；缩短开发周期，通过精准方法快速获得能动性突破；提高应用效果，在特定领域达到更好的性能表现；普惠化应用，让更多中小企业能够负担得起能动性技术。

3、未来发展方向

虽然LIMI目前主要验证了协作软件开发和科学研究两个领域，但其原理有望扩展到医疗诊断能动性、教育辅导能动性、商业分析能动性等更广阔的认知领域。

未来的能动性系统将发展为多模态能动性，融合视觉、语言、行动等多种模态；自主学习能动性，从被动激活发展到主动进化；以及更完善的理论体系，建立能动性激活的数学模型和评估框架。

4、开启能动性新时代

LIMI不仅是一项技术突破，更是AI发展理念的根本性转变。它证明了在能动性开发中，理解本质比扩大规模更重要，质量比数量更关键。

78个精心设计的样本击败万级数据的事实，确立了能动性发展的全新原则： **模型能动性来自精心构造，而非数据堆砌** 。当模型从思考型AI转向工作型AI时，LIMI为真正能动性的可持续培养提供了新范式，开启了能动性发展的新纪元，未来充满无限可能。

编辑丨赵雅鑫  

\----- END -----

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**往期推荐**

**关于wisemodel更多**

1

**欢迎持续关注和支持**

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

开源社区建设需要长期坚持和投入，更需要广大用户的积极参与、贡献和维护，欢迎大家加入wisemodel开源社区的志愿者计划和开源共创计划。期待更多开发者将开源成果，包括模型、数据集和代码等发布到 wisemodel.cn 社区，共建中立、开放的AI开源社区生态。欢迎扫码添加wisemodel微信，申请加入wisemodel社群，持续关注wisemodel.cn开源社区动态。

  

2

**欢迎加盟wisemodel开源社区**

始智AI wisemodel社区自2023年9月上线以来，逐渐成为影响力日益扩大的中立开放的AI开源社区，为了加快公司发展，我们长期需要技术、运营等人才加盟，技术侧重在AI infra、后端开发，熟悉K8S、模型训练和推理等技术， 以及熟悉开发者生态运营的成员，欢迎感兴趣的朋友加盟，可以通过添加wisemodel微信，或者将简历投递到邮箱：liudaoquan@wisemodel.cn

  

3

**欢迎投稿优质内容**

欢迎投稿分享人工智能领域相关的优秀研究成果，鼓励高校实验室、大企业研究团队、个人等，在wisemodel平台上分享各类优质内容，可以是AI领域最新论文解读、最新开源成果介绍，也可以是关于AI技术实践、应用和总结等。投稿可以发邮件到liudaoquan@wisemodel.cn，也可以扫码添加wisemodel微信。

  

4

**关于wisemodel开源社区**

始智AI wisemodel.cn开源社区由清华校友总会AI大数据专委会副秘书长刘道全创立，旨在打造和建设中立开放的AI开源创新社区，将打造成“HuggingFace”之外最活跃的AI开源社区，汇聚主要AI开源模型、数据集和代码等，欢迎高校科研院所、大型互联网公司、创新创业企业、广大个人开发者，以及政府部门、学会协会、联盟、基金会等，还有投资机构、科技媒体等，共同参与建设AI开源创新生态。

  

继续滑动看下一个

始智AI wisemodel

向上滑动看下一个