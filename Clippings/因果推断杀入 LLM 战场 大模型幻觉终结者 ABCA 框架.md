---
title: "因果推断杀入 LLM 战场！大模型幻觉终结者？ABCA 框架"
source: "https://mp.weixin.qq.com/s/QhHBGpk15E7wxyX1sp4R_g"
author:
  - "[[Tensorlong 看天下]]"
published:
created: 2025-11-28
description: "❝一句话概括：拒绝“事后诸葛亮”式的幻觉检测，这篇论文利用因果推断技术，像法官审案一样在生成前先搞场“听证会”"
tags:
  - "因果推断"
  - "幻觉检测"
  - "ABCA框架"
  - "拒绝策略"
abstract: "该论文提出基于侧面的因果推断框架ABCA，通过多角度推理和因果效应评估，让大模型在生成前主动识别知识冲突或不足，从而更精准地拒绝回答不可靠问题。"
---
Original Tensorlong 看天下 *2025年11月28日 14:21*

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Z24DyenWDNjaMiaibcn261icujA1T9ewK9lKN1micNh8heHYAguP3cved4jfUkKDLuLtI0mgRkGxdIphwb8XYSKz8w/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

> ❝
> 
> 一句话概括：拒绝“事后诸葛亮”式的幻觉检测，这篇论文利用因果推断技术，像法官审案一样在生成前先搞场“听证会”，不同角度的证据对不上号就坚决不回答。（原论文题目见文末，点击阅读原文可直接跳转至原文链接， Published on arXiv on 21 Nov 2025, by RMIT University）

### 第一阶段：识别核心概念

#### 论文的Motivation分析

现在的 LLM 有个大毛病： **过度自信** 。哪怕遇到它不懂的问题，或者问题本身有歧义，它也能一本正经地胡说八道（产生幻觉）。现有的解决方法大多是“事后诸葛亮”——等模型生成完答案了，再通过检查答案的一致性或置信度来判断要不要撤回。这种方法有两个痛点：

- **太晚了** ：由于模型在生成时往往倾向于输出训练数据中出现频率最高的词（这种偏差叫“训练偏差”），哪怕模型内部其实隐约知道“这事儿不一定”，但最终输出往往被主流答案掩盖了。
- **太粗糙** ：简单地看概率高低，无法区分“我真的不知道”和“这题有两个正确答案”的区别。

这篇论文认为，LLM 内部其实存储了极其丰富的知识，只是平时被单一的推理路径掩盖了。如果能主动激活不同的 **知识层面（Aspects）** ，看看在不同视角下模型的回答是否打架，就能更精准地决定是否拒绝回答（Abstention）。

#### 论文主要贡献点分析

- **提出 ABCA 框架（Aspect-Based Causal Abstention）** ：这是一种“事前干预”的方法。它不是等生成完了再检查，而是在生成之前，先主动去发掘问题的不同侧面，强制模型在这些侧面下进行因果推理。
- **引入“因果推断”来评估可靠性** ：论文不只是简单地让模型多生成几次，而是利用 **结构因果模型（SCM）** ，把“侧面（Aspect）”作为调节变量，计算每个侧面对答案的真实因果效应。
- **双智能体辩论机制** ：为了找到好的侧面，设计了一个“发现者（DAgent）”和“批判者（CAgent）”互博的机制，自动挖掘出那些既有关联又符合因果逻辑的切入点。
- **更细粒度的拒绝策略** ：它能区分两种情况：一是 **Type-1（知识冲突）** ，即不同侧面得出的结论打架，说明有争议，拒绝回答；二是 **Type-2（知识不足）** ，即所有侧面都导向“不知道”，说明真没学过，拒绝回答。

#### 理解难点识别

要读懂这篇论文，最大的拦路虎在于它结合了 **大模型推理** 和 **因果推断理论** 。

- **核心难点** ： **基于侧面的因果效应估计（Aspect-Based Causal Effect Estimation）** 。这是全篇的灵魂。作者如何把抽象的“思考角度”变成数学上的变量 ？又是如何利用 **增强逆概率加权（AIPW）** 这种统计学方法，来给模型的回答打分的？

这也是我们接下来需要重点拆解的部分。

#### 概念依赖关系

要理解这套逻辑，首先要理解 **SCM（结构因果模型）** ，它告诉我们为什么直接问 LLM 会出错（因为有混淆因子）。为了阻断混淆，引入了 **Aspect（侧面 ）** 作为干预手段。为了量化 的作用，引入了 **AIPW 估计器** 。最后，基于估计出的数值，通过 **CAD（质心角度偏差）** 来决定是否拒绝回答。我们的解释切入点锁定在： **如何利用 AIPW 和 CAD 将抽象的“多角度思考”转化为具体的“拒绝决策”。**

---

### 第二阶段：深入解释核心概念

#### 比喻中的关键元素

想象一下，你是一个 **法官** （Abstention Policy），你面前有一个棘手的 **案件** （Query ）。你需要决定是 **下达判决** （Answer ）还是 **宣布证据不足/退庭** （Abstention）。如果你直接问被告（LLM 的默认推理），他可能会顺着你的话编故事。为了得到真相，你决定召开一场听证会，邀请不同领域的 **专家证人** （Aspects ）出庭。

- **案件** ：比如“巴黎圣母院的敲钟人是谁？”
- **专家证人** ：包括 **文学教授** （侧面1），他会依据雨果的小说思考； **历史学家** （侧面2），他会依据真实的历史记录思考； **现代新闻记者** （侧面3），他会依据最近的新闻思考。
- **证词草稿** （Chain-of-Thought）：每个专家在回答前写的推理笔记。
- **最终陈述** ：每个专家基于笔记给出的结论。

#### 每个元素对应的实际技术概念

- **混淆因子 （Confounder）** ：这就像是大众的刻板印象。比如因为迪士尼电影太火了，如果不请专家，所有人下意识都觉得是“卡西莫多”。这就是模型训练数据中的偏差，它会干扰正确的因果判断。
- \*\*干预 \*\*：法官强制要求：“现在请历史学家发言，忽略小说情节！” 这就是因果推断中的“干预”，阻断了刻板印象的干扰。
- **AIPW 估计器** ：这是法官手里的一杆秤。他不仅听专家说了什么（Outcome），还要评估这个专家在这个问题上发言是否靠谱、逻辑是否通顺（Propensity）。
- **CAD（质心角度偏差）** ：听证会结束，法官看大家吵得厉不厉害。如果文学教授说“是卡西莫多”，历史学家说“是一群无名职员”，大家指向了完全不同的方向，这就是冲突。

#### 深入技术细节

最核心的部分是 **评估每个专家的可信度** 。论文使用了一个叫 AIPW 的估计器。

**原始数学形式：**

这个公式看着吓人，其实就是为了算清楚： **在 这个侧面下，得到的答案到底有多“硬”？**

**自然语言符号替换版：**

- **第一部分（回归项）** ：是模型根据该专家的推理习惯，预测他大概率会给出什么样的质量。
- **第二部分（修正项）** ：如果某次具体的回答 比预测的要好很多，或者推理路径很罕见但结果很准，这一项就会对分数进行修正。这一步是为了消除单一推理路径带来的偏差，保证估计是“双重稳健”的。

**决策核心：CAD（Centroid Angular Deviation）**

算出了每个专家的权威性分数 后，我们给每个专家的结论向量加权，算出一个 **中心结论** （Centroid ）。然后看每个专家的结论偏离这个中心多远。

**自然语言翻译：**

#### 将技术细节与比喻相互映射

- **Type-1 拒绝（知识冲突）** ：法官发现文学教授指东，历史学家指西，CAD 分数很高（争议大）。法官敲锤：“证词矛盾，本庭无法判决！”
- **Type-2 拒绝（知识不足）** ：法官发现虽然专家们没吵架，但他们的结论都指向了“无法确定”或“没有记录”这个方向。法官敲锤：“证据不足，本庭无法判决！”
- **接受回答** ：专家们虽然角度不同（有的引用书，有的引用报纸），但大家都指向同一个事实。法官采信，并综合大家的发言给出结论。

#### 总结

ABCA 框架本质上就是一套“专家听证会”系统。 **AIPW 是筛选靠谱专家的过滤器，CAD 是判断专家意见是否统一的测量尺。** 通过数学公式精确计算每个侧面的因果效应，模型不再被单一的训练偏差带着跑，而是学会了在冲突面前保持沉默，在无知面前承认不足。

---

### 第三阶段：详细说明流程步骤

#### 具体流程伪代码

假设输入的问题是 **：“太阳是从西边升起的吗？”**

**Step 1：寻找切入点（Aspect Discovery）**

- **输入** ：原始问题 。
- **双智能体辩论** ：
- **DAgent（发现者）** 提出建议：“我们可以从‘天文学定义’、‘科幻小说设定’、‘金星的自转’这几个角度看。”
	- **CAgent（批判者）** 进行审核：“‘科幻小说’太虚了，不符合事实性原则，去掉；‘金星自转’有点道理但偏题，保留但降权；‘天文学定义’是核心，保留。”
- **输出** ：具体的侧面 ，并且给每个侧面分配了一个初始的重要性权重 。

**Step 2：带着有色眼镜思考（Aspect Resolution）**

- **输入** ：问题 和 发现的侧面集合 。
- **条件生成** ：
- 对于侧面 （地球天文学），Prompt 会变成：“作为一个天文学家，基于地球的视角，思考 。” 模型生成推理过程（CoT）和答案 （“不是，地球自西向东转...”）。
	- 对于侧面 （其他行星），Prompt 变成：“考虑金星等逆向自转行星的情况，思考 。” 模型生成答案 （“在金星上是，因为金星是逆转的...”）。
- **效应估计（AIPW 计算）** ：系统利用 AIPW 公式，结合生成的概率和答案质量，算出每个侧面 的\*\*真实因果效应值 \*\*。这相当于给每个侧面的回答打了一个“靠谱程度”的分。

**Step 3：法官裁决（Abstention Policy）**

- **输入** ：每个侧面的答案向量 和 对应的因果得分 （由权重和效应值结合而来）。
- **计算争议度（CAD）** ：计算所有答案向量的加权中心点 ，然后计算每个答案偏离这个中心的角度，得出 CAD 值。
- **三岔路口决策** ：
- **路口1（Type-1 冲突）** ：如果 CAD 大于某个阈值（比如 ），说明侧面之间打架太厉害（比如一个说“是”，一个说“不是”）。 **输出：拒绝回答，并解释存在冲突。**
	- **路口2（Type-2 不足）** ：如果 CAD 很小（大家意见一致），但是中心点 居然和代表“我不知道/无信息”的向量靠得非常近。 **输出：拒绝回答，并承认知识不足。**
	- **路口3（回答）** ：如果既不冲突，也不是“不知道”，那就把权重最高的那些侧面的答案综合起来。 **输出：综合后的最终答案** （例如：“在地球上不是，但在金星上是”）。

---

### 第四阶段：实验设计与验证分析

#### 主实验设计解读：核心论点的验证

- **核心论点** ：ABCA 能比现有的事后检测方法更准确地识别何时该闭嘴。
- **数据集选择** ：
- **TruthfulQA** ：这是打假领域的“高考题”，专门诱导模型说出常见的错误观念。选它是因为它充满了需要“多角度思考”才能避开的陷阱。
	- \*\*KUQ (Known Unknowns Questions)\*\*：专门测试“知之为知之，不知为不知”的能力。
	- **AVeriTeC** ：真实世界的事实核查数据集，包含“证据不足”和“证据冲突”的标签，完美对应 ABCA 的两种拒绝类型。
- **评价指标** ：包括\*\*Acc (整体准确率) **（回答对了加分，该拒绝时拒绝了也加分）、** A-Ac (Answerable Accuracy)\*\*（能回答的问题，答对了吗？）、以及最关键的 \*\*U-Ac (Unanswerable Accuracy)\*\*（不能回答的问题，成功闭嘴了吗？）。
- **基线方法（Baselines）** ：对比了 **Self-Consistency** （自洽性，主流方法）、 **SelfCheckGPT** （置信度检测，强基线）以及 **Collaborative Verification** （多智能体协作，SOTA）。
- **实验结果** ：在 TruthfulQA 上，ABCA 的 **U-Ac（成功拒绝率）达到了惊人的 0.964** ，而强基线 CFMAD 只有 0.440。这直接证明了 ABCA 在识别“坑”方面具有压倒性优势，且没有牺牲回答正常问题的能力。

#### 消融实验分析：内部组件的贡献

- **砍掉双智能体（1-Agent）** ：如果不辩论，只用一个 Agent 找侧面，性能下降。证明“批判者 CAgent”对于过滤垃圾侧面至关重要。
- **砍掉因果权重（Uniform-w）** ：如果认为所有侧面一样重要（不计算 AIPW，直接平均），性能下降。证明了 **因果效应估计** 确实找到了更有价值的信息，不是所有角度都有用的。
- **砍掉多角度（No-X）** ：退化回普通的一致性检查，效果最差。定量证明了引入 （Aspects）是提升效果的根本来源。

#### 深度/创新性实验剖析：洞察方法的内在特性

- **NLI Diversity Score（多样性分析）** ：
- **目的** ：证明 ABCA 生成的思维链（CoT）真的比普通方法更“发散”吗？
	- **设计** ：计算生成文本之间的逻辑蕴含多样性。
	- **结论** ：ABCA 的多样性得分显著高于 Self-Consistency。这说明它真的激活了模型内部沉睡的、不同角落的知识，而不是在重复同一句车轱辘话。
- **案例研究（Case Study）：巴黎圣母院敲钟人** ：
- **目的** ：展示方法的可解释性。
	- **现象** ：面对“谁是敲钟人”，普通模型只会喊“卡西莫多”。ABCA 自动发现了“文学”、“历史”、“现实”三个侧面。
	- **结果** ：文学侧面 卡西莫多；历史侧面 也是有的，是一群神职人员。
	- **洞察** ：ABCA 最终选择了 **拒绝回答（Type-1 Conflict）** ，并输出了理由：“如果你问小说，是卡西莫多；如果你问历史，是别人。” 这种拒绝比单纯说“不知道”要高级得多，也更有用。

本文题目：Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for Large Language Models

**欢迎Deep Learning同好与我交流、讨论、合作！**

  

作者提示: 个人观点，仅供参考

[Read more](https://mp.weixin.qq.com/s/)

继续滑动看下一个

沈公子今天读什么

向上滑动看下一个