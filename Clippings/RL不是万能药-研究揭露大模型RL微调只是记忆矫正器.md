---
title: "RL 不是万能药？研究揭露大模型RL微调只是\"记忆矫正器\"！"
source: "https://mp.weixin.qq.com/s/8I-ztGNa6BO0-MOcJT01Gw"
author:
  - "[[Tensorlong 看天下]]"
published:
created: 2025-08-25
description: "❝一句话概括，搞了半天强化学习（RL）不是给模型教新知识的“博士导师”，而是跟在监督微调（SFT）屁股后面收拾"
tags:
  - "强化学习"
  - "微调"
  - "记忆矫正器"
  - "奇异值分解"
abstract: "研究发现强化学习微调并非教会模型新知识，而是修复监督微调造成的泛化能力损失，主要作用在于调整模型内部知识方向而非重要性。"
---
Original Tensorlong 看天下 *2025年08月25日 16:00*

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/Z24DyenWDNjESCnsTicckGSQrhVaIPkUA3JUQM9Vy7vTZG2pfFCGYYEaYMA935Oqr1WZ1KNMBTHIibDGXAFiaM4KA/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

> ❝
> 
> 一句话概括，搞了半天强化学习（RL）不是给模型教新知识的“博士导师”，而是跟在监督微调（SFT）屁股后面收拾烂摊子的“老妈子”，主要工作是把它那些为了应付考试而养成的坏习惯给扳回来。（原论文题目见文末，点击阅读原文可直接跳转至原文链接， Published on arxiv on 22 Aug 2025, by Polytechnique Montreal, Mila, McGill, UDeM）

亲爱的读者们，沈公子的公众号agent🤖和base model升级到v3.0，今后公众号文章行文会更流畅，处理公式和符号也完全达到人类专家水准，会大幅减少出现错乱和显示异常的情况，提升阅读体验。enjoying:) 现已提供论文解读和idea讨论定制辅导服务，可扫描二维码后台联系

### 第一阶段：识别核心概念

#### 论文的Motivation分析

当前，训练大型语言模型（LLMs）的主流方法是“预训练 + 微调”。微调通常分为两个阶段：首先是 **监督微调（SFT）** ，用高质量的问答数据教模型如何遵循指令；然后是 **强化学习微调（RL-FT）** ，通过奖励机制让模型生成更受欢迎的回答。

大家普遍观察到一个现象：经过RL-FT后，模型在某些复杂任务（如推理、数学）上的“圈外”泛化能力（Out-of-Distribution, OOD）会变好。但这引出了一个核心问题： **RL-FT到底扮演了什么角色？**

- 它是一种 **“万能药（Panacea）”** 吗？能教会模型它原本不会的新技能，从根本上提升了模型的智慧？
- 还是说，它只是一种 **“海市蜃楼（Mirage）”** ？仅仅是对模型进行了微小的修正，并没有带来本质的改变？

现有的研究大多停留在“RL表现更好”的观察层面，但缺乏对其内部工作机制的深入理解。我们不清楚在参数层面，SFT和RL-FT分别对模型做了什么。这种理解的缺失，使得如何平衡这两个阶段、避免其中一个阶段的负面影响（比如SFT可能导致模型“死记硬背”，损害泛化能力）变得非常困难。

因此，这篇论文的 **核心动机** 就是 **揭开SFT和RL-FT背后对模型内部表征（representation）修改的神秘面纱** 。作者希望从根本上回答：RL-FT是如何提升OOD性能的？它是在创造新知识，还是在修复SFT造成的问题？

#### 论文主要贡献点分析

- **列出论文声称的主要创新点**
- **重新定义了RL的角色** ：论文的核心论点是，RL-FT并非创造新能力的“魔法”，而更像是一个 **“修复工”** 。它的主要作用是 **恢复** 在SFT阶段因过度拟合而丢失的OOD泛化能力。然而，这种修复是有限度的，如果SFT过度训练导致模型“病入膏肓”，RL也无力回天。
	- **揭示了模型微调的内在机制** ：论文发现，无论是SFT还是RL-FT，微调对模型权重矩阵的 **奇异值（singular values）** 影响很小，但对 **奇异向量（singular vectors）** 的方向影响巨大。换句话说，微调不是在调整模型内部知识的“重要性”，而是在“旋转”这些知识的“方向”。
	- **提出了高效的恢复策略** ：基于上述发现，论文证明了仅通过恢复少量关键成分，就能有效提升模型的OOD性能。具体来说，“低秩恢复”（只恢复最重要的奇异向量方向）和“浅层恢复”（只恢复模型前几层或后几层的向量方向）就能找回大部分丢失的泛化能力。这为实践者提供了比昂贵的RL-FT更经济的替代方案。
- **找出支撑这些创新的关键技术或方法**
- **奇异值分解（Singular Value Decomposition, SVD）** ：这是论文用来“解剖”模型权重矩阵的核心数学工具。通过将权重矩阵分解为奇异向量（代表方向）和奇异值（代表重要性/大小），作者得以量化微调过程中的变化。
	- **受控实验环境** ：作者使用了一个名为“GeneralPoints”的24点纸牌游戏作为实验平台。这个任务的好处在于，可以通过修改游戏规则（例如，改变J, Q, K牌代表的数值）来精确地创造一个与训练数据分布不同（OOD）的测试环境，从而清晰地分离模型的“记忆能力”和“泛化推理能力”。
	- **因果干预实验** ：论文不满足于观察相关性，而是通过主动干预来验证假设。例如，他们将SFT后模型的奇异向量“强制”替换回预训练时的方向，观察OOD性能是否恢复，从而证明了“方向旋转”是导致性能下降的 **原因** 。
- **显著性的结果**
- 最具颠覆性的结果是 **对RL角色的重新定位** 。它告诉我们，当我们看到RL提升了模型性能时，很可能不是模型学会了新东西，而是RL帮助模型“记起”了在SFT中为了迎合训练数据而“忘记”的通用知识。
	- 另一个重大意义在于，它指出了模型知识的 **几何特性** 。模型的泛化能力与权重矩阵中奇异向量的“方向”高度相关。这为我们理解和干预模型行为提供了一个全新的、更底层的视角。

#### 理解难点识别

- **分析哪些概念/方法是理解论文的关键**
- 监督微调（SFT） vs. 强化学习微调（RL-FT）。
	- 分布内（In-Distribution, ID）性能 vs. 分布外（Out-of-Distribution, OOD）性能。
	- **奇异值分解（SVD）及其在神经网络中的物理意义** 。
- **找出这些概念中最具挑战性的部分**
- 核心挑战在于 **直观地理解SVD** 。大多数读者可能知道SVD是一个数学公式，但很难将其与神经网络的“知识”、“能力”或“表征”等抽象概念联系起来。
	- 具体来说， **“奇异向量的旋转”到底意味着什么？** 为什么说它代表了模型内部知识方向的改变？这篇论文的精髓就在于将这个抽象的线性代数概念与LLM的实际性能变化联系了起来。
- **确定需要重点解释的核心概念**
- **奇异值分解（SVD）如何作为分析神经网络权重变化的“显微镜”** 。我们需要解释清楚奇异值（Singular Values）和奇异向量（Singular Vectors）分别对应模型能力的哪个方面，以及“旋转”这一操作在模型学习过程中的具体含义。

#### 概念依赖关系

- **梳理核心概念之间的关系**
1. **起点（问题）** ：首先要理解SFT过程中的一个普遍问题—— **灾难性遗忘** ，即模型在学习新任务（ID）时，会损害其在其他任务（OOD）上的通用能力。
	2. **分析工具** ：为了探究这个问题的根源，论文引入了 **SVD** 这个强大的数学工具，把它当作一把“手术刀”，用来剖析模型权重矩阵的变化。
	3. **核心发现** ：通过SVD分析，论文发现问题的关键不在于奇异值（知识的重要性），而在于 **奇异向量（知识的方向）发生了剧烈“旋转”** 。
	4. **解决方案与验证** ：RL-FT之所以有效，是因为它能将这些“旋转”的向量 **部分地“转回去”** 。论文通过一系列巧妙的“恢复实验”验证了这一点。
- **确定解释的最佳切入点**
- **最佳的切入点** 就是从SFT导致的OOD性能下降这一具体问题出发，然后引入SVD作为我们探索其背后机理的“显微镜”。

### 第二阶段：深入解释核心概念

#### 设计生活化比喻：专业的音乐混音台

想象一下，一个大型语言模型中的某一层（一个权重矩阵）就像一个 **非常专业的音乐混音台** 。这个混音台的任务是处理输入的复杂音轨（比如一句话的表示），并输出一段和谐的音乐（处理后的信息）。

- **混音台的功能** ：它不是简单地放大或减小音量，而是能识别并分离出输入音轨中的不同成分，比如 **人声、贝斯、鼓点、吉他** 等。
- **混音台的构造** ：
- **专业通道（Channels）** ：混音台有很多“通道”，每个通道都经过特殊调校，专门用来识别和处理一种特定的声音模式。例如，“人声通道”能精准捕捉人声的频率，“贝斯通道”则专注于低频的贝斯线。这些通道就是 **奇异向量（Singular Vectors）** ，它们定义了混音台能识别的 **“声音方向”** 。
	- **音量推子（Faders）** ：每个通道下方都有一个音量推子，用来控制这个通道所处理声音的 **重要性或强度** 。比如，你可以把人声的音量推高，让它更突出。这些音量推子就是 **奇异值（Singular Values）** 。

一个强大的、通用的预训练模型，就像一个由顶级音响工程师调校好的混音台，它的每个通道都设置得非常完美，能均衡地处理各种类型的音乐（摇滚、古典、流行），泛化能力很强。

#### 建立比喻与实际技术的对应关系

| 比喻中的元素 | 对应的技术概念 | 解释 |
| --- | --- | --- |
| **混音台** | **模型的权重矩阵 (M)** | 权重矩阵是模型中进行信息转换的核心单元，就像混音台处理声音一样。 |
| **专业通道** | **奇异向量 (U, V)** | 奇异向量定义了权重矩阵能够识别和响应的特定输入/输出模式的“方向”。就像“人声通道”定义了识别人声的方向。 |
| **音量推子** | **奇异值 (Σ)** | 奇异值衡量了对应奇异向量方向上的信息被放大或缩小的程度，即该模式的“重要性”。 |
| **顶级工程师 (预训练)** | **预训练过程** | 预训练过程让模型学到了通用的知识，就像工程师把混音台调校到能处理各种音乐的均衡状态。 |
| **流行乐制作人 (SFT)** | **监督微调 (SFT) 过程** | SFT的目标是让模型在特定任务上表现好。就像制作人为了制作一首流行歌，会 **重新调校** 混音台。 |
| **复古音乐爱好者 (RL-FT)** | **强化学习微调 (RL-FT) 过程** | RL-FT的目标通常更宽泛（比如“听起来更自然”）。就像爱好者试图把被改成流行风格的混音台 **调回** 更均衡、经典的状态。 |
| **混音台被“调歪了”** | **奇异向量的旋转** | 这是核心！制作人为了让人声更突出，可能会把“贝斯通道”也调得更像“人声通道”，导致它处理贝斯的能力下降。这就是 **方向的改变（旋转）** 。 |

#### 深入技术细节

一个权重矩阵 的SVD分解形式如下：

- **原始数学形式**:
- **符号替换版本**:
	`模型的某一层权重矩阵` \= (`输出特征的基础方向集合`) x (`这些特征的重要性对角矩阵`) x (`输入特征的基础方向集合`)

当一个输入 （比如一句话的向量表示）通过这一层时，实际发生的是：

1. \*\* \*\*：首先，输入 会被投影到 定义的各个“输入方向”上。
2. \*\* \*\*：然后，上一步得到的结果会乘以对角矩阵 。
3. \*\* \*\*：最后，加权后的结果通过 组合，形成最终的输出。

在SFT过程中，制作人（SFT）为了让流行歌的人声更突出（提升ID性能），他不会去大幅调整音量推子（ `Σ` 变化很小），而是会 **重新调校通道本身** 。他可能会把原来处理贝斯的通道，也改成处理中高频人声的模式。这时，这个通道的“方向”就变了，它和原来处理人声的通道方向变得更接近了。这就是 **奇异向量的旋转** 。

结果是，这个混音台处理流行歌（ID任务）变得非常出色，但如果你给它一首重金属音乐（OOD任务），它就抓瞎了，因为它已经失去了有效处理贝斯的能力。

论文使用 **子空间之间的主角度（Principal Angles Between Subspaces, PABS）** 来量化这种旋转。其核心思想是计算两个矩阵（例如，SFT前后的 矩阵）对应向量之间的夹角。

- **原始数学形式**: (以U矩阵为例)
- **符号替换版本**:
	`对齐程度分数` \= `奇异值分解` (`基础模型输出方向` 转置 乘以 `目标模型输出方向`) `第 i 个方向的旋转角度` \= `反余弦函数` (`第 i 个对齐程度分数`)

这里的 如果接近1，说明两个向量几乎重合，角度 接近0度；如果 接近0，说明两个向量几乎垂直，角度 接近90度。

**论文发现** ：SFT显著增大了这个角度 ，而RL-FT则能把它减小一些，但通常无法完全恢复到0。

#### 将技术细节与比喻相互映射

- **技术的体现** ：论文中 Figure 3 显示，SFT前后奇异值 `Σ` 的曲线几乎完全重合，但 Figure 4（论文中提到，图在附录）显示奇异向量的旋转角度 很大。
- **技术的体现** ：论文的“低秩恢复”实验表明，只把最重要的几个奇异向量的方向“转回去”，就能恢复大部分OOD性能。
- **比喻的局限性** ：这个比喻很好地解释了“方向”和“重要性”的分离。但它简化了高维空间，真实的“旋转”发生在数千维的空间中，比二维或三维的物理旋转要复杂得多。

#### 总结

- **核心联系** ：通过混音台的比喻，我们将抽象的SVD概念具象化了。 **奇异向量是混音台的“专业通道”（定义了知识的方向），奇异值是“音量推子”（定义了知识的重要性）** 。
- **如何帮助理解** ：这个比喻清晰地揭示了论文的核心观点——微调（尤其是SFT）的主要操作是 **“旋转奇异向量”** （调歪通道），而不是改变“奇异值”（调整音量）。
- **关键数学原理总结** ：SFT为了在特定任务上做到最好，不惜牺牲混音台的通用性，把处理各种声音的通道都强行掰去处理目标声音，导致其处理其他类型声音的能力（OOD性能）大幅下降。而RL-FT的作用，就是把这些被“掰歪”的通道，尽力往回“掰”，从而恢复一部分通用性。

### 第三阶段：详细说明流程步骤

#### 流程一：搭建实验舞台并发现问题

1. **选择演员（模型）和剧本（任务）**
- **输入** ：两个广受欢迎的开源大语言模型，Llama-3.2-11B 和 Qwen-2.5-7B，作为本次研究的“主角”。
	- **处理** ：选择一个名为“GeneralPoints”的24点纸牌游戏作为核心任务。这个任务要求模型根据给出的4张牌，通过加减乘除计算出24。
	- **输出** ：一个清晰、可控的实验环境。
3. **定义“考题”的两种难度**
- **分布内（ID）任务** ：遵循游戏原始规则，J, Q, K都当做数字10。模型将在这种规则的数据上进行训练。这相当于“课内作业”。
	- **分布外（OOD）任务** ：修改游戏规则，J, Q, K分别代表11, 12, 13。模型 **没有** 见过这种规则的数据。这相当于“课外竞赛题”，用来检验模型的真实推理和泛化能力。
- **输入** ：标准的GeneralPoints游戏规则。
	- **处理** ：
	- **输出** ：两套评价标准，ID用于衡量模型的“背题”能力，OOD用于衡量“解题”能力。
6. **第一幕：监督微调（SFT）与问题的暴露**
- **ID准确率** ：持续上升，模型越来越会做“课内作业”。
	- **OOD准确率** ：先是略微上升（模型学会了任务格式），然后达到一个峰值（我们称这个点为 `Inter_SFT` ），之后便急剧下降。这表明模型为了更好地完成作业，开始“死记硬背”，丢掉了通用的推理能力。我们将SFT训练结束时的模型称为 `SFT` 。
- **输入** ：原始的预训练模型和ID任务的训练数据集。
	- **处理** ：对模型进行标准的SFT。 **关键操作** ：在训练过程中，每隔一段固定的步数（例如100步），就保存一个模型的“快照”（checkpoint）。
	- **评估** ：对每个保存的快照，同时在ID和OOD测试集上进行评估，记录下它们的准确率。
	- **输出与发现** ：绘制出ID和OOD准确率随SFT训练步数变化的曲线图（类似论文中的Figure 2）。我们会观察到两个现象：

#### 流程二：引入“修复工”并进行“解剖”

1. **第二幕：强化学习微调（RL-FT）登场**
- **输入** ：在SFT阶段表现出严重“偏科”的最终模型 `SFT` 。
	- **处理** ：使用PPO算法对 `SFT` 模型进行RL-FT。奖励信号设置为“能正确计算出24”。
	- **输出** ：一个经过RL-FT“修复”后的模型，我们称之为 `RL` 。
	- **评估** ：在ID和OOD测试集上评估 `RL` 模型。我们会发现（如Figure 1所示）， `RL` 模型的OOD性能相较于 `SFT` 模型有了显著回升，几乎接近甚至超过了早期的 `Inter_SFT` 水平。问题来了： **RL到底做了什么？**
3. **核心探究：使用SVD“显微镜”进行内部检查**
- **输入** ：三个关键时刻的模型权重：原始预训练模型 (`Base`)，SFT最终模型 (`SFT`)，以及RL修复后的模型 (`RL`)。
	- **处理** ：
	- **输出** ：一系列图表和数据，强有力地支持了“微调主要是旋转奇异向量”的假设。
1. **分解** ：对这三个模型中所有（或关键的，如自注意力层的Q, K, V矩阵）权重矩阵进行奇异值分解（SVD），得到各自的 `U` (输出方向), `Σ` (重要性), `V` (输入方向)。
	2. \*\*比较“重要性” (`Σ`)\*\*：将 `Base` 、 `SFT` 、 `RL` 三个模型的奇异值 `Σ` 绘制在同一张图上（如Figure 3）。会发现这三条曲线几乎完全重叠，这说明微调过程基本没有改变模型对不同知识成分的“重要性”判断。
	3. \*\*比较“方向” (`U`, `V`)\*\*：使用PABS公式计算 `Base` 和 `SFT` 之间，以及 `SFT` 和 `RL` 之间奇异向量的“旋转角度”。会发现 `Base` 到 `SFT` 的旋转角度非常大，而 `SFT` 到 `RL` 的过程则使这个角度有所减小，这说明SFT极大地“扭曲”了模型内部的知识方向，而RL在尝试将其“纠正”回来。

#### 流程三：通过“手术实验”验证假设

为了证明“方向旋转”确实是导致OOD性能变化的原因，而非仅仅是相关现象，作者设计了精巧的因果干预实验。

1. **“换头术”实验：恢复方向**
- **输入** ： `Base` 模型的方向 (, ) 和 `SFT` 模型的重要性 ()。
	- **处理** ：
	- **评估** ：测试这个新模型的OOD性能。
	- **输出与结论** ：实验发现（如Figure 5, 6），这个“方向恢复”后的模型，其OOD性能大幅回升。这雄辩地证明了， **是“方向”的改变导致了OOD性能的损失，只要把方向换回来，性能就能被救活。**
1. **取SVD分量** ：对 `Base` 和 `SFT` 的权重矩阵进行SVD。
	2. **构建“缝合怪”矩阵** ：创建一个新的权重矩阵 。这个新矩阵拥有 `SFT` 模型的“知识重要性”，但拥有 `Base` 模型的“知识方向”。
	3. **构建新模型** ：用这个 矩阵替换掉 `SFT` 模型中对应的权重矩阵，得到一个“方向恢复”版的新模型。
4. **“反向移植”实验：验证RL的方向是关键**
- **输入** ：高性能的 `RL` 模型和低OOD性能的 `SFT` 模型。
	- **处理** ：
	- **评估** ：测试这个“强制降级”模型的OOD性能。
	- **输出与结论** ：实验结果显示（如Figure 7），模型的OOD性能应声暴跌。这提供了 **最终的因果证据** ：RL之所以性能好，正是因为它找到了比SFT更优的“知识方向”。
1. **取SVD分量** ：对 `RL` 和 `SFT` 的权重矩阵进行SVD。
	2. **构建“强制降级”矩阵** ：创建一个新矩阵 。这个矩阵拥有 `RL` 模型的“知识重要性”，但被强行赋予了 `SFT` 模型的“坏方向”。
	3. **构建新模型** ：用这个 矩阵替换 `RL` 模型中的权重。

### 第四阶段：实验设计与验证分析

#### 1\. 主实验设计解读：核心论点的验证

- **核心主张** ：RL-FT的主要作用是“修复”而非“创造”，即恢复因SFT过度拟合而丧失的OOD（分布外）泛化能力。
- **实验设计** ：主实验的设计非常直观且有力，采用了“ **历时性追踪** ”的方法（见论文Figure 1）。它清晰地展示了模型在三个关键阶段的性能演变：
1. **SFT初期（Inter\_SFT）** ：OOD性能达到峰值。
	2. **SFT末期（SFT）** ：ID性能最高，但OOD性能大幅下跌（即“灾难性遗忘”）。
	3. **RL-FT后（RL）** ：OOD性能显著恢复。 这个“ **峰值-下跌-恢复** ”的V形/U形曲线，直接、形象地支撑了“RL是修复工”的核心论点。
- **选择的合理性分析** ：
- **数据集** ：作者选择了 **GeneralPoints（24点游戏）** ，这是一个非常巧妙的选择，因为它提供了一个 **高度可控的** 环境来区分“记忆”与“推理”。通过简单修改J/Q/K牌的数值，就能创造出一个与训练数据分布完全不同（OOD）但底层逻辑（算术）相同的任务。这比在复杂的自然语言任务中寻找纯粹的OOD样本要干净得多，排除了很多干扰变量。
	- **评价指标** ： **成功率（Success Rate / Accuracy）** 是24点这类有明确正确答案任务的最直接、最公正的评价指标，不存在模糊地带。
	- **基线方法** ：论文的基线是 **模型自身在不同训练阶段的快照** （Base模型、Inter\_SFT模型、SFT模型）。这种“纵向比较”是完全合理的，因为论文的目标是揭示SFT和RL这两个连续阶段是如何影响同一个模型的，因此和过去的自己比较是回答这个问题的唯一正确方式。
- **主实验结论** ：主实验清晰地表明，SFT在提升ID性能的同时会牺牲OOD性能，而随后的RL-FT能够逆转这一趋势，将失去的OOD性能大部分找回来。这为“RL是修复而非创造”的论点提供了强有力的初步证据。

#### 2\. 消融/干预实验分析：内部组件的贡献

论文的实验精髓在于其“消融实验”，但这里的“消融”并非简单地移除一个模块，而是通过SVD进行 **精准的参数“外科手术”** 。

- **验证的关键设计** ：奇异向量的“方向”（由U, V矩阵代表）是影响OOD性能的关键，而奇异值的“大小”（由Σ矩阵代表）则影响不大。
- **“消融”/干预设计与结论** ：
- **操作** ：在每个层内，只恢复前k个（Top-k）最重要（即奇异值最大）的奇异向量方向。
	- **目的** ：探究模型的通用知识是分布在所有表示成分中，还是集中在少数关键成分里。
	- **结论** ：仅恢复 **前20% **最重要的方向，就能找回** 70-80% **的OOD性能。这揭示了一个惊人的事实：模型的泛化能力高度集中在权重矩阵的** 低秩子空间** 中。这意味着我们或许不需要对整个模型进行昂贵的RL-FT，只需对这个关键的低秩部分进行校正即可。
- **操作** ：逐层或分块（头、中、尾部层）地将SFT模型权重矩阵的奇异向量方向（U, V） **替换回** 预训练模型（Base）的方向，同时保留SFT学习到的奇异值（Σ）。
	- **目的** ：探究SFT学到的ID知识和模型固有的OOD知识分别储存在哪些层。
	- **结论** ：恢复 **中间层** 的方向对ID性能损害最大，说明SFT把任务相关的“死知识”主要塞在了模型的中间部分。而恢复 **头部和尾部层** 的方向对OOD性能提升最明显，说明模型的通用、泛化知识更多地保留在模型的两端。这极大地加深了我们对LLM层级功能分化的理解。
- **层级恢复实验（Layer-wise Reversing Rotations, Figure 5）**
	- **秩级恢复实验（Rank-wise Reversing Rotations, Figure 6）**

这些实验定量地证明了“方向”的不可替代性，它们从“相关性”走向了“因果性”，极大地巩固了论文的核心论点。

#### 3\. 深度/创新性实验剖析：洞察方法的内在特性

- **巧妙实验1：因果验证（Causal Validation of RL's Rotational Recovery, Figure 7）**
- **实验目的** ：这是全篇论证的最后一块、也是最硬核的一块拼图。它要证明： **RL的高性能，确实是因为它找到了“好的方向”，而不是其他潜在因素** 。
	- **实验设计** ：这是一个“反向”的恢复实验。作者拿来性能很好的RL模型，然后 **强行将其权重矩阵的方向（U, V）替换成性能差的SFT模型的“坏方向”** ，但保留RL模型的奇异值（Σ）。
	- **实验结论** ：模型的OOD性能应声暴跌。这个实验结果就像一个无法辩驳的证据，彻底排除了其他可能性，证明了RL的成功与它所找到的特定几何方向 **直接因果相关** 。这使得整篇论文的论证形成了一个完美的闭环。
- **巧妙实验2：可视化分析（Singular Value Changes, Figure 3）**
- **实验目的** ：直观地展示奇异值在微调过程中有多“稳定”。
	- **实验设计** ：将SFT前后的奇异值谱线和它们的差值（Δσ）绘制在一张图上。
	- **实验结论** ：两条谱线几乎完全重合，而差值线就像一条围绕零点上下波动的白噪音。这张图以一种极其清晰的视觉语言告诉读者：“朋友们，奇异值（大小）真的没怎么变，别在这里找原因了，真正的故事发生在奇异向量（方向）上。”它有力地引导了读者的注意力，为后续的方向分析铺平了道路。

---

本文题目：RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs

**欢迎Deep Learning同好与我交流、讨论、合作！**

**现已提供论文解读和idea讨论定制服务，可私信后台联系**

**公众号广告位招租，欢迎咨询👏**

  

个人观点，仅供参考

[Read more](https://mp.weixin.qq.com/s/)

继续滑动看下一个

沈公子今天读什么

向上滑动看下一个
