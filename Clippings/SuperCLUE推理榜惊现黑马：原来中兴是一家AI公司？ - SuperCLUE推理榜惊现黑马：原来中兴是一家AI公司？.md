---
title: SuperCLUE推理榜惊现黑马：原来中兴是一家AI公司？
source: https://mp.weixin.qq.com/s/H2urbOlVVcFR5b-GA7Rnhw
author:
  - "[[机器之心]]"
published: 
created: 2025-07-01
description: 中兴通讯，这家数万人的科技大厂携 40 年的 ICT 经验也开始加入 AI 赛道了。
tags:
  - 中兴通讯
  - AI赛道
  - 推理榜单
  - 星云大模型
  - 6G网络
  - 【批判-推理】数据飞轮
  - 领域共享属性
abstract: 中兴通讯凭借40年ICT经验进军AI领域，其星云大模型在SuperCLUE推理榜单中夺冠，展示了在AI领域的强大实力。
---
Original 机器之心 *2025年07月01日 13:02*

机器之心原创

**作者：张倩**

> 中兴通讯，这家数万人的科技大厂，凭借40年 ICT 技术积累正式进军 AI 赛道。

  

一家信息通信公司，居然拿到了 AI 推理竞赛的冠军，这事儿有点意思。

  

前段时间，中文大模型测评基准 SuperCLUE 发布了 2025 年 5 月报告。这份报告评估了来自 OpenAI、谷歌、DeepSeek、字节跳动等多家国内外 AI 公司的大模型，并发布了多个榜单。报告显示，虽然海外模型在综合能力上占优，但 国内模型在推理任务中表现亮眼，Doubao-1.5-thinking-pro-250415 与 星云大模型 NebulaCoder-V6 以推理总分 67.4 并列第一 。

  

![推理成绩.jpg](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8ibDkFrNUcs441eSJib7BxVcAf7PuSFrBLHzMounA0sTM7JvDczjMv9DDEaIaNkiaOiaU2xhuIvjYaMg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

SuperCLUE 推理榜单深度聚焦模型的逻辑思维与问题解决能力，涵盖数学推理、科学推理、代码生成三大硬核维度。

  

作为专业赛道的选手，Doubao 的表现并不让人意外。但是，星云大模型 NebulaCoder-V6 着实算得上一匹黑马，因为它来自一家老牌信息通信公司 —— 中兴 通讯 。而且，除了拿下推理榜单第一，它在综合总榜中也表现不俗 —— 与 DeepSeek-R1 并列第二，拿到了银牌。

  

![总榜.jpg](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8ibDkFrNUcs441eSJib7BxVcos0969408y3KAla75IEDfQhStslz088mrwyqMBdFY7TeBXT2XnDqvQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1)

  

这样的成绩让外界对中兴这家公司产生了好奇 —— 毕竟在大多数人的认知里，大模型竞赛是互联网公司和 AI 实验室、创业公司的主场（上榜的模型也大多出自这类机构）。一个常年和基站、交换机打交道的 ICT 厂商，突然在需要抽象思维和逻辑链条的 AI 推理任务中拔得头筹，确实带来了意料之外的「跨界」惊喜。

  

那么， 中兴为什么要这么做？为什么可以做那么好？ 为了弄清楚这些问题，机器之心和中兴通讯的首席战略与生态专家屠嘉顺、星云大模型总工程师韩炳涛、研究员吴琦聊了聊，了解到了通讯与 AI 行业的紧密联系以及星云大模型背后的核心技术，也对中兴这家成立 40 年的科技公司的下一站有了新的认识。

  

中兴通讯，为何重仓押注 AI？

  

在今年 3 月份的 GTC 大会上，英伟达 CEO 黄仁勋曾预言说，「AI 可以彻底改变通信」。

  

屠嘉顺告诉我们，其实这种改变现在就在发生。以基站为例，现在的 4G、5G 基站相比前几年增加了很多，但运维人员数量的增幅却没有那么大。这背后的核心原因是，现在的通信网络大量采用自动化技术，形成了所谓的「自治网络」，大大减少了对运维人员的需求。

  

在即将到来的 6G 时代，这种变革会更加明显。英伟达高级副总裁 Ronnie Vasishta 在一次简报会上提到，「6G 的倒计时已经开始。基础研究已经将注意力转向下一代无线通信。下一代网络将是 AI 原生的 ——AI 将嵌入硬件和软件中…… 下一代无线网络需要连接数千亿台智能设备，这将需要 AI 的支持」。

  

屠嘉顺同意这种「 6G 将是 AI 原生 」的说法。他认为，6G 网络会从设计之初就将 AI 作为其核心组成部分，AI 将贯穿于网络的架构、协议、功能等各个方面。

  

正是因为看到了这一颠覆性趋势的可能性，中兴很早就在 AI 方向做前瞻性布局。在内部，他们成立了多个 AI 相关团队以及星云大语言模型、电信行业大模型这样的大型基础研究团队，并把 智算 等 AI 相关的方向作为重要的战略方向，涵盖 AI 基础设施、AI 数据中心、上层行业应用智能体等多个方面。前段时间，他们开发的 Co-Sight 智能体还登上了 GAIA 基准测试的榜首。

  

其实，除了为未来做准备，当前的中兴也已经与 AI 深度绑定。无论是网络侧、算力侧还是终端侧，中兴都有相关的业务布局。这些业务都需要进行 AI 技术迭代。

  

而且作为一家科技公司，中兴内部也有用 AI 提高研发效率的需求，比如代码自动化。他们研发的星云大模型在其中发挥了重要作用。目前，在内部应用中， 星云大模型每天产生 15 亿 token，合成的代码量已经达到几千万行，公司的 AI 代码占比已经达到了 30% 。

  

从这些维度来看，中兴早已突破大众对 ICT 厂商的固有认知，实质上是以 AI 为核心引擎的科技企业，其发展轨迹正朝着 AI 领域加速演进。

  

星云大模型，何以夺冠？

  

此次星云大模型在 SuperCLUE 推理榜单夺冠，离不开技术团队设计的大模型高效训练优化方案。从预训练到监督微调再到强化学习，他们试图在每一步都激发出模型极致的推理能力。

  

预训练：高效构建知识图谱，帮大模型打好基础

  

预训练阶段的核心目标是提升模型的平均表现，类似于人类学生时代的通识教育。

  

在这一阶段，数据非常重要。但是原始的预训练数据存在的知识缺失和知识错误的问题，是模型产生知识类幻觉的重要原因。

  

针对这些问题， 研究人员设计出了一套高效的知识图谱构建方法，帮助大模型迅速形成准确度极高的知识结构 。

  

具体来说，他们提出了一个名叫 领域共享属性和自校验的图谱知识注入框架 「DASER」 （Domain-Aware Self-validating Entity Representation），该框架能够准确识别预训练文本中的缺失知识和错误知识，再利用搜索引擎从互联网在线检索，补全缺失和更正错误知识，提升模型的知识性能力，让模型「看得多」，又「学得准」，更「懂得深」。

  

![行星.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

什么叫「领域共享属性」？研究人员举了个例子，假如在现成的预训练语料中，火星的知识非常丰富，但木星的数据残缺不全，用传统的预训练数据直接训练必然会缺失大量的木星知识，从而导致模型幻觉。DASER 的创新之处在于使用了同一领域内知识的共享规律 —— 比如行星都具有公转周期、自转周期等共同属性。因此在构建木星知识图谱时，它会根据之前所识别到的行星公共属性去自动填充可复用的属性，并通过网络检索进行缺失数据填充。

  

借助这一方法，星云大模型团队构建了覆盖国家基础学科分类体系的全学科知识图谱。模型训练效率、推理准确性均显著提升，在中兴构建的高难度私域知识类 QA Bench 上， 准确率指标由 61.93% 增长至 66.48% 。

  

![知识图谱.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

监督微调：批判学习 + 数据飞轮，让模型理解复杂指令

  

监督微调（SFT）阶段的目的是将预训练模型拥有的通用潜力转化为特定领域的专业能力，让模型理解并执行复杂指令，这个过程类似于人类的高等教育或职业培训。

  

研究人员介绍说，这一阶段的数据通常有两类：第一类是标准的 QA「问题 - 正确答案」对，用于直接训练模型模仿正确响应；第二类是思维链数据，即在答案中显式包含推理步骤，引导模型分步解决问题。

  

更进一步，还可以使用批判学习（Critique Learning, CL）基于难样本生成特定形式的思维链数据，让模型对错误答案进行批判并验证，从而构建一个持续优化模型推理与批判能力的「批判 - 推理」数据飞轮。

  

在训练模型的过程中，他们发现 批判学习数据效果更为显著 。其原理在于：模型如同人脑，对「异常」（如错误答案）高度敏感。发现错误并提出批判的过程，比单纯接受标准答案更能深化模型的理解。

  

因此，研究人员在 SFT 中引入了批判学习（CL）及成对批判学习（PCL）算法。PCL 的关键流程是：

  

1. 针对困难样本，模型给出初始（错误）回答。
2. 模型对错误回答进行批判。
3. 基于批判信息，模型生成修正后的回答。
4. 利用规则方法验证最终答案的正确性。

  

上述流程将产生 {任务描述，错误回答，批判信息，正确回答} 的四元组训练样本。进一步的，他们发现在模型训练中使用从四元组中抽取 {任务描述，错误回答，批判信息} 三元组，而非直接使用四元组，训练效果会更好。

  

相较于使用纯思维链类数据的 SFT，引入额外 CL/PCL 数据的批判 CFT（Critique Fine-Turing）方法在数学、代码等多项推理中准确率明显上升。

  

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

![批判学习1.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

![批判学习2.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

除此之外，为了让模型在遇到用户复杂指令时也能准确理解并执行。需要让模型看到更多高质量指令数据。为了得到这些数据，他们构造了一个数据飞轮。如下图所示，整个飞轮分为四个模块，其中很多工作可以借助模型来自动完成，比如场景挖掘、候选答案生成。在其中一个关键模块 —— 模型校验中，他们也用到了批判学习。他们借助这种方式获得的数据反哺训练集，迭代地帮模型提高意图理解能力。

  

![数据飞轮.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

强化学习：双阶段强化学习，提升回答精度与严谨度

  

强化学习阶段的目的是通过环境反馈（奖励信号）进一步优化模型的行为策略，使其能够解决更复杂的现实世界问题，类似于人类的职场实战。

  

在这一阶段，星云大模型团队主要关心两个问题：如何提高大模型解决复杂问题的准确率和逻辑严谨性。

  

为此，他们提出了双阶段强化学习，即「先整体纠错→再局部精修」。

  

在纠错阶段，他们引入了「批判性强化学习（CRL）」，选取 STEM 领域的高难度问题进行专项训练，迭代提升模型回答高难度问题的准确度。

  

![强化学习1.png](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

在精修阶段，研究人员发现使用强化学习会导致回答多样性下降。拿代码生成举例，模型可能有多种正确的实现方式， 如果某一种方式因为细微的错误被视为负样本，模型可能会「误以为」这种方法本身是错误的，从而在未来避免使用。这会导致模型生成的答案多样性下降，甚至在海量强化数据优化后无法提供解决方案，从能力「涌现」到能力「崩塌」。

  

为了解决这个问题，他们首先在数据层面，将模型回答错误的样本，通过一个离线的拒绝采样过程，获取「最小修改」纠错样本。再改进传统强化学习算法，单独计算每个 Token 的回报值。这种「更细粒度」的强化学习算法，使模型无论是模型回答还是思维链条都更合理，幻觉明显下降，人类偏好打分提升 13%。

  

从 ICT 到 AI 的无缝切换

  

当 40 年的 ICT 巨头闯入 AI 战场，等待他们的是「跨界」阵痛，还是无缝切换？答案可能是后者。

  

这是因为， AI 和 ICT 看似「跨界」，实际有很多相似之处 ，比如它们的核心都在于数据的处理、交换和存储；都是复杂超大系统的高效协同。

  

具体来说，ICT 涉及多个网元组成的庞大网络，AI 需要芯片、服务器、存储、交换和数据中心组成高效绿色的基座。这些系统不仅需要达到局部最优，还要放在一起进行全局优化。这要求具备全栈的技术积累、工程实践和系统优化能力，而这恰恰是中兴所擅长的，也是他们在未来重要的战略方向 ——「智算」中所要强化的。

  

除此之外，在 AI 这个方向上，中兴也有自己独特的优势。

  

我们知道，AI 的发展是一个跨多学科的复杂工程科学，它的创新进程离不开大量工程实践经验，比如参数调优、算子融合、算法优化…… 其涉及领域之广，技术门槛之高已经让一些早期入局的企业感觉吃力。

  

而从中兴身上，我们能够看到一些走 AI 长期路线的潜质。具体来说，和芯片厂家相比，他们有整体的系统工程能力；和做通算的纯 IT 类厂家相比，他们的组网能力更强；和纯做大模型的厂家相比，他们的硬件能力又更强。所以 综合来看，中兴其实更容易拉起整个产业链 ，无论是硬件开发、软件平台、大模型还是行业应用 ，他们在原来的领域都已经有所涉及。

  

而且，中兴也有巨大的产品生态支撑，这些产品目前正在「AI 化」。如果未来全部 AI 化，市场空间巨大，也能让技术在丰富的场景中快速迭代，形成数据反哺。

  

当传统 ICT 巨头全力拥抱 AI，这场转型会给行业带来怎样的化学反应？答案或许就在中兴接下来的每一步里。

  

© THE END

转载请联系本公众号获得授权

投稿或寻求报道：liyazhou@jiqizhixin.com

  

修改于 2025年07月01日

继续滑动看下一个

机器之心

向上滑动看下一个