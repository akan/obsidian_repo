---
title: "Agent性能暴涨90%，刷榜GAIA可太容易了～"
source: "https://mp.weixin.qq.com/s/dEStwEW8YupOGeZWcUiSyQ"
author:
  - "[[猕猴桃]]"
published:
created: 2025-06-27
description: "亿点点Agent上分攻略"
tags:
  - "Agent构建"
  - "事实获取能力"
  - "逻辑推理保真度"
  - "多模态处理"
  - "多元搜索"
  - "Query调优"
  - "动态规划"
  - "记忆增强"
  - "TTS策略"
abstract: "文章分享了oppo Agent团队关于如何构建高效Agent并提升其在GAIA榜单上表现的干货内容。"
---
![cover_image](https://mmbiz.qpic.cn/mmbiz_jpg/d08lv0anUnjUtibrZMsiciamQxgNtibdRKRe9hibdf7a688PBlNHjibibkricDfTb6piaCuTsU1WcticJMseJXabEiadQIppA/0?wx_fmt=jpeg)

猕猴桃 [探索AGI](https://mp.weixin.qq.com/s/) *2025年06月27日 11:59*

嘿，大家好！这里是一个专注于前沿AI和智能体的频道~

今年，各种 AI Agent层出不穷。因为manus，GAIA火了，每家都能试着在GAIA上刷个榜，然后再发布。

![Image](https://mmbiz.qpic.cn/mmbiz_png/d08lv0anUnjUtibrZMsiciamQxgNtibdRKRe8WevtP4gpx2GH9AXOIAicSwufeics5UL9kZqrkiaoECXMdcd3RX90yZeA/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1)

**很多开源项目跑出来的效果跟论文里差了一大截？复现全靠玄学，提升基本靠炼丹。**

这就是当前Agent研究的现状：缺乏统一标准、难以公平比较、充满了无法复现的工程技巧。

今天给家人们分享来自 **oppo Agent团队** 分享的亿点点干货！到底构建一个高效Agent到底需要哪些关键组件，如何刷榜GAIA。

## 系统性思考

Agent构建出来好不好，核心可以从2个维度来看。

- Factual Acquisition Capacity, FAC - 事实获取能力。 就是Agent感知和与外部世界交互的能力。它依赖于 **工具（Tools）** ，决定了Agent能“看”多远，“拿”到多少准确信息。
- Logical Reasoning Fidelity, LRF - 逻辑推理保真度。 Agent的“大脑”，负责思考、规划和记忆。它由 **规划（Plan）、记忆（Memory）和测试时扩展（Test-Time Scaling）** 三大模块协同工作，保障Agent的决策链条严谨、连贯。

为什么要这么来看？

后续的工程逻辑完全基于这套框架。 他可以让我们清晰地分析和优化Agent的各个子系统。

不要再听没营养的营销号，“吹嘘Agent只是Prompt罢了”的言论了，认知、品味是这个时代最基本的素养。

## FAC - 强化Agent的感知能力

信息获取是基础，不管是刷榜， 还是现实任务，值得狠下功夫。

### 多模态

很多Agent处理多模态任务时，只是简单地把图片、视频转成文本描述。

但是这够吗？

GAIA上音频、图像、视频等等任务有27个。

如果再普通文本处理的Agent上，结合whisper分析语音，关键帧提取和VLM来分析视频，可以再这27个任务上，准确率从48.15%提升到74.07%。

### 多元搜索

Web Search是一个很重要的任务，请不要死磕一个搜索引擎。

如果将Google、Bing、DuckDuckGo、Baidu甚至Wayback Machine（用于历史网页查询）等多个信源组合起来，可以大幅度环节信息盲区及单个搜索引擎的偏见。

集成5个搜索源，可以在GAIA高难度（Level 3）任务上，性能提升了近 8%。

### Query调优

用户直接输入的内容，几乎永远都不会是最优的搜索质量。

一个非常简单且有效的闭环是： 反思 + 扩展 （reflect + expand）

先分析原始查询的歧义和问题，然后通过生成同义词、改变措辞等方式进行扩展，提升搜索结果的相关性。

这个策略对低中难度的有效，Level1可以从67.92% -> 75.47%

Level2 可以从53.49% -> 55.80%。

高难度可能会略有下降，但是平均大概能提升3个百分点。

### 最小化Browsing

请放弃那些花里胡哨的浏览器操作（如滚动、点击特定按钮），只保留三个原子功能： `Search` 、 `Visit` 、 `Read` 。

可以大大降低了Agent决策的复杂度，且能提升鲁棒性。

网页数据提取，与其纯文本扣，用一些结构化文本提取的方案如Jina Reader，平均可以提升近7个百分点。44.2% -> 51.52%。

### 简单总结

上面的强化Agent的感知能力的方法在所有的模型上都有效，无论是openai o系列还是deepseek，包括claude上，最多的模型差不多能提高20个百分点。

有点像前2年的Advanced RAG？

不会过阵子有Advanced Agent把~

## LRF: 让Agent 想得更明白

如果说FAC是输入，那LRF就是处理。如何让Agent的“思维”更强大？

### 动态规划与任务分解

这里有一些比较熟悉的：

**任务分解** ： 将复杂目标拆解成有依赖关系的子任务图。这让Agent能更清晰地进行系统性推理，甚至并行处理无依赖的子任务。

**技术审查** ： 不要做一个一成不变的计划，执行N步后，根据最新的观察动态修正计划，确保Agent不会“一条路走到黑”。

**数据飞轮** ： 通过分析历史执行日志中的失败案例，将经验教训提炼成“启发式指南”，在生成新计划时注入给Agent。

**让Agent从过去的错误中学习，是提升其规划能力的关键。**

3个技巧叠加，差不多也是15个百分点的提升。

### 记忆增强

这里也是被说烂的一点，几个记忆：

- 当前记忆： 短期缓存，处理实时信息。
- 记忆摘要：将原始执行日志总结成结构化知识。
- 向量化检索：通过向量相似度，从历史记忆中精准召回最相关的经验。
- 长期记忆：持续融合和更新，形成对任务的宏观理解。

长期记忆带来的增益最为明显，平均准确率提升了超过4个百分点，51.52%提升至55.76% 。

沉淀历史经验对解决复杂问题至关重要。

### TTS

还是被说烂的一节，几个增强策略：

- BON：结合多个不同LLM的策略进行采样，投票拓宽解决方案空间。
- 反思：对过去的步骤进行实时反思和自我纠正。
- 过程优化：引入基于过程的奖励函数，评估每一步的进展、错误和效率，从而指导Agent走向更优的推理路径。

反思，可以提升约3.03%，但是在复杂的Level 3任务上表现不稳定。

对于真正困难的多步推理，还需要更根本性的突破。

BO4的效果比较稳定，平均提升5.19%。

## 最后

感谢oppo团队的分享，这套策略叠加，GAIA平均可以达到73.93%。

几乎是开源框架的天花板，比很多闭源的系统还牛。

还是想强调几点：

**构建强大的Agent不是简单地调Prompt或换模型，而是一个系统工程。**

**对于每一个Agent来说，建立一个能从历史错误中自动总结经验并反哺决策的闭环，是提升Agent能力的核心。**

**不要迷信榜单，一个能在3次尝试中解决问题的Agent，在实际应用中可能比单次成功率低的Agent更有价值。**

好了，这就是我今天想分享的内容。如果你对构建AI智能体感兴趣，别忘了点赞、关注噢~

  

继续滑动看下一个

探索AGI

向上滑动看下一个