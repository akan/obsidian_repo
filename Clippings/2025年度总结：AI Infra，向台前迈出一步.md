---
title: "2025年度总结：AI Infra，向台前迈出一步"
source: "https://mp.weixin.qq.com/s/LBBBKkZJx4bJq4flef_aHA"
author:
  - "[[Yibo Zhu]]"
published:
created: 2025-12-24
description: "2025年AI领域聚焦技术密度提升与端侧智能发展，大模型性价比显著优化，AI Infra重要性凸显，行业向工程化与自主智能体演进。"
tags:
  - "AI基础设施"
  - "大模型发展"
  - "技术工程化"
  - "行业竞争"
abstract: "作者回顾了2025年AI基础设施领域从幕后走向台前的重要性提升，以及大模型技术在工程化和性价比方面的显著进步。"
---
Original Yibo Zhu *2025年12月24日 11:18*

> ★
> 
> 作者：Yibo Zhu
> 
> 链接：https://www.zhihu.com/question/1974931646080836522/answer/1985650663905055367
> 
> 来源：知乎

背景：我在阶跃星辰做 AI Infra，阶跃星辰是一家大模型创业公司，因此说的都是大模型与 AI 相关的事。

回望 2025，体感上这是过得飞快的一年。

## 聚焦，离“贾维斯”更近的一年

从 2023 年起，我们（以及行业内许多同仁）心中对 AI 的终极想象，始终有着具象的投射：《钢铁侠》里的贾维斯、《Her》里的萨曼莎，或是《银翼杀手 2049》里的 Joi。 我经常和产品、投资圈的朋友 Brainstorm：如果手机里真住着一个全能的贾维斯，它会是用户的必选项吗？还是仅仅是科幻作品的浪漫投射？

**我们坚定地选择了相信前者。**

这也解释了为什么从第一个基模开始，我们就坚持注入视觉理解能力——这是我们长期的护城河。虽然没有语音背景，但我们死磕原生语音模型，从零做到现在，连 OpenAI 和 X.ai 的朋友交流时都说我们做得很好，有些方面比他们还细。

因为我们笃信： **AGI 要在通用领域匹敌人类，就必须具备人类的眼睛和耳朵。** 一个真正的智能助手，必须能看懂现实世界，能与你自然对话。这是通往 AGI 的必经之路。

这一年，这种坚持得到了回报。我们的技术到商业化的路径，比以往任何时候都清晰。我能清晰地看到通往终点的每一个台阶，收入上的明确信号也给了我们极大的鼓舞。

虽然，“用户是否喜欢贾维斯并愿意为之付费”这个问题仍需时间验证，但创业本质上就是一场对未来的 Take a bet。这种不确定性本身，正是我们努力奔跑的动力来源。

  

## 大模型的“渐进式”创新？

2025 年的 LLM 技术，外界看来似乎是“渐进式”的，没有复刻 2024 年 o1 那样颠覆性的范式飞跃。但我看到的却是“实打实的进化”

。DeepSeek-R1 和 Nano Banana 等模型依然惊艳，而更本质的变化在于性价比： **我们现在训练一个 10B 激活的模型，能力已超越了 24 年 100B 以上激活的模型。一年 10 倍的性价比提升，这是算法、数据、系统综合进化的结果。**

“渐进式”这个现实，也带来了一些相应的变化。关于“Pretrain 结束了”的论调，业内大多一笑置之。没有持续的 Pretrain 探索，哪来这 10 倍的进步？GPT-5、Opus 4.5、Gemini 3 的持续迭代证明，Pretrain 依然是地基。模型与模型的竞争，Pretrain 和 Post-train 都不能掉链子。还没有迹象表明 Pretrain 不能继续改进。但我也理解这个论调背后的逻辑，“难道当前的 Pretrain 范式能无限延续且一直有显著收益吗”，我感觉也没有人能够给肯定的回答。

同时，“渐进式”也导致工作进入了拼工程化的时代，而非重大创新主导。有传言 Gemini 3 的成功有很大一部分归功于修了若干重大 bug。工程基础强如 Google 都有这么多 bug，我们也尚未可知我们自己训练中有多少我们不知道的 bug... 拼工程化也意味着更进入拼集团军作战，组织能力的阶段，而非靠少数几个 super star。但有意思的是业界有些公司（比如 Meta）就反着干，我也很好奇会他们会如何发展。

关于下一个重大技术范式变化何时来，我对硅谷是有一点点悲观的。25 年我来往美国，也见了不少 frontier lab 的新老朋友。25 年大家总体心态浮躁了很多，主要是外界薪资变化幅度巨大，就没有不人员动荡的团队。这样的环境对创新是很不利的，大部分员工可能做几个月就要跳槽，既做不了长线的探索也意味着不会有任何技术秘密可言。公司估值太高也有商业化的焦虑。种种因素，说不定更多创新还真要靠中国公司呢，甚至很多在美国 frontier labs 工作的朋友也有类似观点。

当然，我还是希望整个行业大的创新能多来点。

  

## AI Infra，向台前迈出一步

25 年我觉得业界对 AI Infra 的重要性认识得到了大幅的提升。其实 23 年 -24 年倒也没有人说 AI Infra 不重要。但是口头上说的重视，到认真思考 AI Infra 与算法的合作方式，到真正的付诸行动，还是有很大的差距。而且很多人原来概念里的“重要”只是模型成功的“必要条件”，毕竟没有 infra 啥也跑不成。但 25 年，我很高兴越来越多团队开始意识到 AI Infra 可能比“必要条件”更多，它可能是重大竞争力的来源，甚至有可能是模型成功的“充分条件”（当然，不是唯一的充分条件）。

这个转变，头功肯定是要归于 DeepSeek 在年初的走红。首先催生了一大波做推理优化的人，现在招聘市场上，做推理背景的候选人远远多于做训练背景的，许多都是一年推理优化经验。其次，深入了解 DeepSeek 成功的原因的人都不难发现，AI Infra 实力和模型效果其实是存在一定的转换关系的。

今年年中我配合公司模型发布，写了一点文章，做了一期播客（感谢 42 章经的邀请），产生了出乎我意料的反响。大概是因为做 AI Infra 的，尤其是来自自己训基础模型的团队的，出来说话的真的太少，大家都太 i 了，包括我自己……公共场合说话或者写文章都很少。在这个领域我见到认知最深刻的，还得是自己参与训模型的，或者自己参与设计硬件的。也衷心希望我认识的 NB 朋友们也能多出来分享，而且我觉得“务虚”的分享有时比讲具体技术点更重要。

25 年 AI Infra，让我觉得重要的关键进展（如有遗漏，欢迎提醒补充）：

- 分布式推理
- PD 分离大范围普及（从我们 DistServe paper 以来走到大范围普及，还是花了相当的时间）
	- 跨机 EP 大规模落地（这件事上 DeepSeek 确实比我们敢想敢做）
	- AFD 提出（我听说字节已大规模落地。我们贡献了点开源脚手架，但规模肯定远不及字节）
- 以 TileLang 为代表的 Tile-based 编程语言，以及最近出的cuTile。另外特别提一下华为的 PyPTO与我们有一些技术交流。当然还需要一定时间普及与成熟。
- RL 训练框架从同步走向异步+训推分离，大家对训推不一致的重视与分析等，这些都是 24 年 RLHF 时代不太重视，但是 Reasoning 时代大规模 RL 的新东西
- Model-system codesign 成为了关键词，具体细节就不多说了，反正肯定没收敛。没收敛是好事，才有更多创新。
- Agent Infra 的起步
- 硬件上超节点到来。不过我觉得 25 年大家对超节点的设计、如何围绕超节点设计软件系统、如何围绕超节点设计模型，是不够的。在 26 年需要更多的重视和讨论。

## 适应新时代的“注意力机制”

2025 年也让我学到了宝贵的一课： **酒香也怕巷子深** 。

作为 Research 出身的人，我过去习惯于“顶会逻辑”——工作做好了，发了 Paper，自然有同行关注。但在 AI 的“快时代”，传统的顶会评价体系正在失效。把论文挂上 Arxiv、代码传上 Github，如果没有运营，很可能就淹没在信息的洪流中。

很多高校老师也向我吐槽这一点。但这与其说是抱怨， **不如说是时代对技术人提出的新要求** 。在这个流量与技术并行的时代， **如何让优秀的技术工作获得应有的 Recognition，也是一种能力** 。 我们不能改变环境，但可以主动 Adapt。

我们 26 年在这方面会努力做得更好。好的工作，不仅要闷头做出来，更要大声讲出来。这篇回顾，就是我们改变的开始。

2026，保持饥渴，保持聚焦，继续奔跑。

继续滑动看下一个

精博士小酒馆

向上滑动看下一个