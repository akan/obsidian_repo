---
title: "10倍上下文压缩，性能反超SOTA：揭秘字节跳动“上下文折叠”的黑科技"
source: "https://mp.weixin.qq.com/s/f0aWSLVjkuipLveFUmfSAA"
author:
  - "[[TommyYang]]"
published:
created: 2025-11-11
description:
tags:
  - "上下文折叠"
  - "分支返回机制"
  - "FoldGRPO算法"
  - "主动管理"
  - "长时程任务"
abstract: "字节跳动提出上下文折叠框架，通过分支-折叠机制和FoldGRPO强化学习算法，让LLM智能体以十分之一的上下文实现超越SOTA的性能。"
---
![cover_image](https://mmbiz.qpic.cn/sz_mmbiz_jpg/B2ib2Zr2e3biaViaxicSkHzWPqBPeCiclJSRMp4hfJrCia9HqNcgFwKfWCsXJlVMEsdHlWibicYskmIC8jyQk9w9XAAnqA/0?wx_fmt=jpeg)

Original TommyYang [Tommy学习录](https://mp.weixin.qq.com/s/) *2025年11月11日 08:08*

关注公众号，获得更及时的大模型前沿知识：

## 论文介绍

> 论文名称：Scaling Long-Horizon LLM Agent via Context-Folding
> 
> 论文地址： https://arxiv.org/pdf/2510.11967

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/B2ib2Zr2e3bjGRsNUZR6mxq0AE8ICcJESsjNVlXClVbx6R70qJuFubRQEmdlCHXqArm9Twh6hS8Koe4bNbbiayvw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

## 论文摘要

该篇论文由字节跳动（ByteDance Seed）、卡内基梅隆大学和斯坦福大学的研究者们共同发表，旨在解决大型语言模型（LLM）智能体在执行长时程、复杂任务时面临的核心瓶颈——上下文长度限制。文章提出了一种名为“上下文折叠”（Context-Folding）的创新框架，它赋予智能体主动管理其工作上下文的能力。其核心思想是，智能体可以将一个复杂的子任务“分支”（branch）到一个临时的、独立的子轨迹中进行处理，完成後再将这个子轨迹“折叠”（fold），仅保留一个精炼的结果摘要并返回主任务流程。为了让模型学会这种高效的行为，研究者们设计了一个名为FoldGRPO的端到端强化学习框架，通过特定的过程奖励（process rewards）来引导智能体进行有效的任务分解和上下文管理。实验结果极其亮眼，在深度研究（Deep Research）和软件工程（SWE）等复杂长时程任务上，该“折叠智能体”在仅使用小10倍的活动上下文的情况下，其性能匹敌甚至超越了依赖巨大上下文窗口的传统ReAct基线模型，并显著优于基于摘要的方法。这标志着在提升LLM智能体处理复杂任务的能力上，找到了一条更为高效和可扩展的路径。

## 它解决了什么问题？

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/B2ib2Zr2e3bjGRsNUZR6mxq0AE8ICcJESc2Z1yZazib5HMj5lx72DYHHJUh5m0MzfjZXfoXibLJWJicgCpicU61bVIw/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)

想象一下，你让一个非常聪明但记性有限的机器人帮你完成一个大项目，比如“写一份关于全球半导体产业未来十年的深度分析报告”。这个项目极其复杂，需要查阅成百上千份资料、进行数据分析、编写代码验证等。

这个机器人的“记性”就是它的“上下文窗口”（Context Window），它能同时处理的信息量是有限的。现在，主流的智能体（如基于ReAct框架的智能体）在工作时，就像一个把所有资料都堆在桌面上的研究员。

**它会遇到两个致命问题：**

1. **“信息过载”导致的“迷失”** ：随着任务进行，桌面上的文件（交互历史、工具调用结果、观察等）越堆越多。很快，整个桌面就会一片狼藉。当机器人需要查找某个关键信息时，它可能在成堆的文件中找不到，或者被大量不相关的信息干扰，导致“思维混乱”，性能急剧下降。这在学术上被称为“Lost in the Middle”问题。
2. **“效率低下”导致的“缓慢”** ：桌面上的文件越多，机器人每次决策前需要“扫视”一遍所有文件的时间就越长。这种成本随着文件数量的增加呈二次方级增长，导致整个项目进程异常缓慢且昂贵。

**为了解决这个问题，以前有两种主流“笨办法”：**

- **方法一：定期总结（Summary-based）** ：就像请个助手，在桌面快满的时候，把一部分旧文件打包，写个摘要条贴在包上，然后把原文件扔掉。这种方法虽然能腾出空间，但非常粗暴。总结过程可能会丢失关键细节，而且这种“打断式”的总结会破坏机器人连贯的“思考流”，导致后续决策出现偏差。
- **方法二：多智能体协作（Multi-agent systems）** ：把大项目拆分成不同部分，分包给不同的“专业机器人团队”去处理。比如一个团队负责搜集资料，一个团队负责编码。这种方法虽然能分散上下文压力，但通常需要人工设计复杂的协作流程，难以实现端到端的自动优化，通用性也差。

**而“上下文折叠”则提出了一种全新的、更优雅的解决方案。** 它不再把机器人当作一个被动接受信息的“容器”，而是教机器人学会一项高级认知技能： **“工作空间管理”** 。机器人不再把所有东西都堆在一个桌面上，而是学会了当遇到一个复杂的子任务（比如“分析台积电的财报”）时，就拿出一个 **新的、干净的“子桌面”** （分支），在这个子桌面上完成所有相关工作。工作完成后，它只写一张包含核心结论的“便利贴”（摘要），贴回到 **主桌面上** ，然后把这个子桌面连同上面的所有草稿、资料一起收起来（折叠）。

这样一来，主桌面始终保持整洁、聚焦于项目主线，而机器人的“当前注意力”（活动上下文）也始终保持在一个小而高效的范围内，从而根本上解决了信息过载和效率低下的问题。

## 核心方法与原理：它是怎么做到的？

要让智能体学会这种高级的“工作空间管理”技能，该论文提出了两大利器： **“分支-返回”机制** 和 **FoldGRPO强化学习算法** 。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

### 1\. 核心机制：“分支与折叠”（Branching and Folding）

该框架为智能体提供了两个全新的特殊工具（actions）：

- `branch(description, prompt)` ： **开启一个新分支** 。当智能体在主流程中遇到一个可以被独立解决的子任务时，它可以调用此工具。 `description` 是对这个子任务的简短描述， `prompt` 是给这个子任务的详细指令。调用后，系统会创建一个独立的、临时的上下文空间（子轨迹），智能体开始在这个新空间里工作。
- `return(message)` ： **折叠分支并返回** 。当子任务完成后，智能体调用此工具。 `message` 是子任务的最终成果摘要。调用后，系统会销毁这个子任务的临时上下文空间（即“折叠”掉所有的中间步骤），只将 `message` 中的摘要信息追加到主流程的上下文中。智能体的“注意力”也随之切回主流程。

通过这两个工具的配合，智能体可以将一个线性的、不断膨胀的任务历史，重构成一个树状的、主次分明的结构。主干（main thread）只保留高层逻辑和关键节点，而所有耗费大量信息（token-intensive）的细节操作都被“外包”到临时的分支中，用完即弃，极大地压缩了主干的上下文长度。

### 2\. 训练心法：FoldGRPO强化学习算法

仅仅给智能体工具是不够的，它需要学会 **何时** 、 **为何** 以及 **如何** 使用这些工具。这就是FoldGRPO（Folded-context Group Relative Policy Optimization）算法发挥作用的地方。它是一种端到端的强化学习训练框架，其核心在于设计了一套精妙的“奖惩机制”（过程奖励），来引导智能体形成良好的“上下文管理”习惯。

最终的目标奖励很简单：任务成功则奖励，失败则不奖。但这个信号太稀疏了，智能体很难学会复杂的中间步骤。因此，FoldGRPO引入了几个关键的“过程惩罚”：

- **未折叠令牌惩罚（Unfolded Token Penalty）** ：这是“ **保持主干道通畅** ”规则。当主流程的上下文长度超过一定阈值（如50%）时，如果在主流程中执行了大量消耗信息的操作（比如直接在主流程里进行网页搜索和浏览），智能体就会受到惩罚。这个惩罚机制会“逼迫”智能体将这类“脏活累活”放到分支里去完成。
- **范围外惩罚（Out-of-Scope Penalty）** ：这是“ **专心致志** ”规则。在分支（子任务）中，如果智能体的行为超出了该分支被创建时设定的目标范围，它就会受到惩罚。这能确保智能体在处理子任务时保持专注，不会“跑偏”，从而提高分支的执行效率和成功率。
- **失败惩罚（Failure Penalty）** ：当工具调用失败时给予惩罚，这是常规操作。

通过这套“胡萝卜加大棒”的组合拳，FoldGRPO算法能够高效地训练智能体，使其不仅能完成最终任务，更能以一种结构化、有条理、高效率的方式来完成任务，真正掌握了“上下文折叠”的精髓。

## 创新价值：它厉害在哪里？

1. ### 认知范式的飞跃：从“被动约束”到“主动管理”
2. 这篇论文最大的创新在于，它将“上下文管理”从一个外部的、系统层面的约束， **内化** 为了智能体自身的一种可 **学习的认知技能** 。过去的思路是如何在有限的上下文“限制”下做得更好，而本文的思路是让智能体学会“主动地”创造并管理一个远超其物理限制的“虚拟上下文空间”。这是一种根本性的范式转变，让智能体变得更像一个懂得规划和聚焦的“思考者”，而非一个被动的信息处理器。
3. ### 效率与性能的极致平衡
4. 论文最令人震撼的价值体现在实验数据上。在BrowseComp-Plus（深度研究）任务上，“折叠智能体”的pass@1得分达到62.0%，在SWE-Bench（软件工程）任务上达到58.0%。这一成绩不仅全面超越了同样上下文大小（32K）的基线模型，甚至超越了使用327K超长上下文的ReAct基线模型（5.4%的提升）。它用 **十分之一的活动上下文** ，取得了比“巨无霸”模型更好的成绩。这证明了“聪明的管理”远比“盲目的堆砌”更有效，为构建高性能且经济高效的智能体系统指明了方向。
5. ### 通用且可扩展的优雅框架
6. “分支-折叠”的机制非常符合人类解决复杂问题的思维模式（即分而治之），因此具有极强的通用性。论文在两个截然不同（研究与编码）的领域验证了其有效性。更重要的是，这个框架具备天然的可扩展性。未来甚至可以探索“多层折叠”（即在分支中再开辟子分支），构建更深层次的等级化任务结构，以应对前所未有的复杂问题。
7. ### 强化学习在智能体训练中的精妙应用
8. FoldGRPO算法中对“过程奖励”的设计是教科书级的。它成功地将一个抽象的、难以量化的“良好行为习惯”（如保持主干清晰、在分支中保持专注）转化为了具体、可优化的数学信号，为如何通过强化学习训练LLM智能体掌握复杂内在技能提供了宝贵的经验。

## 论文总结

总而言之，《Scaling Long-Horizon LLM Agent via Context-Folding》是一篇具有开创性意义的论文。它通过提出“上下文折叠”这一精妙的机制，并辅以创新的FoldGRPO强化学习算法，成功地将上下文管理从一个困扰大型语言模型智能体的外部技术瓶颈，转变为一项智能体可以主动学习和掌握的核心认知能力。该方法不仅在性能上取得了SOTA（State-of-the-art）级别的成果，更在效率上实现了惊人的提升，证明了智能体通过主动、分层的任务管理，能够以极小的资源代价解决极其复杂的长时程问题。这项工作无疑为通往更强大、更高效、更具扩展性的自主智能体铺平了一条坚实而充满希望的道路。

---

关注公众号，获得更及时的大模型前沿知识：

---

加入公众号交流群（说明来意）

![图片](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

  

![](https://mmbiz.qlogo.cn/mmbiz_jpg/icJiceiabX3zCRGzLiallBmqvablOtxGewQZdpbUDicCMvOokFZWQEWCYaYCB51TbYDL2IzlibVUqicTicxtNI6OgBzqgA/0?wx_fmt=jpeg)

您的鼓励是我坚持的动力

修改于 2025年11月11日

继续滑动看下一个

Tommy学习录

向上滑动看下一个