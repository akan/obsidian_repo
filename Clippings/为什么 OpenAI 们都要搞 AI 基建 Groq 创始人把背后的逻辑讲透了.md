---
title: "为什么 OpenAI 们都要搞 AI 基建？Groq 创始人把背后的逻辑讲透了"
source: "https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&chksm=c153791fc1c67949e33ae60bc04b7ea7bd7b0dc9757c8c3939c2371a1444f99dbd0bc60bbbc4&idx=1&mid=2247519850&sn=8e75516dd8e6ce7f5de09bcf8896f95b#rd"
author:
  - "[[Founder Park]]"
published:
created: 2025-10-11
description: "推理算力翻倍，收入翻倍。"
tags:
  - "算力短缺"
  - "AI基建"
  - "供应链博弈"
  - "自研芯片"
  - "护城河构建"
abstract: "Groq创始人Jonathan Ross在访谈中深入分析了当前AI行业面临的核心问题——算力供给严重不足，并解释了为什么OpenAI等公司都在积极布局AI基础设施建设，包括自研芯片、数据中心等战略举措。"
---
Founder Park *2025年10月10日 21:25*

![Image](https://mmbiz.qpic.cn/sz_mmbiz_gif/qpAK9iaV2O3sAVsSPfCN9UX44XiaoicbUJIrOGuaujdMNY6iaQewDZEX1GY3tcVk3QGeKJyUMMHBSMALvO8B7DZwsA/640?wx_fmt=gif&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

本篇文章转载自「AI产品阿颖」

如果你留意的话，会发现最近 OpenAI 在芯片和数据中心方向出手颇多。

它一手在自建芯片，另外一手又着手和英伟达、AMD、Oracle 等公司合作，推动新一代的 AI 基础设施建设。

为什么要这么干？芯片、数据中心对于 AI 的意义是什么？自研芯片的难点在哪里？目前的芯片热是泡沫吗？

Groq 创始人 Jonathan Ross 的最新一期访谈，能很好地回答这些问题。

Groq 是一家专注超低时延 AI 推理的 LPU 芯片与云服务公司，他们将自己定位为英伟达的最大挑战者。

这期播客访谈的信息量很大：

- 「如果现在给 OpenAI 的推理算力翻一倍，给 Anthropic 的推理算力翻一倍，那么在一个月之内，他们的收入几乎会翻倍。」 AI 应用的增长目前完全受限于算力的供给，谁能获得更多算力，谁就能服务更多用户，赚更多钱。
- AI 与以往的技术革命不同，其增长几乎不受单一要素的制约。AI 的三要素：数据、算法、算力，只要提升其中任意一项，AI 的整体表现就会变好。而在实践中，最容易调整、见效最快的就是算力。
- 传统观念认为，产品的护城河在于技术专利、品牌或网络效应。但一个差异化且高效的供应链本身就是一条极深的护城河。
- 在需求近乎无限的市场中，最稀缺的不是「最好的产品」，而是「可获得的产品」。你的护城河，就是你为客户提供的确定性和可得性。
- 制造芯片的难度被外界严重低估了。芯片的成功不仅在于硬件设计本身，而是其背后极为复杂的软件生态、持续的工程优化和对整个技术生态演进节奏的精准把握。
- 科技巨头为什么都在「造芯」？并不是单纯为了在性能上超越英伟达，而是为了「掌控自己的命运」，关键在于供应链的博弈和议价权。
- 一个反直觉的现实是，市场上依然有大量接近五年前发布的英伟达 H100 GPU 在被高价租用，并且其产生的收入远高于运营成本。整个市场的算力供给远不应求。
- 在算力稀缺的时代，交付能力的重要度远超一切，能够稳定、快速地提供产品本身，构成了强大的护城河。

原访谈链接： https://www.youtube.com/watch?v=VfIK5LFGnlk

---

超 15000 人的「AI 产品市集」社群！不错过每一款有价值的 AI 应用。

邀请从业者、开发人员和创业者，飞书扫码加群：

![Image](https://mmbiz.qpic.cn/sz_mmbiz_png/qpAK9iaV2O3tX32Bm6RQC9FSiaPehw9Uv0LlJRrv0wIiba5qWmibPJ0A0suR4PwPWaD9saF3ZkW24R0O2GUK8r7O4A/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)

进群后，你有机会得到：  

- 最新、最值得关注的 AI 新品资讯；
- 不定期赠送热门新品的邀请码、会员码；
- 最精准的AI产品曝光渠道

---

  

01

## 芯片要自建？难得很

## 主持人：我们现在到底处在什么阶段？世界的发展似乎比以往任何时候都要快。

Jonathan Ross ： 你是问，这是不是一个泡沫吗？

主持人：到底是不是呢？

Jonathan Ross ： 关于是不是泡沫，我的回答是，如果一个人总是问一个问题却得不到答案，也许他应该换个问题。

所以，与其问是不是泡沫，不如去看看那些真正有实力、眼光精准的投资者，他们现在在干什么。

Google 在做什么？Microsoft 在做什么？Amazon 在做什么？还有很多政府，他们都在加码 AI。

大家的投入在不断增加，几乎每次对外公布预算时，都会比上一次多。

最能体现投资收益的例子之一就是微软。

有一季度他们部署了一大批 GPU，然后宣布不会把这些 GPU 放在 Azure 上出租，因为他们自己用这些 GPU 赚到的钱，比租出去赚得还多。

所以市场里是真有钱的。

我觉得最好的比喻是，现在就像石油勘探早期，很多地方钻下去都是空的，只有极少数地方能喷出大量石油。

据我听说，现在大概有 35 或 36 家公司贡献了 99% 的 AI 收入，或者至少是算力开销。分布非常不均。

主持人：现在七巨头是否都意识到，他们需要进入芯片领域，掌控整个垂直链条，从头到尾？

Jonathan Ross ： 我认为不会有太多人能真正成功进入芯片领域。

很多人把 TPU 看作一个巨大成功，但他们没意识到，当时 Google 其实有大约三个芯片项目在同时进行，只有一个最终超越了 GPU。

在整个行业里，也有很多人做芯片，但有些项目会被取消，比如特斯拉的 Dojo 项目最近就被砍掉了。

造芯片非常难。 你要是说我自己做一颗 AI 芯片来和英伟达竞争，这就好比说 Google 搜索挺好用的，我来复制一个吧。

这几乎是疯狂的，因为里面涉及的优化、设计和工程深度极其复杂，几乎不可能复制成功。

主持人：我们之前提到过，要想留在七巨头里，就必须花钱。比如英伟达向 OpenAI 投资 1000 亿美元，而 OpenAI 只是再用这笔钱买回英伟达的芯片。这听起来不就是一个资金在圈子里打转的循环吗？

Jonathan Ross ： 只有当这笔钱没有真正流向芯片供应商去生产时，才叫资金在空转。但只要产生了实际的生产性结果，就不能算是资金绕圈。

大家可以这样想：这些钱里有多少百分比是真正花在建设基础设施上的？比如 40%？那么至少 40% 的资金是真正流向了生态系统。所以这不是无限循环。

主持人：好吧，那就是说有 60% 是循环的？

Jonathan Ross ： 对，部分循环，60%。

主持人： 我们再回到英伟达，他们的股价就能上涨好几千亿美元。

Jonathan Ross ： 是的。

主持人：你是怎么分析这种情况的？

Jonathan Ross ： 我们可以从几个角度来分析。从经济学角度看，这完全说得通，为什么不一直这么做呢？价值能够持续增长，是因为用户被锁定在这个生态里。

当收入增加时，股价涨幅超过收入涨幅，这背后是市场相信这种收入会持续下去。

英伟达本身优秀，更关键的是全世界的算力供给远远不够，对算力的需求几乎无止境。

我敢打赌，如果现在给 OpenAI 的推理算力翻一倍，给 Anthropic 的推理算力翻一倍，那么在一个月之内，他们的收入几乎会翻倍。

主持人：你能帮我解释得更清楚一点吗？

Jonathan Ross ： 他们受限于算力，这是问题的根源。

对 Anthropic 来说，最大的问题之一就是调用限制，用户拿不到足够的 Token。如果他们有更多算力，就能生产更多 Token，就能收更多钱。

对于 OpenAI 来说，它是一个聊天服务。那他们怎么控制使用呢？就是让服务变慢，结果就是用户互动减少。

主持人：你觉得速度有多重要？其实有不少人觉得这没问题。我完全能接受延迟，我输入一个提示，然后去做点别的事情，等我回来结果就出来了。

Jonathan Ross ： 这些观点挺有意思。我们来看一下快消品（CPG）。

如果按利润率来排序，排在最上面的是烟草，接下来是嚼烟，然后是软饮料，再往下才是水和其他类似的产品。

在 CPG 行业里，高利润率最相关的因素是什么？就是成分对人起作用的速度。也就是说，多巴胺循环有多快被触发，决定了人们对品牌的依赖。

当一种产品能带来快速反应时，你会对它产生强烈的品牌联想，进而形成品牌价值。

这也是 Google 为什么那么强调速度，Facebook 为什么也强调速度的原因。每当网页速度提升 100 毫秒，转化率大约会提高 8%。

主持人：所以，他们觉得“没关系，后台可以同时跑很多提示，反正放着让它慢慢跑也没问题”。这种判断是错误的。

Jonathan Ross ： 完全错了。实际上，当我们刚开始优化芯片速度时，我们就清楚自己能做到多快。

我们甚至做了一个演示视频，人们看了之后会问：为什么要比人类阅读速度还快？

我回答说：那网页为什么要比人类阅读速度加载得更快呢？这里存在一种思维错位，很多人并没有在直觉层面真正明白速度有多重要。

人类在判断什么因素会影响参与度、影响结果方面，其实很不敏感。我们从早期互联网公司建设中就已经深有体会。

主持人：你觉得 OpenAI 未来会不会进入芯片领域？英伟达肯定会担心 OpenAI 想要纵向整合，把芯片这一层也掌握在自己手里。你觉得他们能成功完成这样的转型吗？

Jonathan Ross ： 我觉得自研芯片的难点在于一开始大家都以为难的是把芯片做出来，但真正做下去会发现更难的是软件；再往下还会发现，跟上整个技术生态的节奏变成了最难的。

我毫不怀疑 OpenAI 有能力做出自己的芯片；我也相信，最终 Anthropic 会做自己的芯片，所有超大规模云厂商都会做自己的芯片。

我在 Google 时有一次参观实验室，那会儿 AMD 还没像现在这样出色，他们当时经历了一段艰难期。

实验室里有 1 万台基于 AMD 芯片的服务器，工程师把服务器从机架里抽出来，直接把 AMD 芯片撬下来丢进垃圾桶。

好笑的是，这几乎是注定的，因为大家都知道那一代会是英特尔胜出。那为什么 Google 还要做 1 万台 AMD 服务器？因为他们想借此从英特尔那里拿到更大的折扣。

到了这种规模，Google 为适配 AMD 去设计主板、做整机和测试所花的成本，和最终从英特尔拿到的折扣相比，还是划算的。

所以当我们看到公司去做自研芯片时，要考虑他们背后的各种动机。

他们这么做并不只是为了把芯片量产部署。关键在于，英伟达实际上对 HBM（HBM 是 GPU 的超级显存）具有买方垄断的地位。

买方垄断与卖方垄断相反：当市场上只有极少数大买家，而 HBM 的产能又很有限时，就会出现这种格局。

至于 GPU 本体，它用的制造工艺和我们手机芯片的工艺是同一类。

如果只看 GPU 核心，英伟达一年生产 5000 万颗并非不可能，但现实中今年大概只能生产 550 万块整机 GPU。原因就在 HBM 和承载它的中介层（interposer）产能有限。

于是会出现这样的情况：一家超大规模客户说要 100 万块 GPU，英伟达回答说抱歉还有别的客户，对方就说没关系，我自己做。

这时英伟达往往就能找出这批 GPU，优先满足这家客户。

由于产能就是有限的，自研芯片真正带来的，不仅是有了自己的芯片，更是拿回对自己命运的主导权。这才是自研芯片的独特价值所在。

主持人：什么叫掌控自己的命运？

Jonathan Ross ： 就是英伟达不能再决定买家能分到多少 GPU。自研芯片的部署成本可能更高，因为性能未必能赶上英伟达。

但想想看，为什么英伟达只比 AMD 稍微强一些，却能在市场上占据主导？

如果一套系统的整体部署成本远远高于芯片本身的成本，那么芯片价格的轻微上涨几乎可以忽略。

换个角度：假设一台服务器里 GPU 只占物料成本的 20%，而芯片速度提升了 20%，这会给整套系统带来 20% 的价值提升；相比之下，芯片成本上浮 20% 其实不值一提。

也就是说，只要芯片性能有提升，带来的价值放大效应非常大。于是，哪怕性能只领先一点点，产品价值也会被放大很多，这个小优势就能换来巨大的销售优势。

  

02

## 回本周期的算法

## 主持人：你刚才提到买方垄断。在 HBM 市场被买方垄断的情况下，OpenAI、Anthropic 或七巨头里的其他公司，乃至其他厂商，还有可能进入芯片这一层吗？

Jonathan Ross ： 非常难。虽然英伟达下单多、给的条件也好，但厂商不想被它绑死，所以会主动找别的客户。

可问题在于：如果 HBＭ 供应链中的厂商在建设晶圆厂、封装厂和相关产线，而英伟达拿着大额订单预付款来下单，他们当然会优先为英伟达扩建产能。这样英伟达就能提前锁定所需供给。

真正的难点在于，这笔大额预付款必须提前两年以上支付。

因为 AI 的需求正在迅猛飙升，即便英伟达现金流充沛，也很难完全提前覆盖未来的超大需求，因此供给瓶颈仍会存在。

这不仅仅是买方垄断的问题，还有资本开支巨大，内存厂商普遍保守等原因。再者，HBM 的毛利很高，谁都不愿意轻易扩产，因为一旦供给增加，利润率就会下滑。

主持人：从 OpenAI、Anthropic 这些公司可能自研芯片来看，这是不是他们要大规模融资的原因？Sam 说需要几千亿美元，是不是也把这些因素算进去了？

Jonathan Ross ： 不是。大头其实在数据中心。买一套系统很贵，但建数据中心更贵。

原因是数据中心的摊销周期更长：假设把数据中心按 10 年摊销、芯片按 3 到 5 年摊销，那么每年的成本里，数据中心占比会更高。

所以当我们听到超大规模厂商说每年投 750 亿到 1000 亿美元，那主要是因为他们在建设数据中心，这笔钱是为了未来 10 年以上的回报而投入的。

换个角度看，这并没有想象中那么夸张。

主持人：如果芯片的更新换代其实比 3 到 5 年更短，那按 3 到 5 年来做摊销还合理吗？

Jonathan Ross ： 我觉得大家考虑摊销周期往往比我更长。我们内部用得更保守一些的数字，大概是 5 到 6 年。

主持人：你是说应该是 3 年？

Jonathan Ross ： 甚至更短一些。我们大概按一年一换的节奏看待芯片升级。

可以这样理解芯片的价值，它分成两个阶段：第一是我是否愿意买来部署；第二是我是否愿意持续运行。

两者的计算完全不同：部署时要覆盖资本支出（CapEx）；持续运行时只要覆盖运营成本（OpEx）。也就是说，今天我把芯片部署上线，必须把 CapEx 赚回来并且获得回报。

只要能覆盖运营成本，我就会让它继续跑。也就是说可以接受芯片的价值随时间下滑。

大家真正押注的是：新芯片出来后，旧芯片的可创造价值不会低到连 OpEx 都覆盖不了。

以我们来看，把周期拉到 5 年是没有意义的。

主持人：因为性能差距会被拉得很大，旧芯片创造的价值可能会低于它的运营成本，对吗？

Jonathan Ross ： 对，电费、机房费用这些都算在内。

  

03

## 供给决定胜负

## 主持人：那会发生什么？我们会不会出现一堆被闲置浪费的芯片？

Jonathan Ross ： 这确实可能发生，因为很多公司签了很长的合同。于是他们要做第三层计算：违约解约，是否比继续亏损运行这些芯片更划算？没错，就是要这样权衡。

主持人：你们现在已经在看到这种情况了吗？

Jonathan Ross ： 接下来会怎样，这个我没法告诉你，因为我们正努力避免那种局面。

我们做法是把回本周期压得更短，我不愿意把赌注押在太长的周期上。下注周期越短，结果就越可控、越清晰。

主持人： 也就是说，核心是尽量缩短回本周期，同时把运营成本压到最低，这样当芯片性能落后时就能更快淘汰。

Jonathan Ross ： 是的，但还有个反直觉的点：如果完全按会计的账算，我们可能会觉得这主意太糟了。

但从实际情况看，大家现在还在租用 H100。这批芯片都快五年了，依然跑得不错，而且收入远高于运营成本。

我们今天不会再去新部署 H100，但让它们继续运行仍是赚钱的，对吧？这就是我说的第二阶段。

原因很简单：市场算力供不应求。否则 H100 的租价早就掉到现在的几分之一了。只要算力短缺还在，这种情况就会持续。

问题在于：有没有不那么受供给约束的替代方案？这正是我们想切入的点。

说到我们的价值主张，你一开始问的是速度，你知道有多少客户一上来就跟我们谈速度吗？

主持人：不知道。

Jonathan Ross ： 几乎所有人。一旦他们意识到外部供给受限，你知道还有多少人继续纠结速度吗？一个也没有。

大家一开始都谈速度，因为他们知道这对终端客户很重要。接着他们会发现：等等，我连足够的算力都拿不到。

真正的价值主张就变成了供应商是否有能力提供足够的算力容量。两周前有个客户来找我们，要增加 5 倍总算力容量。

他们从任何一家超大规模云厂商都拿不到，从别人那也拿不到，我们也给不了，没有人能给。

所以我们拿不下这个客户，超大规模云也拿不下，因为算力不够。

在这样的市场里，供应商的抉择就是： 谁能买到算力，谁就能拿到客户。 这也是我之前说的：如果 OpenAI 或 Anthropic 的算力翻倍，他们的收入也会翻倍。

对那些算力不够、服务不了客户的公司来说，他们会不惜一切代价去拿算力，因为先拿下客户就能形成锁定价值。

因而我们的首要价值主张是：我们的供应链不同于 GPU 的供应链。GPU 通常要提前两年下大单。

而在我们这里，客户为一百万片 LPU1 支付订单后，首批 LPU1 会在 6 个月……

主持人：6 个月后就到货。哇，那跟 18 个月的周期相比，差距太大了。

Jonathan Ross ： 对，差距巨大。我之前和一家超大规模云的基础设施负责人开会，谈了速度、成本等等。

但当我说我们能把交付周期做到 6 个月时，他立刻打断，要求深入聊这一点。这是他最关心的。

主持人：在模型演进这么快的情况下，两年的周期还说得通吗？

Jonathan Ross ： 这正是问题所在。你知道 Sara 吗？她写过一篇论文《The Hardware Lottery（硬件彩票）》，我大概说下主要内容，就是大家其实是在按硬件来设计模型。

也许有一些架构理论上优于注意力机制，但注意力在 GPU 上特别好用。对既有玩家而言，这构成明显优势，因为模型通常会围绕其硬件进行设计与优化。

即便外部出现理论上更优的架构，只要在现有硬件上运行效果不佳，在实践中就很难说更好。

这会形成硬件生态 -> 模型设计 -> 进一步强化硬件生态的正反馈闭环。

对行业领头企业来说，提前两年规划产品线仍可行；而对新进入者而言，几乎不会有团队提前两年为其芯片做适配，因此必须将产品与生态的迭代周期大幅缩短。

  

04

## 开源不等于更省钱

主持人：按你说的，大家都在往芯片层走，OpenAI 会有自己的，Anthropic 也会有。在那样的世界里，英伟达会怎么做？

Jonathan Ross ： 英伟达依然会持续卖芯片。

主持人：是因为客户高度集中，对吧。

Jonathan Ross ： 没有人能准确预测增长会有多快。我们一开始讨论 AI 是否是泡沫，回看过去 10 年，数据中心基础设施通常要提前两到五年规划。

结果怎么样？大家的预测全错了，建设总是偏少。这 10 年基本都是这样。

如果连续多年都建少了，大家会怎么做？就会尝试超量建设，按最乐观的预期再多建一点，但还是不够，于是再上调预期、再多建。

现实就是这样循环，然而算力依旧供不上，人的直觉在这件事上一直不太准，只是大家还没完全意识到。

AI 和 SaaS 不一样。SaaS 里是工程师把产品做出来，产品质量主要由工程投入决定。

AI 不是这样。在 AI 里，我可以对同一个问题跑两次推理，选更好的答案，从而提升质量；我可以在每次查询上多花算力，让结果更好；甚至可以给更重要的客户分配更多算力，提供更好的结果。

这类似于 OpenAI 最近宣布的做法，有些产品的算力成本很高，承受不起，就先只开放给一部分用户，并且定价很高。

目的就是观察在增加算力投入后，AI 的效果会怎样、产品会变好到什么程度。未来会越来越多是这种模式。

只要给应用投入更多算力，质量就会上升。这也是为什么很多公司的按量计费（Token 即服务）成本几乎贴着营收走，因为大家在争夺客户。只要多花算力，产品就会更好。

主持人：我明白。不过直说一点，大家看 GPT-5 的叙事都在强调效率，认为 Sam 把重心从追求性能转到了追求效率，因为增加算力并不总能带来同等幅度的性能提升。你觉得这个判断公平、真实吗？这和你刚才的观点不矛盾吗？

Jonathan Ross ： 不矛盾。你得看他们要实现的目标不一样。以 OpenAI 为例，它已经进入了对成本极其敏感的市场。

比如印度，如果他们想在印度做，就得把订阅价做到每月 99 卢比，按当前汇率大概 1.13 美元。

主持人：但还有开源选项。我的意思是，他们也可以用开源方案啊。

Jonathan Ross ： 这又是市场上的一个误解。那我们就从澄清这些误解开始说起吧。

当中国的模型出来时，大家的反应都是：天哪，他们把模型训练出来了，几乎赶上美国的模型了。我们之前也做过一期播客聊这个话题。

刚开始连我自己都有点被带偏了，会想这些模型运行成本是不是更低。

现在我更了解大家在用的基础模型和中国模型之间的差别后，我的结论是并不更便宜，运行成本大概高出十倍。

具体来说，以最近发布的 GPT 开源模型为例，它的优化方向和中国模型不同，但质量很高，就其专注的领域而言，我认为明显优于中国的模型。

中国模型关注点不一样。不过，这个开源模型的运行成本大约只有中国模型的十分之一。

那为什么很多人定价更低呢？因为当某个模型在一个被锁定的市场里，用户只想要这个模型，而且只有一个提供方时，它就能把价格抬到十倍。

也就是说，价格被抬高了，但大家把成本和价格混淆了。中国的模型更偏向把训练做得更便宜，而不是把推理运行做得更便宜。

主持人：为什么美国有算力优势？是因为更容易拿到芯片吗？

Jonathan Ross ： 没错。

主持人：那中国呢，不只是补贴。我理解推理和运行的成本更高。如果运行成本更高，但有政府补贴，这还重要吗？

Jonathan Ross ： 这里其实存在主场和客场的区别。主场是指在本国境内建设算力，比如美国在美国本土、中国在中国本土。

客场则是指在盟友国家建设算力，比如在欧洲、韩国、日本、印度等地。

在主场，中国具备很强的优势。比如，他们计划建 150 座核电机组。这样一来，即便芯片的能效不是最好的，也可以依靠充足的能源供应和政府补贴把算力规模堆上去。

但在客场，情况就完全不同了。假设一个国家只有 100 兆瓦的电力储备，你能怎么办？难道还能再建一座核电站？对很多国家来说，这是不现实的。在中国可以做到，但在别的国家很难。

因此，在客场，更高能效的芯片就是关键优势。我的判断是，未来两三年，美国会在客场占据明显的上风。如果他们行动够快，就能把一批盟友拉进这场 AI 竞赛中来。

  

05

## 能源与算力的比拼

## 主持人：现在已经在做了吗？你觉得我们是否应该开放模型，让中国用他们擅长的方式去做蒸馏？

Jonathan Ross ： 我觉得模型本身并不是决定性优势。还记得你第一次请我上播客时，我预测 OpenAI 会把模型开源吗？我的依据就是它的品牌力。

坦白说，即便 OpenAI 现在用的还是两年前的 Llama 2 模型，依然会有很多人去用它，这就是品牌的力量。

当然，他们的模型确实也很强，但有了品牌优势，不一定非要靠最新最强的模型。

我认为 Anthropic 应该把上一代模型开源，让大家用它们而不是用中国模型。

因为愿意用中国模型的人，至少也可以用 Anthropic 的模型，而且他们现有的提示词还能继续复用。

就像软件有兼容性，提示词也有兼容性。以 OpenAI 的开源模型为例，许多人从中国模型转用它，一个关键原因是原有的提示词可以不做改动直接沿用。

当然，如果有人场景成本敏感、付不起 OpenAI 的溢价，就会用这些开源模型；等业务做大、赚钱更多时，就会希望用更高端的闭源模型，而提示词仍然可复用。

这样开源能双赢：一方面拉动采用，另一方面也促使基础设施提供方围绕该模型降本增效，带来大量创新。

主持人：明白了。我再问一个问题。既然我们要尽可能多地建设算力，能源需求会非常大。要满足这波算力浪潮的能源需求，是否只有核电这一条路？

Jonathan Ross ： 不，不止核电。核电高效且成本可控，可再生能源同样高效且成本可控。

我给一个简单的办法：美国及其盟友只要愿意把算力中心建在能源便宜的地方，就能获得比中国更多的可用能源。

再拿欧洲和美国对比。美国相比欧洲，更厌恶风险。不只是能源领域，几乎在所有方面都是。

但关键是分清风险类型：一种是作为性错误，做了错事；另一种是不作为性错误，该做的不做。

美国现在非常害怕不作为的错误。在高速增长的经济里，错过机会往往比做错一件事代价更昂贵。而欧洲对不作为的风险反而更能接受。

所以欧洲尝试竞争的方式更多是通过立法，比如要求数据必须留在欧洲或留在本国。

如果欧洲真想在 AI 上竞争，其实可以这样做：比如让挪威部署大量风电。为什么是挪威？

因为挪威风电的可利用率大约有 80%，也就是 80% 的时间都能发电；同时挪威水电富足，如果把风电装机扩到水电的 5 倍，挪威一国提供的电力就能接近美国全国水平，而且能稳定供给。

这只是欧洲的一个国家。还有多少非核能的潜力可以被释放出来。同时也可以部署核能，现代核能的安全性已经很高。

主持人： 那我们为什么不这么做呢……

Jonathan Ross ： 因为害怕。

主持人：真的是这样吗？

Jonathan Ross ： 是的。

主持人：当你和欧洲各国政府交流时，他们怎么回应你？

Jonathan Ross ： 我一般不主动谈核能，因为这是一个很容易引发反对的能源话题。

但我最近在日本时，他们在讨论重启核反应堆。外界常说日本做事很慢，这种看法缺少细节。真实情况是日本做决策慢，一旦决定了就推进很快。

举个例子，日本决定建设一座 2 纳米工厂。我去的时候他们已经展示了自己做出的 2 纳米晶圆。

良率还不到位，还达不到量产标准，但他们的 2 纳米工厂已经建起来并且开始出片了，接下来会迅速把缺陷密度降下来。

他们为 AI 预留了 650 亿美元预算，而且会很快花出去。他们会重启核电机组。日本要重启核电这件事，欧洲应该警醒，赶紧在能源上追赶。

主持人：追赶正是我在想的，因为建这些东西的速度很慢。你刚才说到风能的可利用率，以及我们如何利用它。但事实是，要建成大规模的风机群需要好多年。为什么你觉得挪威政府会掏钱装上上万台风机呢？

Jonathan Ross ： 不一定要挪威政府自己买单。超大规模云厂商呢？还有想把数据中心设在当地的其他国家政府呢？沙特阿拉伯有数吉瓦级的电力，他们正为此建设数据中心。

为什么欧洲不和沙特合作？沙特提出数据大使馆计划，欧洲可以对自身数据保持主权监管，同时利用当地能源，为什么不用？

这样问题就解决了。他们很快就会建成 3 到 4 吉瓦的产能。

主持人：也就是说，由超大规模云厂商出钱，去使用挪威的可再生能源，然后把它用起来。

Jonathan Ross ： 超大规模云厂商经常抱怨的是流程和审批太慢。我和一家建设核电站的大型能源公司董事聊过，他说在美国，办理许可的花费是电站本身建设费用的三倍。

欧洲我不太清楚，但通常美国在这方面都比欧洲效率更高。大家要记住的是，谁掌握算力，谁就掌控 AI；而没有能源，就不可能有算力。

  

06

## 先把电和算力建好

主持人：欧洲到底落后多少？我们有没有办法追上？会不会已经太晚了？我不想消极，也不算悲观，但这种差距还能追得上吗？

Jonathan Ross ： 如果欧洲现在就行动，我认为完全来得及。中国在执行上走在前面，但欧洲有 5 亿人口，美国有 3 亿多。

如果把盟友都团结起来，比如韩国，他们非常懂得建核电站，阿联酋那座核电站就是韩国建的，他们也可以在欧洲建；法国也会建核电站。

为什么不搞一个类似曼哈顿计划的能源建设项目？夏天的欧洲，热得厉害，冬天又冷得厉害。这种体验在其他地方不常见。多建设能源设施吧。

主持人：我赞同你的观点，但也得现实一点。无论单个政府还是跨国协作，我们的效率都很慢，达不到需要的速度。如果速度达不到，会发生什么？

Jonathan Ross ： 那欧洲的经济就会变成旅游经济，大家来这儿看看古老的建筑，就这样了。没有新经济所需的基础资源，就无法参与竞争。新经济就是 AI，而它建立在算力之上。

主持人：仅靠模型主权就能赢吗？

Jonathan Ross ： 站在服务提供方的角度看，如果没有算力，就跑不动 AI，模型再好也没用。

就算你的模型比 OpenAI 的聪明十倍，只要 OpenAI 的算力多你十倍，OpenAI 的实际效果就会更好。

主持人：所以对某些欧洲厂商来说，如果他们说我们有欧洲本地模型主权，德国的医疗系统、克罗地亚的交通部会用我们的模型，因为我们是欧洲选项，仅凭这一点并不足以取胜，对吗？

Jonathan Ross ： 那它的独特卖点是什么？

主持人：它是欧洲模型，不受美国公司控制，也不受某届美国政府的影响。

Jonathan Ross ： 这和有没有足够算力有什么关系？这解决的是不被别人控制的问题，但没有解决是否有足够算力的问题。顺便说一句，我不是让大家别用 Mistral。

我们和 Mistral 有合作，我们很支持他们。我的意思是，要建设足够的算力，让 Mistral 也能公平竞争。

主持人：照你这么说，人们会不会就想去疯狂采购某些云服务商的资源？毕竟他们按需供给，看起来很香。

Jonathan Ross ： 是的，那家公司很好，但他们拿到的 GPU 配额是有限的。每个人的配额都有限。

主持人：之前你说过，GPU 并不是最适合推理的基础设施。随着训练走向成熟，行业会越来越偏向推理。这难道不意味着英伟达的地位会进一步削弱吗？

Jonathan Ross ： 不会。英伟达造出来的每一块 GPU 都能卖出去。就算我们最终提供的 LPU1 数量是 GPU 的十倍，结果只会让对 GPU 的需求更大，让他们的利润率更高。

主持人：为什么会这样？

Jonathan Ross ： 因为推理越多，就越需要追加训练来优化推理效果；训练越多，又需要铺更多推理来摊薄训练成本。两者之间形成了正向循环。

主持人：全球有 10% 的人口每周都在使用 GPT，这不是很惊人吗？

Jonathan Ross ： 是的。但限制它进一步发展的还是算力。算力限制影响质量。如果能支持更多语言，会有更多人用。全球最常见的反馈就是这点。解决办法还是更多算力、更多数据。

有了更多数据，就能做更多训练，但这需要更多算力。反过来，有了更多算力，也能生成更多数据，从而继续训练。

AI 有三要素：数据、算法、算力。 提升其中任意一项，其他两项并不会马上成为瓶颈。不是说算力不提升就不能多用数据，也不是说数据不提升就不能多用算力。

只要有一项变好，AI 整体就会变好。这也让改进 AI 变得更可操作，因为可以先在某一个维度发力。

实践中，最容易调整，最快见效的，就是算力这一项。算法进步并不频繁，数据更难获取。我们还没完全把合成数据这条路走通。我们做得越来越好，但还没到把算力直接变成更多优质数据的程度。

算力之所以最容易调整，见效最快，是因为它几乎年年在进步。只要花足够的钱，再等一段时间，就能拿到更多算力。这是整个链条里最可预测的部分。

  

07

## 算力没有上限

## 主持人：既然它是整个链条里最可预测的部分。

Jonathan Ross ： 但我们仍然低估了对算力的真实需求量。

主持人：你觉得我们现在严重低估了所需的规模吗？

Jonathan Ross ： 是的，确实如此。

主持人：大概低估到什么程度？

Jonathan Ross ： 回到我之前说的，只要增加算力，产品就会更好。从可用规模上看，算力没有上限。

这和工业革命不一样。工业革命时期，只有先有机器才能用上能源，而且要先把机器造出来，这需要时间。

比如想让路上有更多汽车，必须先把车造出来，光从地下多挖点油是没用的。AI 不是这样。

没错，把模型做得更好，的确可以在同样算力下做更多事；但如果把算力翻倍，用户数会翻倍，模型质量也会提升。这很不一样。

只要给社会配上更多可用的计算能力，整体经济活动就会随之变强。

以往从没出现过这种状况，不再被某个环节卡住；只要把其中一个关键要素加大投入，整体表现就会随之一起提升。

主持人：你说经济会更强，这背后的前提是什么？是不是基于全球大约 10 万亿美元的人力支出向 AI 迁移，而我们能分到一部分？你觉得未来五年，GDP 构成或劳动力支出会不会明显向 AI 转移？

Jonathan Ross ： 我认为 AI 会带来大规模的用工短缺。我们可能没有足够的人来填补即将出现的岗位。

AI 会带来三件事：第一是强烈的通缩压力。 咖啡会更便宜，住房会更便宜，很多东西都会更便宜，这意味着人们所需的钱会更少。

主持人：为什么咖啡会更便宜？

Jonathan Ross ： 因为会有机器人更高效地种植咖啡，有更好的供应链管理；贯穿整条供应链都会提效。

甚至可以用基因工程让咖啡豆在同样日照下产量更高。所有环节一起作用，就会产生强烈的通缩压力。这是第一点。

随之而来， 第二点是人们可以减少工作 ：每周工作时长更少、工作天数更少、职业生涯更短，能更早退休，因为用更少的工作就能维持生活。

第三点是会出现全新的岗位、公司和产业，这些现在还不存在。

想想一百年前，美国 98% 的劳动力在农业，只有 2% 做其他事。后来农业从业降到 2% 后，我们也为那 98% 的人找到了新工作。

一百年后的很多职业，现在根本想象不到。就像一百年前，软件工程师这个概念也不存在。再过一百年，软件工程师可能也会变得没意义，因为人人都会 Vibe Coding。

网红这种职业一百年前也难以想象，但现在是真实存在而且能赚很多钱。

所以总结一下：第一，通缩压力；第二，因通缩而更多人选择减少工作；第三，会诞生当下不可能存在的新岗位和新公司，它们需要劳动力，而我们可能没有足够的人。

主持人：这和常见叙事完全相反。大家都在说会有大量失业，但你的意思是恰恰相反，我们反而会出现人手不够？

Jonathan Ross ： 一百年前最著名的预测是什么？说人类会大饥荒，因为无法养活自己。事实是，每次技术进步，人们总是低估经济会发生的深刻变化。

主持人：从能源需求，以及你刚才说的劳动力变化来看，你觉得特朗普及其政府对美国的 AI 发展是更有帮助还是更有伤害？

Jonathan Ross ： 明显是帮助。近期出台的一系列举措都有利于 AI，比如在许可审批方面的改革。总体上对 AI 很积极。

主持人：你提到过 Vibe Coding，我必须追问一下。你觉得这个市场能长期存在吗？现在很多用例看起来比较短期。你自己也玩过一些，你也说过实习生很会用，你怎么看 Vibe Coding 的前景？

Jonathan Ross ： 我认为 Vibe Coding 会像读写能力的变迁一样。过去识字写字是一种职业技能，抄写员因为会读写而受雇，收入也比一般人高，因为那是稀缺技能。

编程一直也是这样，只有少数人掌握，要学好得花上几年。

但今天人人都会读写，已不再是稀缺技能；未来编程也会变成常识，几乎所有岗位都需要。做市场要会编程，做客服也要会编程。

我和一位经营 25 家咖啡连锁店的人吃饭，他从未写过代码，但用 Vibe Coding 搭了个供应链工具，可以查库存。没写一行代码就让它跑起来了。

有趣的是，他也遇到了软件工程师常见的问题：员工反馈这个功能不行、那个边界情况出错，他就不断修补，这一切都通过 Vibe Coding 完成。

  

08

## 是真实价值还是情绪价值？

## 主持人：原谅我问个财务问题。现在标普快到 7000，七巨头拉升得厉害，价值高度集中，很多人开始觉得有点见顶。我该如何同时看待这两种想法？

Jonathan Ross ： 价值可以分成两部分：一部分像秤，衡量真实价值；另一部分像选美，看的是人气。

有些资产几乎完全取决于人气，比如加密货币。我从没买过比特币。是的，我错过了，因为我不擅长玩这种人气游戏，也看不准什么会火、什么不会。我能做的，就是盯着秤上的真实价值。

看 AI，我看到的是实打实在兑现的价值。最好的例子是，私募基金纷纷来找我们要便宜的 AI 算力，因为拿到更多廉价算力，他们就能直接改善所投企业的利润表。这是真价值，不是选美。

公司之所以拿到高估值，要么是市场相信真实价值会长期沉淀，要么是被情绪炒高，成了纯粹的选美。

市场参与者各不相同，有的人在玩选美，有的人在看秤，他们可能因为不同理由得出相似结论。

从秤的角度看，经济中最宝贵的是劳动。如今我们可以通过提供更多算力和更强的 AI，等于向经济体中增加劳动。这在经济史上从未出现过。

主持人：你担不担心如果短期内出现波动或挫折，因为价值过度集中在少数几家公司，会把经济的很多领域一起拖慢？大家现在涨得很猛，但如果英伟达、谷歌、微软突然遇到障碍，AI 的快车减速，连锁效应会非常大。你会担心吗？

Jonathan Ross ： 会的，而且这与 AI 的内在价值无关，更像控制理论里的动态反馈。

股市可以长期向上，但也会过热，过热会导致失控，人们把价格抬得过高，随后发现错误，价格回落，甚至跌破合理区间，支出收缩，企业拿不到建设所需资金。

很多好公司会在下行期倒下，但同样也常在这种周期里诞生最好的公司。我们会一次次看到，低谷之后涌现出一批了不起的新企业。

主持人：你觉得宏观层面会出现下行吗？

Jonathan Ross ： 我无法预测会不会出现下行。预测能力很大程度取决于预测会不会反过来影响结果。

如果预测会改变结果，那它就无法被准确预测，因为你的预测会改变结局。只有那些预测不会改变结果的事情才可预测。

比如一颗小行星正朝地球飞来，而我们观测到了。如果我们没有阻止它的技术，它就会撞上地球；但如果我们能提前观测并做出预测，我们也许就会发展出拦截它的技术。

你明白问题所在了吧。在经济中，我们不需要造出什么实体，只要资金在不同地方流动，人们根据预测做出反应，就会产生快速的短期波动，这反而让走势更难预测。

我无法告诉你经济接下来会怎样。我能说的是，目前我在 AI 领域看到的最大问题是，只要是原本我们想要聘用的优秀工程师，他们现在几乎可以自己去融资，筹到一两千万、上亿美元，甚至十亿美元。

于是他们就去创办自己的公司，而不是加入现有的 AI 创业公司，这导致任何一家初创公司都很难聚拢足够的人才。

另一方面，AI 又在提升这些公司里每个人的生产力。 至于经济是否过热，我认为一个很好的判断指标是，宏观是否已经开始妨碍企业的成功。如果没有妨碍，我就不觉得它过热。

主持人：你不觉得它已经开始妨碍了吗？从根本上说，资金供给过于充裕，反而让你组建顶尖工程团队变难了。因为资本把人才推到极致，他们可以自己融到巨款，而不是来加入 Groq。

Jonathan Ross ： 是的，请别再这样了。不过，AI 正在提高生产力，所以也有可能在经济持续繁荣的同时，各家公司依旧非常成功。我们不确定，因为我们从未经历过这种情形。

主持人：当下的人才争夺是不是已经疯狂了？

Jonathan Ross ： 确实比历史上的任何时候都更激烈，但主要发生在科技行业。体育圈一直很疯狂，或者至少近些年很疯狂。

回看二三十年前，体育的薪资结构很像现在的科技业，人们只是更清楚地认识到了价值。

不同在于体育有球队数量上限，还有工资帽等约束；而在科技领域没有这些限制，团队和初创公司可以无限多。

想象一下，如果任何人都能创建自己的橄榄球队，薪资会怎样膨胀，俱乐部的价值又会如何被重塑？

主持人：在现有大公司中，你最看好谁？最担心谁？

Jonathan Ross ： 我会说，在这场转变中，谷歌的动作幅度是最大的，而且它在这方面本身就有结构上的优势。

历史上谷歌更依赖工程师提出好点子，只要管理层少干预，谷歌就会冒出很多好东西。从文化角度看，这是一种系统性优势，对他们有利。

主持人： 我觉得 Gemini 最终算是他们的一次成功。

Jonathan Ross ： 看采用数据就知道，表现不错。

主持人：那在面向消费者产品的落地上，你怎么看？

Jonathan Ross ： 消费者产品这块我没那么看好。你会看到他们把 Gemini 东一榔头西一棒子塞进很多产品里，比如塞进了 Gmail 但几乎不可用，几乎每个产品都塞了点，看起来想法并不成熟。

不过也别太早下结论，至少他们在获取真实使用反馈，从而确定真正该做什么。想想 Google Chrome，当初起步还是 Google TV，完全失败，后来迭代成了 Chrome。

这就是典型过程：有人先把东西放出来，大家一顿吐槽，但我们没意识到他们愿意承受这些吐槽来把产品打磨得更好。

主持人： 只要分发优势的窗口期还在，挨骂也无所谓。难点在于这个窗口不再那么大了。OpenAI 把这道鸿沟大幅缩小了。

Jonathan Ross ： 确实如此，谷歌可能已经有点晚了。

主持人：你懂我的意思吧？这是个经典问题，老牌公司能否在初创公司拿到分发之前完成创新？现在初创已经拿到分发了，触达全球约 10% 的人，挺惊人的。

Jonathan Ross ： 是的，很难想象 OpenAI 会消失，我看不到这种可能。至少从现在起，赛道里会有两个长期对手相互竞争。

主持人：是哪两个？OpenAI 和 Anthropic，还是 OpenAI 和谷歌？

Jonathan Ross ： OpenAI 和谷歌。Anthropic 做的有些不同，更偏向编程工具；OpenAI 做聊天机器人；谷歌做聊天机器人，也做编程工具。谷歌几乎什么都在做。

主持人：不过 OpenAI 也在做编程工具呀。

Jonathan Ross ： 对，而且我们工程师最近用 Codex 的频率已经超过了 Anthropic 的工具。

有意思的是，这几乎是按月轮换的。我们的理念是，不规定工程师用哪款工具，但必须用 AI，否则没有竞争力。

我们看到他们先用 Sourcegraph，后来用 Anthropic，再后来用 Codex。下个月可能又回到 Sourcegraph。工具使用在循环往复地更替。

主持人：切换得这么随意，那这些工具还有持久价值吗？毕竟迁移成本这么低。

Jonathan Ross ： 我们的工程师是前沿用户，会在某个工具成为当下最佳时立即切换。但不是所有人都这样。

主持人：不过还是有很多人是这样的吧。

Jonathan Ross ： 你接触到的很多人是这样没错。但企业客户往往会签长期合同，然后在相当长时间内沿用一年前定下的工具。

  

09

## 护城河与毛利的取舍

主持人：如果让你选，5000 亿估值投 OpenAI，还是 1800 亿投 Anthropic？

Jonathan Ross ： 我两个都投。它们都被低估了，严重低估。我们现在看它们，好像是在一个有限市场里争夺有限结果；但实际上，它们通过持续研发在扩大整个市场的价值。

主持人：那展开说说，如果做一个多头情景，它们会发展成什么样？

Jonathan Ross ： 我认为当下的大型科技公司还能明显提升估值；同时，AI 实验室也会追赶到这些科技巨头的体量。

七巨头的价值会上升，而 AI 实验室的价值会追到与七巨头相当，但彼时七巨头又更高了。问题在于，AI 实验室最终会不会反超七巨头。

主持人：什么因素会决定结果？

Jonathan Ross ： 坦白说，我觉得最终会从七巨头变成九巨头、十一巨头，甚至二十巨头。

主持人：你觉得这些 AI 实验室会大举进入应用层，把大部分应用生态都收归旗下吗？

Jonathan Ross ： 这正是成功科技公司的自然倾向。他们一开始做客户在做的事，逐步往上游延伸，最后把客户原本做的部分吞并掉。随后会有新一代公司再在他们之上构建。

OpenAI 的做法也是如此。我记得 Sam Altman 在你的节目里说过，如果一款产品只是基于 OpenAI 做点小改进，终有一天会被他们碾过去。他只是坦诚说明他们的策略。

我们则划了一条界线，不和客户在模型层竞争，也就是我们不自研通用模型。通过明确这条界线，我们在传递一个信号：在我们的基础设施上构建是安全的，因为我们不会去抢你的业务。

当然，这个决定也可能是错的，将来我们也许会被某个客户反向吞并。但至少现在他们可以放心地在我们之上开发。我承认这可能是个很大的赌注。

主持人：确实可能。而且要自己做模型也需要很多资金。说到钱，你们这轮新融资是多少？

Jonathan Ross ： 我们融了 7.5 亿美元。

主持人：7.5 亿美元，对应的估值是 60 亿？

Jonathan Ross ： 对，接近 70 亿。

主持人：明白了，这听起来相当夸张。那这些钱够用吗？

Jonathan Ross ： 够的。其实我们原本只打算融 3 亿。你刚提到盈利性之类的问题，硬件公司在这方面更有优势，因为和很多公司不同，我们卖的东西本身就赚钱。我们卖硬件的单品毛利是正的。

主持人： 我以为你们毛利是负的。

Jonathan Ross ： 至少卖硬件不是。

主持人：那卖软件呢？

Jonathan Ross ： 软件要看具体模型。我们当前在量产芯片上跑的最受欢迎的模型是正毛利的。

但也有一些模型，运营成本可以覆盖，但我们对资本开销回收不满意。别人可能觉得那样也行，但我们更保守。

所以更容易表述的是：卖硬件这块基本都是正毛利，因为到交付那一刻，售价和成本就已经锁定了。至于模型侧的利润，还取决于硬件能用多久。

主持人：总体毛利率随时间会怎么走呢？

Jonathan Ross ： 作为未上市公司，好处之一是我不需要披露。

主持人：确实不需要，但如果你愿意说就更好了。

Jonathan Ross ： 这几乎是未上市公司唯一的优势了。

主持人：不不不，优势多着呢。没有锁定期、变现也更自由。

Jonathan Ross ： 是，但我不卖股份。

主持人：你从没卖过一股？你显然不太懂玩法，没事我可以教你。回到毛利，长期看会不会明显提升？你是怎么考虑的？我也不是一定要你说得特别具体。

Jonathan Ross ： 还是那句话，在保证业务稳定的前提下，我希望毛利尽量低。

高毛利的意义主要在于，当你需要资金时，可以通过提价迅速拿到现金；而在平常，你则有空间把毛利压低，以保持竞争优势。

算力需求极强，如果有人现在就需要而我们正好有货，他们愿意支付更高费用。这样一来，我们整体上就可以用更低的毛利率来运营业务。

  

10

## 从芯片到系统视角

主持人：帮我描绘下五年后的芯片市场格局。你说 OpenAI、Anthropic 等都会有自研芯片基础设施，同时还有英伟达。整体会是什么样？

Jonathan Ross ： 我的预测是，五年后英伟达的营收份额仍会超过 50%，但芯片出货量占比会低于半数。可能是营收占 51%，出货只占 10%。

主持人：这个怎么理解？

Jonathan Ross ： 品牌溢价的价值巨大，可以把价格定得更高，但这也会削弱企业进取心，从而倾向于维持高毛利。

很多客户也愿意买单，因为选英伟达没人会因此丢工作。这位置非常舒服、业务也会长期很值钱，投英伟达大概率没问题。

但从大客户视角看，当市场像现在这样，高度集中在三四十家头部买家手里，他们做决策会更少看品牌，更看业务成败所需，因为他们有足够话语权。

所以你会看到其他芯片也被采用，因为这些客户能自己拍板。

主持人：你说投英伟达不会差。我有个朋友常说一句话：这些都很好，可跟我有什么关系？所以直截了当问一句，以五年为期，英伟达 10 万亿美元市值，是高还是低？

Jonathan Ross ： 如果五年后英伟达不到 10 万亿美元，我会惊讶。更该问的是：五年后 Groq 会不会到 10 万亿？有可能。

我们不受同样的供应链约束，我们能造出比任何人都多的算力。现在最稀缺、被高价竞购的资源是算力，而我们几乎可以无限量供给。

主持人：关于 Groq，市场最没理解到，但应该理解的点是什么？

Jonathan Ross ： 这每个月都在变。以前大家以为我们做不到在同一硬件上服务多用户，后来我们就现场演示了多用户并发。他们还以为……

主持人：是因为你们的 SRAM 架构对吧。

Jonathan Ross ： 其实和 SRAM 有关。再说一个常见疑问。

主持人：上次学到了不少，谢谢你。我真的从你这学到很多。

Jonathan Ross ： 最常被问的是：SRAM 不是比 DRAM 贵吗？答案是贵。直观理解，按位算，SRAM 天生就要贵 3 到 4 倍，撇开其他细节不谈。

主持人：给不熟悉的观众再科普一下，SRAM 和 DRAM 的区别，尽量讲简单点。

Jonathan Ross ： 我尽量通俗点讲（不完全严格）。可以把 SRAM 理解为芯片内的存储，DRAM 是外部存储，本质更多在设计实现上。

DRAM 每个位由一个电容 + 一个晶体管组成，SRAM 每个位需要 6 到 8 个晶体管，所以单位存储位面积更大、硅用量更多、成本更高。

再加上 SRAM 常部署在更先进的芯片工艺上，比如 3nm，单位面积成本也更贵。

综合下来，按位成本可能是 DRAM 的 10 倍。但关键在系统层面，比如我们把 Kimi 这样的模型跑在 4000 颗我们的芯片上，而你把同一个模型跑在 8 块 GPU 上。

我们这边芯片数量是对方的 500 倍，意味着 GPU 侧要复制 500 份模型，用到 500 倍的外部内存。

所以即便 SRAM 按位贵 10 倍，对方在 DRAM 上用的内存是 500 倍，整体内存成本反而更高。这就是只从芯片单体看问题，和从系统整体看问题的经典差别。

我们的所有设计都坚持从系统视角出发，现在更扩展到全球视角。

我们会在全球数据中心之间做负载均衡。现在有 13 个数据中心，分布在美国、加拿大、欧洲、中东。做到全球分布后，决策就不能只停留在单个机房层面。

我们会根据各地区的使用情况，在某些机房多部署某些模型实例，并做不同的编译优化以适配输入或输出。

某个模型在某个机房可能根本不放，而是放在别处；然后通过全球调度来平衡。

这意味着我们的优化单位是全球，而不是单个数据中心。

  

11

## 算力供需差距太大

主持人：如果你不害怕，你会怎么做？

Jonathan Ross ： 我换个说法，我在哪些方面可以把业务的风险再加码？

主持人： 我问的就是这个。

Jonathan Ross ： 我们还没做的是，把供应链的订单直接翻倍。对，我们的供给周期是六个月，所以响应市场会比任何人都快。

主持人：你们的供给相对需求有多紧？

Jonathan Ross ： 就像我说的，上周有人找我们要五倍于他们现有总产能的算力。我们之所以没一股脑儿把筹码全压上去，原因只有一个。

主持人：在通用供给上加码嘛，为什么不就这么做？

Jonathan Ross ： 因为存在门槛。比如说，就算我们把产能翻倍，也拿不下那个客户，他们要的是 5 倍。翻倍还不够，必须 5 倍才够。那问题来了，产能翻倍之后，能不能覆盖这种级别的客户？

主持人：所以你们可加码的风险，具体是指什么？

Jonathan Ross ： 我们可以把产能建设的速度直接翻倍。这轮融资我们拿到的金额超过原计划的两倍，超额认购也达到了已募金额的四倍。

其实还能多融很多，但那样股权稀释会更严重。我得替投资人和团队考虑稀释问题。另一方面，我们也可以选择再多融，然后大规模把算力砸下去。

我们还有一个优势，在同等速度下，我们的每 Token 成本很占优。这意味着我们可以比市场更低价，这对做这类生意很关键。

不是因为大家抠门，而是因为只要我们把价格降一半，客户就会买两倍的量，他们花得越多，输出质量就越高，花费和收益是一起的。

主持人：你们会考虑上市吗？

Jonathan Ross ： 我们现在只专注执行。上市与否是另一种玩法，和我们当下做的不是一回事。眼下唯一重要的是，我们能不能满足算力需求。

主持人：接下来是快问快答。关于英伟达，如今最大的误解是什么？

Jonathan Ross ： 认为英伟达的软件是它的护城河。

主持人：所谓靠软件把客户锁死是扯淡？

Jonathan Ross ： 在训练阶段这点成立，但在推理阶段并不成立。我们现在平台上注册的开发者有 220 万了。

主持人：哇，那英伟达有多少？

Jonathan Ross ： 他们宣称有……

主持人：600 万。如果你在今天创办 Groq，英伟达市值四万亿，AI 大潮正盛，你会有什么不同做法？

Jonathan Ross ： 我不会做芯片了。那班车已经开走了，造芯片周期太长。

主持人：可现在也有新芯片公司不断冒出来，他们从头部机构那里融到很多钱。

Jonathan Ross ： 现在已经晚了。说说我当初做芯片的理由，我做过 Google TPU。离开前我还和 Google Brain 的同事在分类模型（比如 ResNet-50）上拿过最佳成绩。

我们做了实验，把当时所有结果都超了，所以我本可以转去算法方向。其实当初融资时我也没 100% 确定要做芯片，还想过做算法，尤其是形式化推理，庆幸后来没走那条路。

我选芯片的主要动机是护城河，时间护城河。VC 常问怎么防止别人抄袭？答案是就算照抄，也会比我们晚三年，这还是在一切顺利、从设计到量产只需三年的理想情况下。

我们现在已经做了三款量产芯片，全部都是一次流片成功（A0）。但行业里首版成功率只有 14%，也就是说我们有 86% 的概率需要重转一次。

我们做 V2 时甚至先把重转的排期都订好了，结果意外地首版就通了，这不应被当作常态。所以说三年是万事俱备的理想情况。

英伟达一代芯片通常要 3—4 年，他们是多代并行。Groq 现在是一年一更：V2 之后一年是 V3，再过一年是 V4。

主持人：你怎么看拉里·埃里森和甲骨文这波重新加速的腾飞？

Jonathan Ross ： 既做出了聪明的商业决策，又敢于迅速推进。大多数人当下都在犹豫，AI 会不会过热？要不要加码？他们没有犹豫，立刻全力投入，打法非常激进。

别人恐惧时就该大胆出手，别人贪婪时反而要收敛。眼下大环境更偏恐惧。你看到的那些有人很贪，还赚了大钱，本质上只是少数聪明又动作迅速的人抓住了机会。

主持人：那作为投资人，我什么时候该贪婪，什么时候该恐惧？

Jonathan Ross ： 其实很简单，护城河在哪，大家心里都清楚。我们都知道 Hamilton Helmer 的战略 7 力理论，看到护城河，就该贪婪。

主持人： 但真正有护城河的不多。

Jonathan Ross ： 是啊，尤其在偏早期的投资阶段更少。

主持人： 确实。

Jonathan Ross ： 所以你得提前判断它未来能长出护城河。

主持人：那如果有护城河，Pre……也配得上十亿美元估值？

Jonathan Ross ： 是啊，叫它“Pre-seed、Pre-moat”（种子前、护城河前）都行。投资人可以直接标注成“Pre-moat”。

主持人：过去 12 个月里，你哪件事改主意了？

Jonathan Ross ： 与其说我改变了想法，不如说我在调整资源配比，把更多精力压到更少的重点方向上。我们每个月都更聚焦，拒绝更多事，业务反而表现更好。

以前我觉得最重要的是保留选择权，现在我认为更重要的是聚焦。当然，早期的选择权至关重要，它让我们摸到最有胜算的赛道；而到了现在，重心就是聚焦。

主持人：聊了很多 OpenAI 和 Anthropic。你觉得埃隆·马斯克能把 xAI 和 Grok 做成吗？

Jonathan Ross ： 能，但路数可能不同。每当一个新领域出现，很多人以为彼此在同一条赛道厮杀，其实不然。做基础模型的这些人，常以为在为同一目标竞争。

Anthropic 的高明之处在于不在所有方面都竞争，而是聚焦在编程，这对他们很有用。再看 xAI，他们有社交网络，并把聊天机器人和它结合。

我不会用那个聊天机器人做深度研究或复杂分析，也不会用它来写代码。虽然他们也有写代码的模型，但缺少在代码领域的分发。

他们能借社交分发切进编程吗？也许能，但专注度就会被分散。他们走的是另一条路。

市场最终会分化。七巨头之间业务有重叠，但各自主业不同。不做差异化，就会被淘汰。

主持人：在谷歌、微软、亚马逊里，你会买谁、卖谁？

Jonathan Ross ： 看时间维度。短期内，微软因为与 OpenAI 的关系在做一些重置；长期看，他们大概率仍会表现不错。

主持人：明白。那这是实质性伤害吗？

Jonathan Ross ： 不是。所以我才说这是短期影响。长期就未必。

主持人：他们不是从中获益良多吗？既持有 OpenAI 的财务权益，又能在很多场景里灵活用 Anthropic。

Jonathan Ross ： 而且他们已经部署了庞大的算力。就算 OpenAI 多元化，去别处拿算力，微软自己也握有充足的算力，算力就像黄金，有算力就有 AI。

至于亚马逊，我觉得它缺少 AI 的基因。你刚没提 Meta。Meta 和谷歌一直有 AI 基因，微软则通过 OpenAI 买来了这种基因，也为自己赢得了时间。亚马逊仍然缺这层基因，但它有算力。

主持人：最后一个问题。展望未来 5 到 7 年，你最期待什么？我想以积极的调子收尾。

Jonathan Ross ： 大多数人害怕的事，恰恰让我兴奋。大家担心 AI 会带来什么，我觉得可以用伽利略做比喻。几百年前，伽利略让望远镜普及，为此惹了大麻烦。

因为望远镜让我们看到了真相，宇宙比想象中更辽阔，于是我们感到自身渺小。后来我们发现，人类很小，宇宙却广阔而动人。

我认为大模型是心智的望远镜。它们现在让我们觉得自己很渺小，但一百年后，我们会意识到智能的广阔超乎想象，而那同样是美的。

主持人：每次和你聊我都记一大堆笔记。非常感谢你来做这期节目，这期播客太棒了。

Jonathan Ross ： 谢谢。

![图片](https://mp.weixin.qq.com/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

**更多阅读**

****

[Sam Altman：我承认我之前错了，AI 超级系统才是 OpenAI 真正想要的](https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247519842&idx=1&sn=646386c4052f9034647764da2db422db&scene=21#wechat_redirect)

[对话 Plaud 莫子皓：你还记得 PMF 的感觉吗？](https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247519706&idx=1&sn=6e88af744628a77c9da729c610d5c30b&scene=21#wechat_redirect)

[Nano Banana 核心团队：图像生成质量几乎到顶了，下一步是让模型读懂用户的intention](https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247519625&idx=1&sn=d7e7674cb6b1aeb30ea7c7d3192d4cc9&scene=21#wechat_redirect)

[扒完全网最强 AI 团队的 Context Engineering 攻略，我们总结出了这 5 大方法](https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247519771&idx=1&sn=4545fdbabc8569d791901315c37a9389&scene=21#wechat_redirect)

****

转载原创文章请添加微信：founderparker

继续滑动看下一个

Founder Park

向上滑动看下一个