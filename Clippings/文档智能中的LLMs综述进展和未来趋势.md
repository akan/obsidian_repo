---
title: "太重要了，文档智能中的LLMs：综述、进展、和未来趋势"
source: "https://mp.weixin.qq.com/s/KLlHG3CIVoOtaZHp4Ffu5g"
author:
  - "[[AI修猫Prompt]]"
published:
created: 2025-09-26
description: "文档智能的“终局”之战：RAG与长上下文，谁是处理复杂文档的未来？"
tags:
  - "文档智能"
  - "LLM技术"
  - "RAG框架"
  - "长上下文处理"
  - "表格识别"
abstract: "这篇论文全面综述了大型语言模型在文档智能领域的技术进展，重点分析了管线式与端到端解析、RAG与长上下文处理等核心技术的优劣与协同方案。"
---
Original AI修猫Prompt *2025年09月26日 17:37*

随着数字化时代的到来，文档数量急剧增加。文本文件、网页、幻灯片、海报、电子表格数据，甚至场景文本图像。这些文档不仅封装了不同行业内部和外部事务的处理细节和积累的知识，还涵盖了大量的行业相关实例和数据，其中蕴藏着难以估量的价值。并且近年来，以GPT系列为代表的大型语言模型（LLMs）极大地推动了文档智能领域的发展，让我们以为像合同审核或财报问答的任务可以直接交给AI梭哈处理，但当我们把一年的发票、合同、年报塞给模型，问它“ **本季度净利润同比** ”时，模型愣住了：文本对了， **结构没了** ；答案有了， **溯源没了** ；上下文加长了， **幻觉爆了** 。

![Image](https://mmbiz.qpic.cn/mmbiz_jpg/Iurk1iaf4xdGfByP8zJQaA3GE90Rib4v1r8BYmcvVPt0Pxl0dp1OrK5SjicK51GiaW4NraKAH5DKT7KPY37nG5Q8mA/640?wx_fmt=jpeg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

因此如何高效地自动分析、分类、提取和查询这些文档，把文档的价值规模化释放变得至关重要。这正是今天这篇论文要解决的核心问题，来自东南大学及北京计算机技术及应用研究所的研究者们把 **管线式与端到端** 的取舍、 **RAG 与长上下文** 的协同、以及 **表格、版面、公式** 这些“难啃骨头”放在一起，给出了一套可落地的 **工程蓝图** 。这篇文章已经被ACM接受。

![Image](https://mmbiz.qpic.cn/mmbiz_png/Iurk1iaf4xdGfByP8zJQaA3GE90Rib4v1rNgbOlo918tmCs3ne12xk7k7zPiby9nzytGOicrL7UTdPfdt8U5qQ4SUQ/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)

**主要贡献包括** ：

- **全面的文献回顾** ：回顾了总共322篇论文，重点分析了2021年至2025年间发表的265篇论文，提供了对该领域演变的深入视角。
- **深入分析当前开发范式** ：系统比较 **管线式解析 vs 端到端解析** ，涵盖了文档解析、归纳 **文档和表格专用LLM** 、细化 **RAG（检索增强生成）全链路** 、梳理 **长上下文** 方法。
- **总结实际应用、数据集和评估标准** ：整理了20个真实世界的应用任务、30个常用数据集、6个基准测试套件和16个评估指标。
- **探讨挑战与未来方向** ：讨论了文档LLMs领域当前面临的主要挑战和未来的发展方向。

### 精华摘要：文档智能的认知导航图

面对AI处理复杂文档时“理想很丰满，现实很骨感”的困境，这篇重磅综述论文为我们提供了一份清晰的“作战地图”。本文将为您系统拆解这份地图的核心内容，主要聚焦于三个层面：

- **两大主流范式** ：深入对比 **管线式 (Pipeline)** 的模块化组合与 **端到端 (End-to-End)** 的一步到位，分析二者在工程实践中的优劣与取舍。
- **四大核心技术** ：详细剖析当前最关键的技术路径，包括 **文档解析** 、 **专用LLM微调** 、大热的 **RAG (检索增强生成)** 以及突破瓶颈的 **长上下文处理** ，看它们如何协同解决表格、版面、多页等难题。
- **一套完整生态** ：全面梳理从 **数据集** 、 **开源工具** 到 **行业基准** 和 **评估指标** 的完整生态，为技术的评估和落地提供依据。

相信您看完后会对当前的文档智能领域有一个全面而又系统的认识

## 文档智能的8个核心挑战

研究者们首先总结了文档处理中普遍存在的八大挑战（CH1-CH8），这些是理解后续技术方案的出发点：

![Image](https://mmbiz.qpic.cn/mmbiz_png/Iurk1iaf4xdGfByP8zJQaA3GE90Rib4v1rSjTgxWFNsXFU1jic4QiboC1yqdAf3MAVSAm1PlWejLq0DbbBqTKSqQAg/640?wx_fmt=png&from=appmsg&watermark=1&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=2)
1. **文档解析 (Document Parsing)**: 如何准确地从多样的格式（PDF、图片）中提取文本、布局、表格等信息，并处理扫描噪声。
2. **复杂布局 (Complex Layouts)**: 文档通常包含页眉、页脚、多栏、图表等复杂排版，模型需要理解这些视觉布局才能正确理解内容。
3. **富含细节的图像 (Rich-detail Images)**: 文档中的图像（如图表、示意图）比自然场景图像分辨率更高、细节更丰富，对视觉编码器要求很高。
4. **多页文档 (Multi-page Documents)**: 如何在处理多页文档时保持上下文的连续性，关联跨页信息。
5. **表格识别 (Tabular Recognition)**: 准确地识别表格的行、列、单元格边界，特别是对于复杂的合并单元格。
6. **表格推理 (Table Inference)**: 不仅要识别表格，还要能对表格中的数据进行逻辑和数学推理（如计算财务报表）。
7. **多模态信息利用 (Multimodal Information Utilization)**: 如何有效融合文本、图像、表格、布局等多种模态的信息。
8. **长上下文 (Long Context)**: 文档通常很长，内容远超现有LLMs的上下文窗口限制，导致信息处理不完整。

## 两大主流技术范式

研究者们将当前的技术方案归纳为两大范式，这两种范式的主要区别在于是否依赖传统的光学字符识别（OCR）工具。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **流水线范式 (Pipeline-based / OCR-based)**:
- **流程**: 这是一个模块化的、分阶段的处理流程： `文档图像 -> 图像预处理 -> 布局分析 -> OCR识别 -> 语义理解` 。每个阶段使用专门的工具或模型，例如用OCR工具提取文字，再将文字输入LLM进行理解。
- **优点**: 结构清晰，每个模块可以独立优化，可解释性强。
- **缺点**: 流程长，容易产生 **错误累积** （前一阶段的错误会传递并影响后续阶段），且工程开销大。
- **端到端范式 (End-to-End / OCR-free)**:
- **流程**: 直接将文档图像和任务指令作为输入，通过一个统一的多模态大模型（MLLM）直接生成最终结果（如JSON格式的结构化数据）。代表模型有 `Donut` 、 `Nougat` 。
- **优点**: 避免了中间步骤的信息损失，对复杂布局和非标准文档的适应性更强。
- **缺点**: 需要极大的模型、海量的训练数据和巨大的计算资源，且容易出现“幻觉”问题。

## 关键技术一：文档解析

文档解析是文档智能流程的入口，其核心目标是将各种格式的文档（如扫描件、PDF、网页等）作为输入，输出结构化的、机器可理解的表示或语义信息。这项技术主要通过两种不同的范式来实现：

**基于管道（Pipeline）的方法** 和 **端到端（End-to-End）的方法** 。

### 1\. 基于管道 (Pipeline) 的方法

这种方法继承了传统的文档分析理念，将复杂的解析任务分解为一系列独立的、顺序执行的模块化步骤。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

#### 核心流程

一个典型的管道流程包含以下几个关键环节：

- **图像处理 (Image Processing)** ：这是最初的预处理阶段，目的是提升文档图像的质量，为后续步骤打好基础。具体任务包括：
- **预处理** ：如图像去噪、对比度增强、二值化等。
- **校正** ：修正图像的倾斜、失真等问题。
- **移除干扰** ：去除边框、水印等装饰性元素。
- **布局分析 (Layout Analysis)** ：此阶段旨在识别和分割文档的物理结构，理解各个内容元素（如文本块、标题、表格、图片）的位置和关系。
- **技术演进** ：早期研究直接使用CNN进行布局单元检测，而近年来基于多模态Transformer的方法，通过结合图像和文本嵌入信息，取得了更好的效果。例如，将文档表示为图结构，然后利用图神经网络（GNN）进行分割和分类。
- **内容识别 (Content Recognition)** ：在完成布局分析后，此阶段专注于识别具体内容。
- **文本识别 (OCR)** ：这是最核心的部分，包括识别印刷体、手写体和场景文本。研究人员利用Transformer架构统一文本检测和识别任务，或通过自监督学习提升模型的鲁棒性。
- **数学公式识别** ：由于公式包含复杂的结构（如上下标、特殊符号），识别难度远超普通文本。相关方法通常先检测公式实体，再利用多模态Transformer进行分组和解析。
- **实体标准化** ：在OCR之后，文本可能存在错误，此步骤旨在消除实体（如人名、机构名）的歧义，并将其转换为标准化的标识符。
- **语义理解 (Semantic Understanding)** ：这是管道的最后一步，旨在从识别出的内容中提取有价值的信息，并理解其含义。任务包括：
- **信息提取** ：从文本中抽取关键实体和关系。
- **文档问答 (Q&A)** ：根据文档内容回答用户提问。
- **摘要生成** ：自动生成文档的核心内容摘要。

#### 优点与缺点

- **优点** ：每个模块都可以独立进行优化和替换，系统具有很强的可解释性和可控性。
- **缺点** ：流程较长，且前一阶段的错误会传递并累积到后续阶段，可能导致整体性能下降。

#### 相关工具

许多开源工具和框架都采用了管道模式，例如：

- **PP-Structure** ：集成图像校正、布局分析和多种识别工具，进行文档解析。
- **Docling** ：一个Python包，集成了布局分析和表格结构识别等功能。
- **MinerU** ：集成了OCR、表格识别、公式识别等多个开源工具，并进行了大量的工程后处理。
- **RagFlow** ：一个专注于文档解析的RAG框架，应用OCR技术和解析器支持不同格式的文档解析。

### 2\. 端到端 (End-to-End) 的方法

与管道方法相反，端到端范式利用一个统一的多模态大模型（MLLMs），直接将原始文档图像和任务指令（Prompts）作为输入，一次性生成最终的解析结果。这类方法通常也被称为“OCR-Free”方法，因为它们不依赖外部的OCR工具来提取文本。

#### 核心思想

端到端方法的核心是训练一个大型视觉语言模型（LVLM），使其能够直接理解图像中的文本和布局信息。

- **模型训练** ：通常需要构建大量的 `<prompt, doc_image, ocr_md>` 三元组数据对模型进行特定训练和微调。
- **代表性模型** ：
- **Donut** ：首个提出的OCR-Free模型，直接将输入图像映射到结构化输出。它在预训练阶段学习“阅读”文本，在微调阶段学习根据下游任务“理解”整个文档。
- **Nougat** ：使用Swin Transformer编码器和mBART解码器，将PDF格式的学术文档直接转换为机器可读的Markdown语言。

#### 优点与缺点

- **优点** ：
- 避免了管道方法中因多模块串联而导致的错误累积问题。
- 在处理复杂布局和非标准文档时展现出更强的适应性。
- 流程完整且平滑。
- **缺点** ：
- 容易出现“幻觉”（Hallucination）和泛化能力不足的问题。
- 需要极大的模型规模、海量的训练数据和巨大的计算资源。
- 推理速度慢，内存消耗高，限制了其在实时场景中的应用。

文档解析技术正处于从传统的、模块化的管道方法 向更集成、更强大的 **端到端方法** 演进的过程中。管道方法成熟、可控，在许多场景下依然是实用且必要的选择。而端到端方法则代表了未来的发展方向，尽管目前仍面临性能和资源上的挑战，但其潜力巨大。

## 关键技术二：文档和表格专用LLM

第二种关键技术， **微调文档LLMs (Fine-tuning Document LLMs)** 。

这项技术的核心思想是，虽然通用的多模态大模型（如BLIP、FlanT5）具备理解图像和文本的基础能力，但它们并未针对文档这种富含文本、布局复杂、结构多样的特殊“图像”进行优化。因此，通过微调 (Fine-tuning) 的方式，可以将这些通用模型的能力继承下来，并进一步发展出专门处理文档任务的专业模型，即 **文档LLMs (Document LLMs)** 。

论文将这一技术领域分为两大类：通用的 **文档LLMs** 和专门针对表格的 **表格LLMs (Table LLMs)** 。

### 1\. 文档LLMs (Document LLMs)

文档LLMs旨在通过端到端的方式全面理解整个文档，有效保留视觉布局、结构信息和多模态线索，特别适用于需要精确布局保留和综合多模态推理的任务。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

#### 典型的微调框架

一个典型的微调流程如上图所示，它通常包含几个关键组件：

1. **冻结的骨干模型 (Frozen Backbones)** ：通常会使用两个预训练好的、参数被冻结（不参与训练）的模型，例如一个视觉编码器（如BLIP）用来理解图像，一个大型语言模型（如FlanT5）用来处理文本和指令。
2. **可训练的“桥梁”结构** ：为了将视觉信息和语言信息对齐，会引入一些可训练的模块。例如，论文中提到的 **Document-former** 和前馈网络（FFN）。Document-former的作用是将视觉编码器输出的图像信息映射到语言模型的语义空间中。
3. **输入与输出** ：输入通常包括文档图像、从图像中提取的OCR文本和坐标信息，以及一个描述任务的指令（Prompt）。这些信息被送入模型后，LLM最终生成任务所需的结果，如分类、问答等。

#### 解决的关键挑战与相应技术

微调文档LLMs主要为了解决以下几个核心挑战：

- **挑战一：复杂的结构与布局理解 (Structure and Layout Understanding)**
- **问题** ：文档的语义不仅由文本决定，还与布局（如标题、列表、段落的位置关系）紧密相关。
- **解决方案** ：将布局信息作为一种独立的模态输入给模型。
- **DocLLM** ：通过OCR获取每个文本token的 **边界框坐标** ，并将这些空间布局信息作为独立向量与文本信息一同输入模型。
- **LayoutLLM** ：使用像LayoutLMv3这样的编码器来处理文档图像，并显式地表示其二维位置特征（如左上角和右下角坐标）。
- **InstructDoc** ：同样使用OCR提取文本和文本框坐标，并通过Document-former将视觉编码器、OCR坐标和LLMs连接起来。
- **挑战二：高分辨率图像处理 (High-Resolution Image Processing)**
- **问题** ：与自然图像相比，文档图像的分辨率更高，信息密度更大。而大多数视觉编码器的输入分辨率有限，直接缩放会导致关键细节丢失。
- **解决方案** ：采用特殊的图像处理策略，以OCR-Free的方式处理高分辨率图像。
- **mPLUG-DocOwl1.5** ：采用 **形状自适应切片** 模块，将高分辨率图像切成多个子图进行处理。
- **TextMonkey** ：使用 **滑动窗口** 来划分高分辨率图像，并通过 **令牌重采样器** 来压缩过长的令牌序列，以在保留信息的同时提高效率。
- **Fox** ：通过高压缩率将一个1024×1024的页面压缩成256个图像令牌，实现了对多页文档的高效微调。
- **挑战三：多页文档理解 (Multi-Pages Document Understanding)**
- **问题** ：真实世界的文档大多是多页的，模型需要理解和关联跨越不同页面的信息。
- **解决方案** ：
- **分层处理** ：像 **Hi-VT5** 和 **InstructDoc** 这样的模型，会先独立处理每一页，然后将每页的输出（如嵌入向量）进行聚合（如通过平均池化），最后送入LLM生成最终答案。
- **统一嵌入** ：将不同页面的图像块、OCR文本和坐标等信息嵌入到一个统一的空间中，从而让模型能够更好地捕捉跨页面的关系。
- **先进视觉建模** ：利用 **DocOwl2** 等模型中的高分辨率文档压缩模块，在压缩图像特征的同时保留关键的布局和文本信息，从而高效处理多页文档。

### 2\. 表格LLMs (Table LLMs)

表格是文档中一种常见且重要的结构化数据形式，但其复杂的结构（如合并单元格）给LLM的理解和推理带来了巨大挑战。表格LLMs就是专门为应对这些挑战而设计的。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

#### 主要技术路径

- **路径一：表格数据训练 (Tabular Data Training)**
- **核心思想** ：通过构建包含多种表格任务的大规模训练数据来专门训练LLM，提升其理解表格的能力。
- **代表模型** ：
- **Table-GPT** ：为不同的表格任务（如查找列、错误检测、表格摘要）综合并构建训练数据，然后对模型进行“表格微调”。
- **TableLLM** ：不仅使用现有的基准训练数据，还从可用表格数据中自动生成新的问答对，并通过交叉验证策略确保生成数据的质量。
- **TableLlama** ：从维基百科的电子表格中构建了包含表格解读、增强、问答和事实核查等多种任务的训练数据。

  

- **路径二：基于提示的表格推理 (Prompt-Based Table Reasoning)**
- **核心思想** ：应用 **思维链 (Chain of Thought, CoT)** 和 **情境学习 (in-context learning)** 等技术，将复杂的表格推理问题分解为多个步骤，逐步解决。
- **代表模型与方法** ：
- **TableCoT** ：利用包含多个示例的 **少样本 (few-shots)** 提示形式，引导模型进行复杂表格的推理。
- **DATER** ：如上图所示，首先利用LLM将复杂问题分解为子问题，并提取相关的子表格；然后将子问题转换为可执行的查询（如SQL），最后再进行推理得到答案。
- **Chain-of-Table** ：定义了一系列表格操作（如添加列、排序等），在推理的每一步，模型会动态生成一个操作来更新表格，从而形成一个清晰的推理链条。

“微调文档LLMs”是一项关键技术，它通过在通用大模型的基础上进行专门化的训练，使其能够精准地理解文档特有的布局、结构和内容，无论是处理复杂的扫描文档还是进行基于表格的逻辑推理，都展现出了比通用模型更强的性能。

## 关键技术三：RAG检索增强生成

RAG，Retrieval-Augmented Generation是一种强大的框架，旨在解决大型语言模型 (LLMs) 在处理信息密集、冗长或专业领域的文档时面临的挑战。其核心思想是，不完全依赖 LLM 内部存储的知识，而是通过一个 检索器 (Retriever) 从外部知识库（在这里就是指待处理的文档）中动态查找相关信息，然后将这些信息与用户的原始问题一起提供给 **生成器 (Generator)** ，也就是 LLM，从而生成更准确、更具事实依据且上下文更相关的回答。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

### 1\. 预处理 (Preprocessing)

#### 数据清洗 (Data Cleaning)

在将文档存入知识库之前，必须进行有效的数据清洗，因为原始文档中包含的大量无关信息会干扰后续的检索效果。

- **基本文本清洗** ：统一文档格式，移除特殊字符、无关细节和冗余信息。例如，HtmlRAG 会自动清理 HTML 文档中的 CSS 样式、JavaScript 代码和不必要的标签属性。
- **数据增强 (Data Augmentation)** ：通过同义词替换、释义或多语言互译等方法来扩充和丰富知识库，这在数据资源较少的场景下尤其有效。

#### 分块 (Chunking)

由于 LLMs 存在固定的上下文窗口限制，无法一次性处理长文档。因此，分块技术成为一种必要的解决方案。它将长文档分割成多个符合模型窗口大小的片段。

- **简单分块 (Simple Chunking)** ：将文本分割成固定大小的片段，这是一种直接且常用的策略。可以通过设置重叠（overlap）来缓解语义单元被切断的问题。
- **基于规则的分块 (Rule-based Chunking)** ：利用文档的结构特征或特殊符号（如换行符）进行分割。例如，

**递归分块 (recursive chunking)** 会使用一系列分隔符（如 `\n\n` 、 `\n` ）来迭代地分割文本。

- **基于语义的分块 (Semantic-based Chunking)** ：识别并组合文档中具有语义意义的元素，如表格、多级标题及其相关内容，从而生成上下文更连贯的块。

### 2\. 检索 (Retrieval)

检索是 RAG 的核心，其准确性直接影响最终生成内容的质量。这个过程通常分为三个阶段。

#### 检索前 (Pre-retrieval)

在正式检索之前对查询进行优化，以提高检索的效率和质量。

- **查询重写 (Query Rewriting)** ：改进用户查询，解决其中可能存在的模糊、拼写错误或不具体等问题，使其更好地与知识库对齐。例如，HyDE 方法会从用户查询中生成一个“假设性”文档，然后用这个文档来引导检索。
- **元数据利用 (Metadata Utilization)** ：利用文档的元数据（如作者、文档类型、章节标题）来提供额外的上下文，或作为过滤器来缩小检索范围，提高相关性。

#### 正式检索 (Formal Retrieval)

这个阶段的目标是找到与用户查询最匹配的文档块。

- **检索器类型** ：
- **稀疏检索器 (Sparse Retrievers)** ：主要依赖词法分析，将文本编码为高维稀疏向量。经典的

**BM25** 算法是其中的代表，它基于词频和逆文档频率来评估相似度。

- **密集检索器 (Dense Retrievers)** ：将文本编码为低维密集向量，能更好地捕捉语义信息。

**DPR** 是一个著名的密集检索器，它使用双塔 BERT 编码器来分别编码查询和文档。

- **检索策略** ：
- **基于迭代的检索 (Iteration-based Retrieval)** ：对生成的结果进行多次迭代，在每次迭代中都进行检索和生成，以逐步优化输出质量。
- **基于多路径的检索 (Multipath-based Retrieval)** ：将原始查询分层分解为多个子查询，从不同角度进行检索，以丰富检索到的内容，拓宽生成任务的上下文。

#### 检索后 (Post-retrieval)

在初步检索（通常是 top-k 选择）之后，对结果进行进一步筛选，以确保提供给 LLM 的都是高度相关的内容。

- **重排 (Reranking)** ：对检索到的文档块重新排序，将与查询最相关的块排在前面。例如，TrustRAG 框架中的重排模块会从多个检索路径中融合结果，并进行综合评估和优化。
- **过滤 (Filtering)** ：移除不满足特定相关性阈值的文档块。

#### 多模态检索 (Multimodal Retrieval)

对于包含图像、表格等非文本内容的文档，检索策略也需要相应调整。

- **基于 OCR 的检索** ：这是主流方法，先用 OCR 工具将文档中的视觉内容转换为机器可读的文本，然后进行语义检索。但这种方法通常会忽略图像和图形内容，并且表格转换可能导致空间和结构信息丢失。
- **基于 VLM 的检索** ：利用视觉语言模型 (VLM) 来处理多模态信息，将文本和图像都编码到统一的向量空间中。例如，M3DocRAG 系统使用视觉编码器处理文档页面，然后计算查询与页面之间的相似度来检索最相关的页面。

### 3\. 检索增强提示 (Retrieval-Augmented Prompting)

在检索到相关文档块后，需要将它们与用户的原始查询结合起来，形成一个新的、信息更丰富的输入，即“检索增强提示” (RAP)。

- **简单拼接** ：最直接的方法是将检索到的文档内容与用户查询简单地拼接在一起。
- **结构化保留** ：当检索到的是 JSON 文件、表格或知识图谱等结构化文档时，保留其原始结构对于增强语义信息至关重要。

### 4\. 推理 (Inference)

最后，LLM 基于增强后的提示进行推理和生成最终答案。为了处理文档中复杂的语义和结构关系，推理过程也需要优化。

- **思维链 (CoT) 推理** ：像 EvidenceChat 这样的系统利用 CoT 来指导检索、提取和生成过程。
- **多智能体框架 (Multi-agent Framework)** ：ViDoRAG 引入了一个包含多个专业智能体（如搜索智能体、检查智能体）的框架，通过迭代推理来提高对富视觉文档的回答准确性。

RAG是一种高度模块化和可扩展的技术，通过将外部知识的“即时”检索与 LLM 的强大生成能力相结合，极大地提升了其在文档智能任务中的表现，特别是在处理长篇、复杂和多模态文档时显示出巨大优势。

## 关键技术四：长上下文处理

在文档智能领域，许多任务（如分析法律合同、学术论文）都需要模型能够理解和处理跨越数千甚至数万个词的超长文本。 但作为现代LLM基础的Transformer架构在处理长上下文时面临着固有的挑战。 长上下文处理 (Long Context Processing)这项技术就是为了突破这些限制而发展起来的。

### 为什么长上下文处理如此困难？

研究者们首先指出了 Transformer 架构在处理长文本时遇到的三大核心挑战：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
1. **文本长度编码的限制** ：Transformer 使用位置编码来为每个词（token）提供其在序列中的位置信息。这种编码的长度是在训练时固定的，一旦输入文本超过了训练时的最大长度，模型就无法有效地定位和处理超出部分的信息。
2. **注意力机制的资源消耗** ：标准自注意力机制需要计算序列中每个 token 与所有其他 token 之间的关系。这意味着计算复杂度和内存需求会随着序列长度的增加而呈二次方级增长，导致处理长文本时资源消耗巨大且效率低下。
3. **长距离依赖关系处理不足** ：虽然自注意力机制理论上可以捕捉序列中的任何依赖关系，但它往往更关注局部信息，导致在捕捉超长距离的语义关联时效果不佳。

为了应对这些挑战，研究人员从多个角度提出了创新的解决方案。将这些技术分为以下几类：

### 1\. 位置编码 (Positional Encoding) 的优化

这类方法旨在修改或扩展位置编码，使其能够适应比训练时更长的文本序列。

- **位置插值 (Position Interpolation, PI)** ：此技术通过“减慢”位置编码的旋转速度，将原本为较短文本设计的位置编码平滑地“拉伸”，以覆盖更长的上下文。
- **NTK-Aware 插值** ：这种方法在插值时考虑了不同频率分量的特性，对高频和低频部分进行差异化处理，以达到更好的外推效果。
- **YARN (Yet another RoPE extensioN method)** ：该方法引入了“温度缩放”的概念，对旋转位置编码（RoPE）的不同维度进行非均匀插值，以最小化困惑度（一种衡量模型性能的指标）的方式找到最优插值方案。
- **LongRoPE** ：该方法采用渐进式扩展策略，在已经微调过的模型上进行第二次插值，进一步扩展上下文窗口。

### 2\. 注意力机制 (Attention Mechanism) 的优化

这类方法的核心是通过近似或稀疏化注意力矩阵来降低计算和内存成本，同时尽量保留关键信息。

- **滑动窗口注意力 (Sliding Window Attention)** ：代表模型是 **Longformer** 。它不计算全局注意力，而是让每个 token 只关注其邻近的一个固定大小的窗口内的其他 token。
- **保留初始 Tokens (Attention Sinks)** ： **StreamingLLM** 发现，在 LLM 的推理过程中，大部分注意力得分会集中在序列最开始的几个 token 上。因此，该方法在滑动窗口的基础上，额外保留了这些初始 token 的键值对（KV pairs），使得模型在处理无限长的文本流时也能保持稳定。
- **分组注意力与滑动窗口结合** ： **LongLoRA** 在微调时将长上下文分成多个组，在组内进行完整的自注意力计算，而在组间则通过滑动窗口机制进行信息交换。
- **其他稀疏注意力方法** ：
- **LongNet** ：引入了“扩展注意力”的概念，通过分段输入并根据 token 间距离的增加逐步并行化分配稀疏注意力。
- **Unlimiformer** ：在每个解码器层之前使用 kNN 搜索，从整个输入序列中为每个注意力头选择 top-k 个最相关的隐藏状态，从而在不截断输入的情况下关注全局信息。

### 3\. 内存管理 (Memory Management)

这类技术通过引入外部内存模块，让模型能够存储和检索超出当前上下文窗口的信息，模拟一种“长期记忆”。

- **Landmark Attention** ：在输入序列中设置“地标”（landmarks），模型可以根据这些地标来检索相关的内存块。
- **基于 KV 缓存的内存** ： **LongMEM** 使用一个内存缓存库来维护最近输入的注意力键值对。在推理时，模型可以同时关注局部上下文和从内存中检索出的历史上下文。
- **分层内存系统** ： **MemGPT** 受到操作系统分层内存系统的启发，通过一个虚拟上下文管理系统来实现对海量信息的管理和调用。

### 4\. 提示压缩 (Prompt Compression)

这类技术与改变模型架构不同，它专注于在将长文本输入模型之前，对其进行压缩，识别并剔除冗余内容，只保留最有价值的部分。

- **令牌修剪/合并 (Token Pruning/Merging)** ：
- **Power-BERT** 通过消除词嵌入中的冗余信息来减少计算量。
- **Token Merging (ToMe)** 不是删除令牌，而是将相似的冗余令牌批量合并，从而在不丢失太多信息的情况下缩短序列长度。
- **基于小模型的压缩** ：
- **LLMLingua** ：训练一个专门用于提示压缩的小型语言模型。它对输入进行粗粒度和细粒度的两遍压缩，以保留关键信息，同时大幅缩短提示长度。
- **LongLLMLingua** ：在 LLMLingua 的基础上进一步优化，旨在增强 LLM 对提示中关键信息的感知能力。

### 5\. 工程方法 (Engineering Approaches)

除了算法层面的优化，许多业界领先的模型还结合了硬件层面的工程优化来实现超长上下文。

- **Flash Attention** ：利用 GPU 硬件的特性，将计算尽可能地保留在速度更快的 SRAM 中，从而减少对 GPU 显存的读写操作，大幅提升了注意力计算的速度和效率。
- **Ring Attention** ：在多机多卡的场景下，让每块硬件只存储部分注意力矩阵，各自进行部分计算，最后再将结果聚合起来，从而突破了单张显卡的显存限制。

长上下文处理是一个多维度、跨层次的技术领域，它结合了从底层硬件优化到顶层算法设计的多种策略，其最终目标是打破 Transformer 架构的长度限制，使 LLM 能够真正胜任对海量文档的深度理解和分析任务。

## 数据集、实现、基准和指标

论文最后一部分关于 **数据集、实现、基准和指标** 的内容。这四个方面共同构成了文档智能研究的基石，为模型的训练、部署、评估和比较提供了完整的框架。

### 1\. 数据集 (Datasets)

数据集是模型训练和验证的基础，其质量和多样性直接影响模型的学习效果和泛化能力。研究者重点介绍了以下四类关键数据集：

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **文档问答 (Document QA) 数据集** ：这类数据集支持对视觉内容的理解。
- **DocVQA** ：包含超过5万个源自各种文档（如发票、报告）图像的问题，尤其适用于导航和视觉布局推理任务。
- **QASPER** ：专注于科学文献领域，包含1585篇论文和5049个相关问题，有助于对论文进行深度分析。
- **InfographicVQA** ：专注于对视觉信息的基本推理，包含5485份文档和超过3万个问题。
- **ChartQA** 和 **PlotQA** ：将问答能力扩展到图表信息，分别包含大量关于图表的问题和摘要。
	![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **文档布局分析 (Document Layout Analysis) 数据集** ：这类数据集面向文档的结构化分析。
- **Publaynet** ：一个大规模的文档布局分析数据集，训练集包含超过33万张图像，为文本、标题、表格等元素提供了详细的标注。
- **DocLayNet** ：包含80863个带有标注的PDF页面，支持对各种文档及其布局进行精确训练。
- **DocBank** ：从科学论文中获取细粒度的语义类别，为文档分析增加了深度和广度。
	![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **表格识别 (Table Recognition) 数据集** ：这类数据集专注于表格信息的提取。
- **TableBank** ：包含来自Word和LaTeX的丰富表格图像，用于支持和加强大模型在表格检测和识别方面的能力。
- **PubTabNet** ：一个大规模的基于图像的表格识别资源，包含超过56.8万张表格图像及其对应的HTML表示。
- **XFUND** ：一个多语言环境下的表格数据集，涵盖七种语言，对信息提取任务至关重要。
- **推理 (Reasoning) 数据集** ：这类数据集专注于表格的语义理解和逻辑推理。
- **TabFact** ：基于维基百科表格构建了11.8万个陈述及其真伪标注，专注于表格内容的逻辑一致性验证和事实推理。
- **WikiTableQuestions** ：提供了22033个需要多步推理的问答对，涵盖数值计算、时间推理和实体关系推断等核心任务。

### 2\. 实现 (Implementation)

实现部分涵盖了构建高效文档智能系统所需的实用策略、工具选择和系统设计原则。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **工具选择** ：
- **OCR-Free模型** ：像 **mPLUG-DocOwl 1.5** 和 **DocLLM** 这样的布局感知视觉语言模型，可以直接处理文档图像，替代传统的OCR流程，同时提高鲁棒性。
- **统一提示框架** ： **OmniParser v2** 等工具允许通过一个通用接口处理结构化解析、键值提取和视觉文本理解等多种任务。
	![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **集成策略** ：
- **长文档处理** ： **DocOwl2** 模型集成了视觉令牌压缩和序列对齐技术，以高效处理多页文档而不损害其结构完整性。
- **商业平台** ： **Azure Document Intelligence** 提供了模块化的API，用于布局解析、字段提取和文档分类，允许灵活地组合传统和现代组件。
- **RAG框架** ：RAG已成为文档问答的核心，相关研究强调了分块策略、证据选择和溯源机制的重要性。
	![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **最佳实践** ：
- **可解释性** ：像 **DLaVA** 这样的工具通过提供视觉证据（例如，在文档图像上定位答案来源）来增强用户信任。
- **模块化** ：商业工具和学术研究都强调了模块化设计的重要性，包括备用方案处理和“人在回路”的验证机制。

### 3\. 基准 (Benchmarks)

基准是评估模型性能和比较不同方法的关键工具。研究者们重点介绍了六个重要的基准研究：

- **UDA (Unstructured Document Analysis)** ：包含金融、学术和世界知识三个领域的真实世界文档和专家标注的问答对，旨在反映真实应用场景。
- **OHRBench** ：首个用于理解OCR对RAG系统级联影响的基准，评估OCR产生的语义和格式噪声对RAG性能的影响。
- **OCRBench (v1/v2)** ：旨在评估多模态大模型在OCR任务中的表现，涵盖文本识别、文档问答和关键信息提取等多个方面。
- **OmniDocBench** ：包含多种文档类型（如学术论文、教科书）和丰富的布局、内容及属性标注，用于评估模型在文本、表格、公式等多种任务上的表现。
- **CC-OCR** ：一个全面且具挑战性的OCR基准，包含多场景文本阅读、多语言文本阅读、文档解析和关键信息提取四大任务。

### 4\. 指标 (Metrics)

为了全面评估模型在各种文档处理任务中的性能，需要使用多样化的评估指标。

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)
- **定位和识别指标** ：
- **IoU (Intersection over Union)** ：衡量预测边界框与真实边界框重叠程度的核心指标，广泛用于文本和表格检测。
- **F1-score** ：平衡了精确率和召回率，用于评估定位和识别任务的整体准确性。
- **CER (Character Error Rate)** ：衡量字符级别的差异，用于高精度的OCR任务评估。
- **结构和语义相似性指标** ：
- **SSIM (Structural Similarity Index)** ：通过评估亮度、对比度和结构信息来衡量图像相似度，常用于数学公式识别和图表结构提取。
- **TEDS (Tree-Edit-Distance-Based Similarity)** ：使用树编辑距离来衡量表格结构的相似性，特别适用于评估复杂的表格逻辑结构。
- **表格和图表专用指标** ：
- **Purity 和 Completeness** ：分别用于衡量表格检测结果中的噪声水平和检测区域的覆盖率。
- **CAR (Cell Adjacency Relations)** ：专注于分析表格中单元格边界检测和相对定位的准确性。
- **数学表达式识别专用指标** ：
- **CDM (Character Detection Matching)** ：通过解决不同LaTeX表示法可能引发的问题，为数学表达式的结构化分析提供了可靠的评估方法。

## 最后：挑战与未来展望

研究者们最后总结了文档智能领域面临的挑战并指出了未来的研究方向：

**主要挑战** ：

- **检索结果中的噪声** ：文档解析过程可能引入错误，导致检索到的信息包含噪声或矛盾。
- **分块结果的完整性** ：如何将解析后的文档重新分割成连贯的语义块是一个关键问题。
- **RAG系统的复杂性** ：依赖多种工具和API接口增加了工程开销和系统复杂性。
- **文档特征的差异性** ：学术文档与金融报告等行业文档在结构和内容上存在显著差异，限制了技术的广泛应用。

**未来工作** ：

- **更灵活的RAG架构** ：开发递归或自适应的RAG架构，以适应不同的文档结构和用户需求。
- **先进的纠错机制** ：实施复杂的错误检测和校正机制，以解决检索结果中的噪声问题。
- **拓展更多领域的应用** ：将文档智能技术应用于教育、医疗、法律和科学研究等更多领域，以释放其巨大潜力。

回顾全文，我们不难发现，这篇论文最大的价值不仅在于其全面性，更在于其强烈的“工程实践”导向。它没有停留在理论探讨，而是将文档智能的实现路径清晰地摆在我们面前。无论是RAG的噪声，还是端到端模型的幻觉，这些都并非技术的终点，恰恰是创新的 **起点** 和商业价值的 **机遇点** 。“管线式vs端到端”的取舍，是成本与精度的权衡；“RAG vs 长上下文”的协同，是通用性与专用性的博弈。对于每一位开发者、产品经理和研究者而言，这篇论文就是一本珍贵的“导航手册”。它告诉我们，从“能用”到“好用”的文档智能产品，需要在哪些技术节点上做精做深。 未来已来，这份蓝图，就是我们亲手构建下一个智能应用时代的起点。如果这篇文章能帮到您，麻烦给修猫点一个赞或在看！感谢！

未来已来，有缘一起同行！

![Image](https://mp.weixin.qq.com/s/www.w3.org/2000/svg'%20xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg%20stroke='none'%20stroke-width='1'%20fill='none'%20fill-rule='evenodd'%20fill-opacity='0'%3E%3Cg%20transform='translate(-249.000000,%20-126.000000)'%20fill='%23FFFFFF'%3E%3Crect%20x='249'%20y='126'%20width='1'%20height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

<本文完 结>

1. **转载请与本喵联系，私自抓取转载将被起诉**

🎉 **让我们一起创造更多美好！** 🎉

  

如果您觉得这篇文章对您有帮助

感谢您为我 **【点赞】** 、 **【在看】**

  

**<您为我点赞在看，只有我能看到>**

  

**👉** **微信号：xiumaoprompt**

**添加请注明来意！**

感谢！

素材来源官方媒体/网络新闻

继续滑动看下一个

AI修猫Prompt

向上滑动看下一个