## 效率A vs 效率B

效率B侧重于减少运营负担——通过修改流程以较少的资源实现相同水平的产出、质量或服务。尽管有价值，但我们认为效率B并不是创新驱动竞争的核心。
相比之下，效率A更为雄心勃勃，关注于在相同的资源基础上创造显著更多的价值。后者形式的效率实现起来更具挑战性，但影响深远，也是我们在整个工作中明确倡导的形式。


## 探索 vs 变现

- 他们刻意把CoE长期维持在exploration状态，直到认为达到“转型sigmoid的顶部”：再投入巨大工程也只会带来边际创新；这意味着关键工具集已经齐备。
    
- 这种策略与主流“尽快商业化”的激励相反，研究者在结论中把它描述为构建M2所必需的纪律性探索。
![image.png](https://raw.githubusercontent.com/akan/wangzhan/main/pic/20260109101416397.png)


## “化身校准”

概念上的反转：利用强化学习来理解交易算法的内部“大脑”，并根据交易员的“大脑”（即专家的启发式方法）对其进行校准（一种正则化形式）。证明了在日益由机器主导的环境中，人类专家仍能发挥重要作用，通过校准过程向机器证明，其性能在有人类参与的情况下优于无人类参与的情况。

![image.png](https://raw.githubusercontent.com/akan/wangzhan/main/pic/20260109102223785.png)


## 联邦架构包含两个基本层：

### 1. 服务
    包括数据库、消息系统和通信协议等共享组件。

### 2. 智能代理（或智能节点）
    代表系统“如果-那么”逻辑被分解成的模块单元。每个节点作为算法实体自主运行，能够将启发式方法与统计模型（计算或传统）结合起来，类似于算法交易策略的架构。

![image.png](https://raw.githubusercontent.com/akan/wangzhan/main/pic/20260109101916488.png)

## 三种架构

1. 最小架构单元（MAU），包含单元的核心计算原理、数据驱动操作所需的数据访问能力以及参与联邦网络所需的通信接口。

2. 最小架构扩展（MAE），构成对MAU的直接功能增强，扩展其操作范围，同时保持结构凝聚力和互操作性。

3. 最小架构模式（MAP），是MAU和MAE的高层次编排。MAP生成完整的服务和应用程序，并且从根本上基于代理之间的设计互操作性。其性能通过协调的软硬件协同作用进一步提升，同样嵌入到架构设计之初——即它们是协同的定制SaaS。
![image.png](https://raw.githubusercontent.com/akan/wangzhan/main/pic/20260109102329466.png)
![image.png](https://raw.githubusercontent.com/akan/wangzhan/main/pic/20260109102424769.png)


## 两种代理

● 当节点包含明确的算法结构时，我们称其为基于策略的AI代理。


● 当一个节点主要由统计模型构成，并且该模型是大语言模型（LLM）时，我们将其归类为基于LLM的AI代理。

在目标是可扩展、有弹性和生产级别的转型时，基于策略的架构优于基于LLM的方法。我们的分析旨在提供一个框架，使读者能够做出明智的判断，而不是强加一个结论。


## 为什么AI迄今大多失败

### 公司不是算法生态系统
### 供应商尚未准备好，其客户亦然
### 人才在转型中的角色管理不当


● 真正的催化剂带来了推动公司前进所需的愿景、方法、知识和架构理解。

● 合适的倡导者是愿意承担风险以追求回报的内部企业家。

● 审计员的设计目的是观察和报告；他们不创造或推动转型。但他们是有智慧的资产，高级管理层可以利用。

混淆这些角色会导致停滞的举措、稀释的影响、内部（和外部）摩擦，最终导致战略失败。当高级管理层主要为了审计内部努力而指派值得信赖的员工担任转型角色，却未能将他们与缺乏必要跨学科专业知识的催化剂职责分离时，组织就会暴露于最昂贵的战略错误之一。这种角色、技能和授权的错位系统性地减缓了转型，扭曲了技术采用路径，最终危及公司的长期竞争地位。

### 应用科学与科学应用的混淆

所谓的“科学应用”，它们通常缺乏足够的领域知识来解决潜在的业务挑战。这种技能与需求之间的不匹配导致了结构性失败模式

有效的解决方案，即应用科学，需要整合专家启发式、计算统计学和传统统计方法——共同形成我们所定义的算法。此外，在竞争环境中，解决方案本质上是动态的：需要不断纳入新的启发式方法、更新的模型和改进的操作程序。这种迭代进化实际上是无止境的。因此，我们认为创造力——即生成新启发式方法和战略洞察的能力——将继续成为未来人类工作的核心，即使算法系统变得越来越普遍。


## 智能代理AI的机器理论：M1和M2

### M1
包括构建学习组件（即L）所需的所有机制——即，构建、估计和展示统计模型f(·)；

### M2
包括消费L所需的所有机制，将其集成到企业范围内的算法、战略和运营架构中。M2可以包含多个M1


### ML中的L
机器学习的学习组件——即ML中的L——对应于计算统计学和传统统计学的结合领域。从转型的角度来看，这一组件代表了科学：模型f(·)是其核心挑战。该领域通过数十年持续的学术研究得以发展，旨在推进模型开发的前沿。因此，学术界在这个领域保留了结构性优势。市面上的通用大模型商品化

### ML中的M1
    
    类似RAG， SFT应该都属于M1，模型训练、部署和微调的成本极等等。围绕大模型的基建。
1. 将数据转换为适合统计估计的数值表示（例如，分词、嵌入、张量）。

2. 执行大规模迭代优化以估计 f(·) 的参数（例如，梯度下降、反向传播、分布式训练）。

3. 管理计算环境——GPU集群、分布式系统、内存管理——使这种优化能够大规模进行。

4. 部署并提供生成的模型以供下游应用或用户界面使用。

超高速交易系统需要极其复杂、低延迟的基础设施，通常位于交易所同一物理建筑内以实现最快的可能消息传播——否则，相同的算法可能会表现出显著不同的性能。这些都是典型的M1系统：紧密工程化、硬件密集型，并专注于精确校准。

### ML中的M2 （应用科学）

    尽管M1基于LLM的实现外还存在其他实现方式，灵活且互操作的战略推理并不是M1的目标——这就是为什么还需要一个M2
M2系统有如下挑战
精益IT 
专有网络安全
设计合规性

M1 创建模型；M2 创建能够消费该模型的组织。

